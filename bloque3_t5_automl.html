
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>14. T5. Auto Machine Learning(AutoML) &#8212; Minería de Textos</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/estilos.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="15. T5.1. AutoGOAL" href="bloque3_t5.1_autogoal.html" />
    <link rel="prev" title="13. T4. Centralización de datasets y modelos: Huggingface" href="bloque3_t4_huggingface.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-master-ca.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Minería de Textos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Materiales de Minería de Textos
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 1
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1.html">
   1. Introducción a la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_1Introduccion.html">
   2. Minería de textos y procesamiento del lenguaje natural.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_2CategorialSintactico.html">
   3. Análisis categorial y sintáctico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica1.html">
   4. Práctica 1.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_3AnalisisSemantico.html">
   5. Análisis semántico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_4AnalisisSemanticoVectorial.html">
   6. Análisis semántico vectorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica2.html">
   7. Práctica 1b :
   <em>
    Topic modeling
   </em>
   .
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 2
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3.html">
   8. Aplicaciones de la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t1_aplicaciones.html">
   9. T1. Aplicaciones generales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t2_subaplicaciones-benchmarks.html">
   10. T2. Aplicaciones específicas y Benchmacks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t2.1_analisis_sentimientos.html">
   11. T2.1. Aplicaciones específicas. Análisis de Sentimientos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t3.1_metricas.html">
   12. T3. Métricas de Evaluación
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t4_huggingface.html">
   13. T4. Centralización de datasets y modelos: Huggingface
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   14. T5. Auto Machine Learning(AutoML)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t5.1_autogoal.html">
   15. T5.1. AutoGOAL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p1_SA-Pipeline-Reviews.html">
   16. P1.1. Pipeline simple
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p2_SA-Transformers-Basic.html">
   17. P1.2. APIs Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p3_SA-Transformers-Training-FineTuning.html">
   18. P2. Reajustar modelos Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p4_SA-Transformers-Training-Custom.html">
   19. P3. Composición de vectores de características
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_ev.html">
   20. Ev. Evaluación del bloque 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 3
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque2.html">
   21. Técnicas para la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque2_historia.html">
   22. Revisión histórica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque2_embeddings.html">
   23. Representaciones de palabras y oraciones
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque2_practica.html">
   24. Práctica. Lectura y documentación del código de un extractor de entidades
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Extras
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="content.html">
   25. Content in Jupyter Book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   26. Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   27. Content with notebooks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/bloque3_t5_automl.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   14.1. Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#automl-vs-estandar-ml">
   14.2. AutoML vs estandar ML
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objetivos-de-automatizacion">
   14.3. Objetivos de automatización
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rendimiento-suficientemente-bueno">
     14.3.1. Rendimiento suficientemente bueno
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metodos-de-automl">
   14.4. Métodos de AutoML
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#busqueda-de-arquitectura-neuronal-neural-architecture-search-nas">
     14.4.1. Búsqueda de arquitectura neuronal (Neural Architecture Search,NAS)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sistemas-de-automl">
   14.5. Sistemas de AutoML
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-weka">
     14.5.1. Auto-Weka
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperopt-sklearn">
     14.5.2. Hyperopt-Sklearn
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-sklearn">
     14.5.3. Auto-sklearn
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-net-towards-automatically-tuned-neural-networks">
     14.5.4. Auto-Net: Towards Automatically-Tuned Neural Networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tpot-a-tool-for-automating-machine-learning">
     14.5.5. TPOT: A Tool for Automating Machine Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autogoal-automatic-generation-optimization-and-artificial-learning">
     14.5.6. AutoGOAL: Automatic Generation, Optimization And Artificial Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#competiciones-y-benchmarks-de-automl">
   14.6. Competiciones y Benchmarks de AutoML
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliogarfia">
   14.7. Bibliogarfía
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>T5. Auto Machine Learning(AutoML)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   14.1. Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#automl-vs-estandar-ml">
   14.2. AutoML vs estandar ML
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#objetivos-de-automatizacion">
   14.3. Objetivos de automatización
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rendimiento-suficientemente-bueno">
     14.3.1. Rendimiento suficientemente bueno
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metodos-de-automl">
   14.4. Métodos de AutoML
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#busqueda-de-arquitectura-neuronal-neural-architecture-search-nas">
     14.4.1. Búsqueda de arquitectura neuronal (Neural Architecture Search,NAS)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sistemas-de-automl">
   14.5. Sistemas de AutoML
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-weka">
     14.5.1. Auto-Weka
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hyperopt-sklearn">
     14.5.2. Hyperopt-Sklearn
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-sklearn">
     14.5.3. Auto-sklearn
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auto-net-towards-automatically-tuned-neural-networks">
     14.5.4. Auto-Net: Towards Automatically-Tuned Neural Networks
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tpot-a-tool-for-automating-machine-learning">
     14.5.5. TPOT: A Tool for Automating Machine Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autogoal-automatic-generation-optimization-and-artificial-learning">
     14.5.6. AutoGOAL: Automatic Generation, Optimization And Artificial Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#competiciones-y-benchmarks-de-automl">
   14.6. Competiciones y Benchmarks de AutoML
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliogarfia">
   14.7. Bibliogarfía
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="t5-auto-machine-learning-automl">
<h1><span class="section-number">14. </span>T5. Auto Machine Learning(AutoML)<a class="headerlink" href="#t5-auto-machine-learning-automl" title="Permalink to this headline">#</a></h1>
<p>Contenidos:</p>
<ul class="simple">
<li><p><a class="reference external" href="#introduccion">Introducción</a></p></li>
<li><p><a class="reference external" href="#automl-vs-estandar-ml">AutoML vs estandar ML</a></p></li>
<li><p><a class="reference external" href="#objetivos-de-automatizacion">Objetivos de automatización</a></p></li>
<li><p><a class="reference external" href="#metodos-de-automl">Métodos de AutoML</a></p></li>
<li><p><a class="reference external" href="#sistemas-de-automl">Sistemas de AutoML</a></p></li>
<li><p><a class="reference external" href="#competiciones-y-benchmarks-de-automl">Competiciones y Benchmarks de AutoML</a></p></li>
</ul>
<section id="introduccion">
<h2><span class="section-number">14.1. </span>Introducción<a class="headerlink" href="#introduccion" title="Permalink to this headline">#</a></h2>
<p>“I’d like to use machine learning, but I can’t invest much time” =&gt; <em>Me gustaría usar aprendizaje de máquinas, pero no puedo invertir mucho tiempo.</em></p>
<p>Esta <strong>frase</strong> es algo que <strong>se escucha con demasiada frecuencia</strong> en la industria y de investigadores de otras disciplinas ajenas al aprendizaje de máquinas. La <strong>demanda de soluciones con muy poca implicación humana</strong> para el aprendizaje automático ha dado lugar recientemente al campo del aprendizaje automático automatizado (<strong>AutoML</strong>) [1].
El aprendizaje automático (AutoML) es el proceso de automatizar una acción aplicando el aprendizaje automático común para resolver problemas reales.</p>
<p><strong>Ventaja:</strong></p>
<ul class="simple">
<li><p>El alto grado de <strong>automatización</strong> en AutoML permite que aquellos que no son expertos puedan hacer uso de <strong>modelos de aprendizaje automático</strong> sin necesitar mucha experiencia previa en dicho campo.</p></li>
<li><p>La automatización del proceso de aprendizaje ofrece otras ventajas, como la <strong>producción de soluciones más sencillas</strong> y una <strong>resolución más rápida</strong>.</p></li>
</ul>
</section>
<section id="automl-vs-estandar-ml">
<h2><span class="section-number">14.2. </span>AutoML vs estandar ML<a class="headerlink" href="#automl-vs-estandar-ml" title="Permalink to this headline">#</a></h2>
<p>En una aplicación de <strong>aprendizaje automático estándar</strong>, los practicantes tienen un conjunto de datos y tienen que lidiar con distintas etapas para el diseño de su algoritmo.
Un <strong>experto puede</strong>:</p>
<ol class="simple">
<li><p>tener que aplicar los <strong>datos de preprocesado adecuados</strong>,</p></li>
<li><p>realizar <strong>métodos de ingeniería</strong>,</p></li>
<li><p><strong>extracción</strong> y</p></li>
<li><p><strong>selección</strong> para hacer el <strong>conjunto de datos</strong> legible para el aprendizaje automático. Siguiendo dichos pasos de preprocesado, los practicantes han de realizar</p></li>
<li><p><strong>selección de algoritmo</strong>, y</p></li>
<li><p><strong>optimización de hiperparámetros</strong> para maximizar el rendimiento predictivo su modelo de aprendizaje automático.</p></li>
</ol>
<p>Esto es precisamente los que el AutoML persigue automatizar y liberar al practicante de repetitivas iteraciones de prueba de parámetros y estrategias.</p>
<p><strong>Una desventaja</strong> son los <strong>parámetros adicionales</strong> de las herramientas AutoML, que pueden necesitar alguna ayuda para establecerse. Aunque existan dicho hiperparámetros, <strong>AutoML simplifica la aplicación de aprendizaje automático para aquellos que no son expertos</strong>.</p>
</section>
<section id="objetivos-de-automatizacion">
<h2><span class="section-number">14.3. </span>Objetivos de automatización<a class="headerlink" href="#objetivos-de-automatizacion" title="Permalink to this headline">#</a></h2>
<p>La última década ha sido testigo de una explosión de investigación y aplicaciones de aprendizaje automático; especialmente, los métodos de aprendizaje profundo (<em>Deep Learning</em>) <strong>han permitido avances clave</strong> en muchos dominios de aplicaciones, como la visión por computadora, el procesamiento del habla y los video juegos. Sin embargo, el rendimiento de muchos <strong>métodos de aprendizaje automático</strong> es <strong>muy sensible</strong> a una gran cantidad de <strong>decisiones de diseño</strong>, lo que constituye una barrera considerable para los nuevos usuarios. Esto es particularmente cierto en el campo en auge del aprendizaje profundo, donde los <strong>ingenieros humanos</strong> deben aplicar el <strong>proceso de seleccionar</strong>:</p>
<ul class="simple">
<li><p>las <strong>arquitecturas neuronales</strong>,</p></li>
<li><p>los <strong>procedimientos de entrenamiento</strong>,</p></li>
<li><p>los <strong>métodos de regularización</strong> y</p></li>
<li><p>los <strong>hiper-parámetros</strong> correctos de todos estos componentes para hacer que sus redes hagan lo que se supone que deben hacer.</p></li>
</ul>
<section id="rendimiento-suficientemente-bueno">
<h3><span class="section-number">14.3.1. </span>Rendimiento suficientemente bueno<a class="headerlink" href="#rendimiento-suficientemente-bueno" title="Permalink to this headline">#</a></h3>
<p>Este proceso debe repetirse para cada aplicación. Incluso los expertos a menudo se quedan con tediosos episodios de prueba y error hasta que identifican un buen conjunto de opciones para un conjunto de datos en particular.
El campo del aprendizaje automático automatizado (AutoML) tiene como objetivo tomar estas decisiones de una manera basada en datos, objetiva y automatizada:</p>
<ul class="simple">
<li><p>el <strong>usuario</strong> simplemente <strong>proporciona datos</strong></p></li>
<li><p>y el <strong>sistema AutoML determina</strong> automáticamente el <strong>enfoque</strong> que funciona <strong>mejor</strong>.</p></li>
</ul>
<p>Por lo tanto, <strong>AutoML</strong> hace que los <strong>enfoques de aprendizaje automático</strong> de vanguardia sean <strong>accesibles</strong> para los <strong>científicos</strong> del dominio que están interesados en aplicar el aprendizaje automático, pero que <strong>no</strong> tienen los recursos para <strong>aprender</strong> sobre las <strong>tecnologías</strong> de ML en detalle. Esto puede verse como una <strong>democratización del aprendizaje automático</strong>.
Con <strong>AutoML</strong>, el aprendizaje automático personalizado de última generación está <strong>al alcance de todos</strong>. La máquina de aprendizaje automático puede tener varios objetivos en su proceso de automatización. Esencialmente los <strong>objetivos</strong> pueden ser <strong>agrupados</strong> en campos de <strong>preparación</strong>, <strong>ingeniería</strong>, selección de <strong>métrica</strong> y optimización de <strong>hiper-parámetros</strong>.</p>
<ul class="simple">
<li><p><strong>Preparación de datos automatizada</strong> (de datos en crudo y formatos misceláneos)</p>
<ul>
<li><p>Detección automatizada de tipo columna; por ejemplo, booleano, discreto numérico, continuo numérico o texto.</p></li>
<li><p>Detección automatizada de intento de columna; por ejemplo, etiqueta/objetivo, campo de estratificación, característica numérica, característica de texto categórico o característica de texto libre.</p></li>
<li><p>Detección de tarea automatizada; por ejemplo, clasificación binaria, regresión, agrupamiento o clasificación.</p></li>
</ul>
</li>
<li><p><strong>Ingeniería automatizada</strong></p>
<ul>
<li><p>Selección de variable.</p></li>
<li><p>Extracción de variable.</p></li>
<li><p>Meta-aprendizaje y aprendizaje de transferencia.</p></li>
<li><p>Detección y manipulación de datos sesgados y/o valores desaparecidos.</p></li>
</ul>
</li>
<li><p><strong>Selección de modelo automatizado</strong></p></li>
<li><p><strong>Optimización de hiperparámetros</strong> del algoritmo de aprendizaje y caracterización.</p></li>
<li><p><strong>Selección automatizada de métricas</strong> de evaluación o procedimientos de validación.</p></li>
<li><p><strong>Comprobación automática de problemas</strong></p>
<ul>
<li><p>Detección de elementos filtrados</p></li>
<li><p>Detección de fallos de configuración</p></li>
</ul>
</li>
<li><p><strong>Resultados obtenidos de análisis automáticos</strong>.</p></li>
<li><p><strong>Interfaces</strong> de usuario y <strong>visualizaciones</strong> de aprendizaje automático.</p></li>
</ul>
</section>
</section>
<section id="metodos-de-automl">
<h2><span class="section-number">14.4. </span>Métodos de AutoML<a class="headerlink" href="#metodos-de-automl" title="Permalink to this headline">#</a></h2>
<p>Entre las <strong>vertientes</strong> más generales en la que se enfoca el <strong>AutoML</strong> nos encontramos con la <strong>Optimización de Parámetros</strong>; el <strong>Meta Aprendizaje</strong>; y la <strong>Búsqueda de Arquitecturas de Redes Neuronales</strong>. A continuación, listamos los siguientes trabajos en los que se recopila el estado de la cuestión de cada una de estas:</p>
<ul class="simple">
<li><p><strong>Optimización de hyperparametros</strong>: La optimización o ajuste de hiperparámetros es el problema de elegir un conjunto de hiperparámetros óptimos para un algoritmo de aprendizaje. Un hiperparámetro es un parámetro cuyo valor se utiliza para controlar el proceso de aprendizaje. Por el contrario, se aprenden los valores de otros parámetros (normalmente ponderaciones de los nodos).
El mismo tipo de modelo de aprendizaje automático puede requerir diferentes restricciones, pesos o tasas de aprendizaje para generalizar diferentes patrones de datos. Estas medidas se denominan hiperparámetros y deben ajustarse para que el modelo pueda resolver de manera óptima el problema del aprendizaje automático.
La optimización de hiperparámetros encuentra una tupla de hiperparámetros que produce un <strong>modelo óptimo</strong> que <strong>minimiza una función de pérdida</strong> predefinida en datos independientes dados. [2] La <strong>función objetivo</strong> toma una <strong>tupla</strong> de <strong>hiperparámetros</strong> y <strong>devuelve la pérdida asociada</strong>. [2] La <strong>validación cruzada</strong> se utiliza a menudo para <strong>estimar este rendimiento de generalización</strong>. [3].
La optimización de hyperparametros se suele estudiar aplicando técnicas como las que se listan a continuación:</p>
<ul>
<li><p>Grid search</p></li>
<li><p>Random search</p></li>
<li><p>Bayesian optimization</p></li>
<li><p>Gradient-based optimization</p></li>
<li><p>Evolutionary optimization</p></li>
<li><p>Population-based</p></li>
<li><p>Early Stopping-based</p></li>
</ul>
</li>
</ul>
<p>Se recomienda la lectura del capítulo Hyperparameter Optimization [1], donde se hace una lectura concienzuda de la bibliografía.</p>
<ul class="simple">
<li><p><strong>Meta Aprendizaje:</strong> Consiste en aplicar <strong>algoritmos de ML</strong> a los <strong>metadatos de otros algoritmos de ML</strong>, de ahí la denominación alternativa: aprender a aprender.</p></li>
</ul>
<p>El objetivo es <strong>entender cómo resolver problemas de aprendizaje con mayor flexibilidad</strong>, mejorando el desempeño de algoritmos existentes o induciendo al algoritmo de aprendizaje en sí.
La <strong>flexibilidad es importante</strong> porque cada algoritmo está basado en una serie de asunciones sobre los datos, su sesgo inductivo. Esto quiere decir que el <strong>algoritmo solo aprenderá correctamente si su sesgo inductivo se ajusta al problema de aprendizaje</strong> (usualmente una base de datos). Por ende, un <strong>algoritmo se desempeña bien en un dominio específico</strong>, pero <strong>no en otros</strong>.</p>
<p>Se utilizan diferentes <strong>tipos de metadatos</strong> como:</p>
<ul class="simple">
<li><p>las <strong>propiedades del problema</strong> de aprendizaje,</p></li>
<li><p>las del <strong>propio algoritmo</strong> (como mediciones de desempeño), o</p></li>
<li><p><strong>patrones</strong> derivados directamente de los <strong>datos</strong>.</p></li>
</ul>
<p>De esta manera es posible aprender, seleccionar, alterar o combinar diferentes algoritmos de IA para buscar los resultados que mejor satisfagan el problema de aprendizaje.
Os recomendamos la lectura del capítulo Meta Learning [1], donde se hace una lectura concienzuda de la bibliografía al respecto.</p>
<section id="busqueda-de-arquitectura-neuronal-neural-architecture-search-nas">
<h3><span class="section-number">14.4.1. </span>Búsqueda de arquitectura neuronal (Neural Architecture Search,NAS)<a class="headerlink" href="#busqueda-de-arquitectura-neuronal-neural-architecture-search-nas" title="Permalink to this headline">#</a></h3>
<p>Es una <strong>técnica para automatizar el diseño de redes neuronales artificiales</strong>. Este es un modelo ampliamente utilizado en el campo del aprendizaje automático.</p>
<p>NAS se ha utilizado para diseñar redes que están a la par o superan las arquitecturas diseñadas a mano. Los <strong>métodos para NAS</strong> se pueden clasificar de acuerdo con el <strong>espacio de búsqueda</strong>, la <strong>estrategia de búsqueda</strong> y la <strong>estrategia de estimación del rendimiento</strong> utilizada:</p>
<ul class="simple">
<li><p>El <strong>espacio de búsqueda</strong> define el (los) tipo (s) de red neuronal artificial que se pueden diseñar y optimizar.</p></li>
<li><p>La <strong>estrategia de búsqueda</strong> define el enfoque de exploración del espacio de búsqueda.</p></li>
<li><p>La <strong>estrategia de estimación del desempeño</strong> evalúa el desempeño de una posible red neurinal artificial a partir de su diseño.</p></li>
</ul>
<p>NAS está estrechamente relacionado con la <strong>optimización de hiperparámetros</strong> y es un subcampo del aprendizaje automático automatizado (AutoML).
Os recomendamos la lectura del capítulo Neural Architecture Search [1], donde se hace una lectura concienzuda de la bibliografía al respecto.</p>
</section>
</section>
<section id="sistemas-de-automl">
<h2><span class="section-number">14.5. </span>Sistemas de AutoML<a class="headerlink" href="#sistemas-de-automl" title="Permalink to this headline">#</a></h2>
<section id="auto-weka">
<h3><span class="section-number">14.5.1. </span>Auto-Weka<a class="headerlink" href="#auto-weka" title="Permalink to this headline">#</a></h3>
<p><strong>Auto-Weka [12]</strong> ha sido uno de los <strong>primeros sistemas AutoML</strong> identificados en la literatura. <strong>Se basa</strong> en el conocido kit de herramientas de aprendizaje automático <strong>WEKA</strong> y busca en diferentes métodos de <strong>clasificación</strong> y <strong>regresión</strong>, su configuración de <strong>hiperparámetros</strong> y métodos de <strong>preprocesamiento de datos</strong>.</p>
<p>Todo esto está disponible a través de la <strong>interfaz gráfica</strong> con solo hacer clic en un botón, sin la necesidad de una sola línea de código.</p>
<p><strong>Software:</strong> <a class="reference external" href="https://www.cs.ubc.ca/labs/beta/Projects/autoweka/#software">https://www.cs.ubc.ca/labs/beta/Projects/autoweka/#software</a></p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/t5_autoweka.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/t5_autoweka.jpg" style="width: 500px;" /></a>
<p>Figura 1. Técnicas de aprendizaje y métodos soportados por Auto-Weka jiunto con el numero de hyper-parametros. Todos portan clasificación y los señalados con <code class="docutils literal notranslate"><span class="pre">*</span></code> soportan regresión. Tomado de [1].</p>
</section>
<section id="hyperopt-sklearn">
<h3><span class="section-number">14.5.2. </span>Hyperopt-Sklearn<a class="headerlink" href="#hyperopt-sklearn" title="Permalink to this headline">#</a></h3>
<p>Hyperopt-Sklearn [13] abarca la <strong>definición del espacio de búsqueda</strong> con:</p>
<ul class="simple">
<li><p>24 clasificadores</p></li>
<li><p>12 regresores</p></li>
<li><p>7 metodos de preprocesamiento
En total considera 65 hyperparametros: 15 boleanos, 14 categoricos, 17 discretos, y 19 variables de valores reales.</p></li>
</ul>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/t5_hyperopt-sklearn.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/t5_hyperopt-sklearn.jpg" style="width: 600px;" /></a>
<p>Figura 2. Ejemplo de un espacio de búsqueda de hyperopt-sklearn teniendo en cuenta un paso de preprocesamiento y un segundo de clasificación.Tomado de [1].</p>
</section>
<section id="auto-sklearn">
<h3><span class="section-number">14.5.3. </span>Auto-sklearn<a class="headerlink" href="#auto-sklearn" title="Permalink to this headline">#</a></h3>
<p>Auto-sklearn [14] es un <strong>sistema AutoML</strong> <strong>basado</strong> en el paquete de aprendizaje automático de <strong>Python scikit-learn</strong>.</p>
<p>Incluye:</p>
<ul class="simple">
<li><p>15 clasificadores,</p></li>
<li><p>14 metodos de preprocesamiento de características,</p></li>
<li><p>4 metodos de preprocesamiento de datos,</p></li>
<li><p>llegando a ngestinar hasta 110 hyperparameters</p></li>
</ul>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/t5_autosklearn_process.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/t5_autosklearn_process.jpg" style="width: 600px;" /></a>
<p>Figura 3. Proceso general de optimización. Tomado de [1].</p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/t5_autosklearn_espacioBusq.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/t5_autosklearn_espacioBusq.jpg" style="width: 600px;" /></a>
<p>Figura 4. Configuraciión estructurada del espacio de búsqueda. Tomado de [1].</p>
<p>El siguiente ejemplo muestra la simplicidad de invocar procediminetos con Autosklearn</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">autosklearn.classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">cls</span> <span class="o">=</span> <span class="n">autosklearn</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">AutoSklearnClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">cls</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">predictions</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>Vér más en <a class="reference external" href="https://automl.github.io/auto-sklearn/master/#example">https://automl.github.io/auto-sklearn/master/#example</a></p>
</section>
<section id="auto-net-towards-automatically-tuned-neural-networks">
<h3><span class="section-number">14.5.4. </span>Auto-Net: Towards Automatically-Tuned Neural Networks<a class="headerlink" href="#auto-net-towards-automatically-tuned-neural-networks" title="Permalink to this headline">#</a></h3>
<p><strong>AutoNet1.0 [11]</strong>. Una <strong>extension de AutoSKlearn</strong> añadiendo algunos componentes de clasificación y regresión.
Permite aprovechar las partes existentes de la canalización del aprendizaje automático:</p>
<ul class="simple">
<li><p>preprocesamiento de funciones,</p></li>
<li><p>preprocesamiento de datos</p></li>
<li><p>y construcción de conjuntos.
Aquí, <strong>limitamos Auto-Net a redes neuronales</strong> de alimentación <strong>hacia adelante</strong> completamente conectadas (full connceted), ya que se aplican a una amplia gama de conjuntos de datos diferentes; diferimos la extensión a otros tipos de redes neuronales, como las <strong>redes neuronales convolucionales (CNN)</strong> o <strong>recurrentes(RNN)</strong>.</p></li>
</ul>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/t5_config_espacio_autonet1.0.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/t5_config_espacio_autonet1.0.jpg" style="width: 500px;" /></a>
<p>Figura 5. Configuración del espacio de búsqueda con AutoNet 1.0.</p>
<p><strong>AutoNet 2.0</strong>. Se <strong>diferencia</strong> de <strong>AutoNet 1.0</strong> principalmente en los siguientes tres aspectos:</p>
<ul class="simple">
<li><p>utiliza <strong>PyTorch</strong> en lugar de Lasagne como biblioteca de <strong>aprendizaje profundo</strong> (DeepLearning)</p></li>
<li><p>utiliza un <strong>espacio de configuración más grande</strong> que incluye técnicas de <strong>aprendizaje profundo actualizadas</strong>, <strong>arquitecturas modernas</strong> (como ResNets) e incluye <strong>representaciones más compactas</strong> del espacio de búsqueda, y</p></li>
<li><p>aplica <a class="reference external" href="https://www.automl.org/blog_bohb/">BOHB</a> en lugar de <a class="reference external" href="https://www.automl.org/automated-algorithm-design/algorithm-configuration/smac/">SMAC</a> para trabajar con la red neuronal de manera más eficiente.</p></li>
<li><p>la configuración de AutoNet 2.0 tiene hasta <strong>112 hyperparametros</strong> y está <strong>más centrado</strong> en descibir configuraciones de <strong>redes neuronales</strong>.</p></li>
</ul>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/t5_config_espacio_autonet2.0.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/t5_config_espacio_autonet2.0.jpg" style="width: 500px;" /></a>
<p>Figura 6. Configuración del espacio de búsqueda con AutoNet 2.0</p>
</section>
<section id="tpot-a-tool-for-automating-machine-learning">
<h3><span class="section-number">14.5.5. </span>TPOT: A Tool for Automating Machine Learning<a class="headerlink" href="#tpot-a-tool-for-automating-machine-learning" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://automl.info/tpot/">TPOT</a> es un <strong>contenedor para</strong> el paquete de aprendizaje automático de Python, <strong>scikitlearn</strong>. Cada operador de flujo de aprendizaje automático (es decir, GP primitivo) en TPOT corresponde a un algoritmo de aprendizaje automático, como un modelo de clasificación supervisado o un escalador de características estándar. Todas las implementaciones de los algoritmos de aprendizaje automático son de scikit-learn [excepto GBoost] [9] [10].</p>
<p><strong>Operadores de clasificación</strong> supervisados:</p>
<ul class="simple">
<li><p>DecisionTree,</p></li>
<li><p>RandomForest,</p></li>
<li><p>eXtreme Gradient Boosting Classifier (de XGBoost),</p></li>
<li><p>LogisticRegression,</p></li>
<li><p>y KNearestNeighborClassifier.</p></li>
</ul>
<p>Los <strong>operadores</strong> de clasificación <strong>almacenan</strong> las <strong>predicciones</strong> del clasificador <strong>como una nueva característica</strong> (i.e. estrategia memoria), así como la clasificación para la canalización.</p>
<p><strong>Operadores de preprocesamiento de funciones</strong>:</p>
<ul class="simple">
<li><p>StandardScaler,</p></li>
<li><p>RobustScaler,</p></li>
<li><p>MinMaxScaler,</p></li>
<li><p>MaxAbsScaler,</p></li>
<li><p>RandomizedPCA,</p></li>
<li><p>Binarizer</p></li>
<li><p>y PolynomialFeatures.</p></li>
</ul>
<p>Los <strong>operadores de preprocesamiento modifican el conjunto de datos</strong> de alguna manera y <strong>devuelven</strong> el <strong>conjunto de datos modificado</strong>.</p>
<p><strong>Operadores de selección de características</strong>:</p>
<ul class="simple">
<li><p>VarianceThreshold,</p></li>
<li><p>SelectKBest,</p></li>
<li><p>SelectPercentile,</p></li>
<li><p>SelectFwe,</p></li>
<li><p>y Eliminación de características recursivas <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html">RFE</a>.</p></li>
</ul>
<p>Los <strong>operadores de selección de características reducen la cantidad de características en el conjunto de datos</strong> utilizando algunos criterios y devuelven el conjunto de datos modificado.</p>
</section>
<section id="autogoal-automatic-generation-optimization-and-artificial-learning">
<h3><span class="section-number">14.5.6. </span>AutoGOAL: Automatic Generation, Optimization And Artificial Learning<a class="headerlink" href="#autogoal-automatic-generation-optimization-and-artificial-learning" title="Permalink to this headline">#</a></h3>
<p><strong>AutoGOAL</strong> es un marco para <strong>encontrar</strong> el mejor programa (<strong>Pipeline</strong>) para resolver un problema dado. AutoGOAL proporciona un conjunto de <strong>componentes de bajo nivel</strong> para definir diferentes espacios de búsqueda y buscar de manera eficiente en ellos. En el contexto específico del aprendizaje automático, AutoGOAL también proporciona <strong>componentes de alto nivel</strong> que se pueden usar como <strong>caja negra</strong> en casi <strong>cualquier tipo de problema y formato de conjunto de datos</strong>.</p>
<a class="bg-primary mb-1 reference internal image-reference" href="_images/t5_autogoal_arq.jpg"><img alt="comic xkcd 2421" class="bg-primary mb-1 align-center" src="_images/t5_autogoal_arq.jpg" style="width: 600px;" /></a>
<p>Figura 6. Arquitectura Autogoal[4] [5]</p>
<p>Simplicidad para usar AutoGOAL:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>!pip install autogoal[contrib]==0.4.4

from autogoal.datasets import cars
from autogoal.ml import AutoML
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
X, y,*_ = cars.load()

y = encoder.fit_transform(y)
automl = AutoML()
automl.fit(X, y)

# Reporte del mejor pipeline
print(automl.best_pipeline_)
print(&#39;score: &#39; + str(automl.best_score_))
</pre></div>
</div>
</section>
</section>
<section id="competiciones-y-benchmarks-de-automl">
<h2><span class="section-number">14.6. </span>Competiciones y Benchmarks de AutoML<a class="headerlink" href="#competiciones-y-benchmarks-de-automl" title="Permalink to this headline">#</a></h2>
<p>Hemos identificado <strong>entornos científicos de competición y benchmarks</strong>.  Estas competiciones han implicado los siguientes <strong>dominios de aplicación</strong> [8]:</p>
<ul class="simple">
<li><p>biología y medicina,</p></li>
<li><p>ecología,</p></li>
<li><p>gestión de la energía y la sostenibilidad,</p></li>
<li><p>procesamiento de imágenes,</p></li>
<li><p>texto,</p></li>
<li><p>audio,</p></li>
<li><p>voz,</p></li>
<li><p>vídeo y otros datos de sensores,</p></li>
<li><p>gestión y publicidad de redes sociales en Internet,</p></li>
<li><p>análisis de mercado y predicción financiera.</p></li>
</ul>
<p>Las distintas <strong>competiciones hasta la fecha</strong> son:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://competitions.codalab.org/competitions/2321">AutoML1</a> (2015-2016): ChaLearn Automatic Machine Learning Challenge (AutoML)</p></li>
<li><p><a class="reference external" href="https://competitions.codalab.org/competitions/17767">AutoML2</a> (2017-2018): AutoML 2018 challenge :: PAKDD2018</p></li>
<li><p><a class="reference external" href="https://competitions.codalab.org/competitions/19836">AutoML3</a> (LLML, 2018): AutoML3 (LLML, 2018)</p></li>
</ul>
</section>
<section id="bibliogarfia">
<h2><span class="section-number">14.7. </span>Bibliogarfía<a class="headerlink" href="#bibliogarfia" title="Permalink to this headline">#</a></h2>
<p>[1] Hutter, F., Kotthoff, L., &amp; Vanschoren, J. (2019). Automated machine learning: methods, systems, challenges (p. 219). Springer Nature.</p>
<p>[2] Claesen, Marc; Bart De Moor (2015). “Hyperparameter Search in Machine Learning”. arXiv:1502.02127 [cs.LG].</p>
<p>[3] Bergstra, James; Bengio, Yoshua (2012). “Random Search for Hyper-Parameter Optimization” (PDF). Journal of Machine Learning Research. 13: 281–305.</p>
<p>[4] Zoph, Barret; Le, Quoc V. (2016-11-04). “Neural Architecture Search with Reinforcement Learning”. arXiv:1611.01578 [cs.LG]</p>
<p>[5] Estévez-Velarde, S., Gutiérrez, Y., Almeida-Cruz, Y., &amp; Montoyo, A. (2020). General-purpose hierarchical optimisation of machine learning pipelines with grammatical evolution. Information Sciences, 543, 58-71.</p>
<p>[6] Estévez-Velarde, S., Piad-Morffis, A., Vázquez, Y.G., Montoyo, A., Muñoz-Guillena, R., &amp; Cruz, Y.A. (2020). Demo Application for the AutoGOAL Framework. COLING.</p>
<p>[7] (The Automatic Statistician. Christian Steinruecken and Emma Smith and David Janz and James Lloyd and Zoubin Ghahramani, 2019.)[<a class="reference external" href="https://www.automl.org/wp-content/uploads/2020/01/automl_ch9.txt">https://www.automl.org/wp-content/uploads/2020/01/automl_ch9.txt</a>]</p>
<p>[8] Analysis of the AutoML Challenge series 2015-2018 . Isabelle Guyon and Lisheng Sun-Hosoya and Marc Boull ́e and Hugo Jair Escalante and Sergio Escalera and Zhengying Liu and Damir Jajetic and Bisakha Ray and Mehreen Saeed and Michele Sebag and Alexander Statnikov and Wei-Wei Tu and Evelyne Viegas. 2018.</p>
<p>[9] TPOT: A Tool for Automating Machine Learning. Randal S. Olson and Jason H. Moore. 2018.</p>
<p>[10] The Automatic Statistician. Christian Steinruecken and Emma Smith and David Janz and James Lloyd and Zoubin Ghahramani. 2018.</p>
<p>[11] Towards Automatically-Tuned Neural Networks. Hector Mendoza and Aaron Klein and Matthias Feurer and Jost Tobias Springenberg and Matthias Urban and Michael Burkart and Max Dippel and Marius Lindauer and Frank Hutter. 2018.</p>
<p>[12] Auto-WEKA. Lars Kotthoff and Chris Thornton and Holger H. Hoos and Frank Hutter and Kevin Leyton-Brown. 2013.</p>
<p>[13] Hyperopt-Sklearn. Brent Komer and James Bergstra and Chris Eliasmith. 2019.</p>
<p>[14] Auto-sklearn: Efficient and Robust Automated Machine Learning. Matthias Feurer and Aaron Klein and Katharina Eggensperger and Jost Tobias Springenberg and Manuel Blum and Frank Hutter. 2019.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="bloque3_t4_huggingface.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">13. </span>T4. Centralización de datasets y modelos: Huggingface</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="bloque3_t5.1_autogoal.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">15. </span>T5.1. AutoGOAL</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Universitat d'Alacant<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>