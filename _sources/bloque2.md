
(label_tecnicas)=
T√©cnicas para la miner√≠a de textos
==================================

En este bloque se aborda el estudio de algunos modelos neuronales utilizados para procesar textos. El profesor de este bloque es Juan Antonio P√©rez Ortiz. El bloque comienza con un repaso del funcionamiento del regresor log√≠stico, que nos servir√° para asentar los conocimientos necesarios para entender posteriores modelos. A continuaci√≥n se estudia con cierto nivel de detalle *skip-grams*, uno de los algoritmos para la obtenci√≥n de *embeddings* incontextuales de palabras. Despu√©s se repasa el funcionamiento de las arquitecturas neuronales *feedforward* y se estudia su aplicaci√≥n a modelos de lengua. El objetivo √∫ltimo es abordar el estudio de la arquitectura m√°s importante de los sistemas actuales de procesamiento de textos: el transformer. Una vez estudiadas estas arquitecturas, finalizaremos con un an√°lisis del funcionamiento de los modelos preentrenados (modelos fundacionales), en general, y de los modelos de lengua, en particular.

Los materiales de clase complementan la lectura de algunos cap√≠tulos de un libro de texto ("Speech and Language Processing" de Dan Jurafsky y James H. Martin, borrador de la tercera edici√≥n, disponible online) con anotaciones realizadas por el profesor.

## Pr√°cticas a entregar para este bloque

Durante las sesiones de este bloque, estudiaremos diferentes implementaciones en PyTorch de modelos neuronales para procesar textos. Para cada ejemplo de c√≥digo, excepto el √∫ltimo, has de entregar un notebook con el c√≥digo original y peque√±os bloques de texto con tus comentarios explicando el c√≥digo en base a lo que has aprendido sobre el tema y sobre PyTorch. Entrega todos los notebooks en forma de enlaces de Google Colab a trav√©s de una tutor√≠a de UACloud. Crea los cuadernos de Google Colab con tu cuenta de `gcloud.ua.es` y comp√°rtelos con la cuenta del profesor que te indicar√° en clase. Para el √∫ltimo bloque de c√≥digo (implementaci√≥n del transformer), tendr√°s que complementar el cuaderno con c√≥digo propio para realizar una tarea adicional y ajuntar un informe detallado dentro del cuaderno. El **plazo de entrega acaba el 31 de mayo de 2023** a las 23.59 horas. Las pr√°cticas se pueden hacer en parejas. Recuerda que hay un examen final de la asignatura, por lo que es muy recomendable que ambos miembros del equipo se impliquen de igual manera.

## Primera sesi√≥n (29 de marzo de 2023)

**<span style="font-size: 1.15em">Contenidos a preparar antes de la sesi√≥n del 29/03/2023</span>**

Las actividades a realizar antes de esta clase son:

- Lectura y estudio de los contenidos de [esta p√°gina](https://jaspock.github.io/me/materials/transformers/regresor) sobre regresi√≥n log√≠stica. Puedes saltar por ahora el apartado de [implementaci√≥n en PyTorch](https://jaspock.github.io/me/materials/transformers/regresor#regresores-implementados-en-pytorch), ya que ser√° el eje central de la clase presencial. Como ver√°s, la p√°gina te indica qu√© contenidos has de leer del libro. Tras una primera lectura, lee las anotaciones del profesor, cuyo prop√≥sito es ayudarte a entender los conceptos clave del cap√≠tulo. Despu√©s, realiza una segunda lectura del cap√≠tulo del libro. En total, esta parte deber√≠a llevarte unas 3 horas üïíÔ∏è de trabajo.
- Visionado y estudio de los tutoriales en v√≠deo de esta [playlist oficial de PyTorch](https://www.youtube.com/playlist?list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN).  Estudia al menos los 4 primeros v√≠deos (‚ÄúIntroduction to PyTorch‚Äù, ‚ÄúIntroduction to PyTorch Tensors‚Äù, ‚ÄúThe Fundamentals of Autograd‚Äù y ‚ÄúBuilding Models with PyTorch‚Äù). En total, esta parte deber√≠a llevarte unas 2 horas üïíÔ∏è de trabajo.
- Tras acabar con las dos partes anteriores, realiza este [test de evaluaci√≥n](https://forms.gle/E1xzZHw6hzMWJaNr7) de estos contenidos. Son pocas preguntas y te llevar√° unos minutos.

**<span style="font-size: 1.15em">Contenidos para la sesi√≥n presencial del 29/03/2023</span>**

En la clase presencial (3 horas üïíÔ∏è de duraci√≥n), repasaremos los contenidos de la semana anterior y veremos c√≥mo se implementa un regresor log√≠stico en PyTorch siguiendo la implementaci√≥n de un regresor log√≠stico binario y de uno multinomial que se comentan en [este apartado](https://jaspock.github.io/me/materials/transformers/regresor#regresores-implementados-en-pytorch).

La idea es que vayas creando una serie de notebooks en Google Colab en los que incluyas y comentes cada uno de los programas que vamos a ir viendo. En la √∫ltima clase se presentar√° una pr√°ctica m√°s avanzada que implicar√° modificar el c√≥digo del transformer.

*Nota:* por si te es de utilidad, tienes una copia del c√≥digo que veremos en este bloque en [esta carpeta de Google Drive][drivecolab] (accede con tu cuenta de `gcloud.ua.es`).

[drivecolab]: https://drive.google.com/drive/folders/1W47uSa0ddxalj9OWQIKk1mRYJ7xq6ftv?usp=sharing

## Segunda sesi√≥n (26 de abril de 2023)

Entre la sesi√≥n anterior y la del 26 de abril transcurren varias semanas, por lo que la carga de trabajo es mayor que en la sesi√≥n anterior.

**<span style="font-size: 1.15em">Contenidos a preparar antes de la sesi√≥n del 26/04/2023</span>**

Las actividades a realizar antes de esta clase son:

- Lectura y estudio de [esta p√°gina](https://jaspock.github.io/me/materials/transformers/embeddings) sobre la obtenci√≥n de embeddings incontextuales. Puedes saltar de nuevo el apartado de [implementaci√≥n en PyTorch](https://jaspock.github.io/me/materials/transformers/embeddings#implementaci√≥n-en-pytorch), ya que se estudiar√° en la pr√≥xima clase presencial. Como ver√°s, la p√°gina te indica qu√© contenidos has de leer del libro. Tras una primera lectura, lee las anotaciones del profesor, cuyo objetivo es ayudarte a entender los conceptos clave del cap√≠tulo. Despu√©s, realiza una segunda lectura del cap√≠tulo. En total, esta parte deber√≠a llevarte unas 4 horas üïíÔ∏è de trabajo.
- Lectura y estudio de [esta p√°gina](https://jaspock.github.io/me/materials/transformers/ffw) sobre las redes neuronales hacia delante. Puedes saltar tambi√©n aqu√≠ el apartado de [implementaci√≥n en PyTorch](https://jaspock.github.io/me/materials/transformers/ffw#implementaci√≥n-en-pytorch), ya que se estudiar√° tambi√©n en la pr√≥xima clase presencial. En total, esta parte deber√≠a llevarte unas 3 horas üïíÔ∏è de trabajo.
- Primeros pasos en el estudio del modelo transformer. Volveremos a dedicar m√°s horas a esta arquitectura para la pr√≥xima sesi√≥n de forma que la abordaremos en dos fases. Por ahora, lee con detenimiento la introducci√≥n a mecanismos de atenci√≥n de ["Visualizing A Neural Machine Translation Model"](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/), as√≠ como la introducci√≥n visual a los transformers de ["The Illustrated Transformer"](http://jalammar.github.io/illustrated-transformer/) y la m√°s elaborada de ["The Illustrated GPT-2"](https://jalammar.github.io/illustrated-gpt2/). A continuaci√≥n, lee el apartado 9.7 (solo este apartado) del cap√≠tulo ["Deep learning architectures for sequence processing"](https://web.archive.org/web/20221216193204/https://web.stanford.edu/~jurafsky/slp3/9.pdf); el objetivo es que entiendas conceptualmente el mecanismo de atenci√≥n de los transformers, pero no es necesario que en este momento comprendas todos los detalles t√©cnicos (especialmente las ecuaciones del modelo), ya que volver√°s a dedicarle tiempo a este cap√≠tulo m√°s adelante. En total, esta parte deber√≠a llevarte ahora unas 4 horas üïíÔ∏è de trabajo.
- Realizaci√≥n del [test de evaluaci√≥n](https://forms.gle/Eb3ZwwGxbQp88t4FA) de estos contenidos. Son pocas preguntas y te llevar√° unos minutos.

**<span style="font-size: 1.15em">Contenidos para la sesi√≥n presencial del 26/04/2023</span>**

En la clase presencial (3 horas üïíÔ∏è de duraci√≥n), repasaremos los contenidos de la semana anterior y veremos sendas implementaciones en PyTorch del algoritmo [skip-grams](https://jaspock.github.io/me/materials/transformers/embeddings#implementaci√≥n-en-pytorch) y de un modelo de lengua basado en [redes feedforward](https://jaspock.github.io/me/materials/transformers/ffw#implementaci√≥n-en-pytorch).

## Tercera sesi√≥n (10 de mayo de 2023)

**<span style="font-size: 1.15em">Contenidos a preparar antes de la sesi√≥n del 10/05/2023</span>**

Las actividades a realizar antes de esta clase son:

- Afianzar el estudio de [esta p√°gina](https://jaspock.github.io/me/materials/transformers/attention) sobre el modelo transformer y el cap√≠tulo correspondiente del libro. En realidad, ya estudiaste para la sesi√≥n anterior todos estos conceptos, pero se te pidi√≥ que no te detuvieras en exceso en los detalles t√©cnicos del libro. Ahora, es el momento de que vuelvas a leerlo con m√°s calma y consultes tambi√©n las anotaciones del profesor que hay en la p√°gina web. Puedes saltar de nuevo el apartado de [implementaci√≥n en PyTorch][guiamingpt], ya que se estudiar√° en la pr√≥xima clase presencial. En total, esta parte deber√≠a llevarte unas 4 horas üïíÔ∏è de trabajo.
- Visualizar el [v√≠deo][vidkarpathy] que introduce las ideas principales de la implementaci√≥n del transformer que estudiaremos en la clase presencial. Pausa el v√≠deo y vuelve atr√°s cuando sea necesario para entender los conceptos clave. En total, esta parte deber√≠a llevarte unas 2 horas üïíÔ∏è de trabajo.

[vidkarpathy]: https://youtu.be/kCc8FmEb1nY
[guiamingpt]: https://jaspock.github.io/me/materials/transformers/attention#implementaci√≥n-en-pytorch

**<span style="font-size: 1.15em">Contenidos para la sesi√≥n del 10/05/2023</span>**

En la clase presencial (3 horas üïíÔ∏è de duraci√≥n), repasaremos los contenidos de la semana anterior y veremos c√≥mo se [implementa el modelo transformer en PyTorch](https://jaspock.github.io/me/materials/transformers/attention#implementaci√≥n-en-pytorch). En esta clase, adem√°s, se presentar√° la parte final de la pr√°ctica a realizar en base al c√≥digo del transformer.

Del c√≥digo del transformer solo has de comentar en un cuaderno las clases `CausalSelfAttention` y `Block`, as√≠ como los m√©todos `forward`, `generate`, `__init__`, `_init_weights` y `get_default_config` de la clase `GPT`. Puedes a√±adir un peque√±o c√≥digo que use las clases del modelo. Haz la pr√°ctica final que se menciona a continuaci√≥n en un cuaderno diferente.

**<span style="font-size: 1.15em">Contenidos pr√°cticos a trabajar tras la sesi√≥n</span>**

Tras la sesi√≥n, ya puedes ponerte a trabajar en la pr√°ctica de desarrollo a realizar para este bloque y de la cual saldr√° la mayor parte de la nota del bloque (un 90% aproximadamente). Se espera que dediques a ella unas 11 horas üïíÔ∏è de trabajo. La pr√°ctica se basa en modificar ligeramente el c√≥digo de [minGPT][guiamingpt] para poder realizar experimentos de interpretabilidad mecanicista. El enunciado completo est√° en el siguiente apartado.

## Pr√°ctica sobre interpretabilidad mecanicista de transformers

La *interpretabilidad mecanicista* en el contexto de la inteligencia artificial intenta dar una explicaci√≥n motivada del funcionamiento de los modelos de aprendizaje autom√°tico. Es una propuesta muy importante de cara a generar confianza en los sistemas e inducir ciertos comportamientos en ellos. Dentro del campo de la interpretabilidad mecanicista existen un buen n√∫mero de t√©cnicas que se pueden aplicar a los transformers. Aqu√≠ nos centraremos en el [parcheado de activaciones][patching].

[patching]: https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx

El parcheado de activaciones *interviene* en una activaci√≥n espec√≠fica de un modelo mediante la sustituci√≥n de una activaci√≥n *corrompida* con una activaci√≥n *limpia*. Se mide entonces c√≥mo afecta el cambio a la salida del modelo. Esto nos permite identificar qu√© activaciones son importantes para el resultado del modelo y localizar posibles causas de errores en la predicci√≥n. 

En nuestro caso particular, vas a escribir c√≥digo que ejecute la versi√≥n m√°s peque√±a de GPT2 (usa la cadena `gpt2` en el c√≥digo) con dos entradas diferentes: dos textos que solo se diferencien en un √∫nico token. La idea es que al proporcionar al modelo la entrada corrompida, intervendremos en el embedding tras una cierta capa (uno solo cada vez) y lo parchearemos con el embedding correspondiente de la ejecuci√≥n limpia. Luego mediremos cu√°nto cambia la predicci√≥n del siguiente token respecto a la ejecuci√≥n limpia. Si el cambio es significativo, entonces podemos estar seguros de que la activaci√≥n que hemos alterado es importante para la predicci√≥n. Este proceso de parcheado lo realizaremos para cada capa del modelo y para cada token de la entrada. Con toda esta informaci√≥n, obtendremos una gr√°fica y sacaremos conclusiones. Por motivos que entender√°s en un momento, los dos textos han de tener el mismo n√∫mero de tokens.

**<span style="font-size: 1.15em">Ejemplo de an√°lisis</span>**

Daremos un ejemplo para que se entienda mejor. Considera el siguiente texto de entrada: "Michelle Jones was a top-notch student. Michelle". Si se lo damos a GPT2 y estudiamos la probabilidad emitida por el modelo para el token que sigue a la segunda aparici√≥n de Michelle, obtendremos lo siguiente (solo se muestran los 20 tokens m√°s probables): 

```{list-table}
:header-rows: 1

* - Position
  - Token index
  - Token
  - Probability
* - 1
  - 373
  - was
  - 0.1634
* - 2
  - 5437
  - Jones
  - 0.1396
* - 3
  - 338
  - 's
  - 0.0806
* - 4
  - 550
  - had
  - 0.0491
* - 5
  - 318
  - is
  - 0.0229
* - 6
  - 290
  - and
  - 0.0227
* - 7
  - 11
  - ,
  - 0.0222
* - 8
  - 531
  - said
  - 0.0134
* - 9
  - 468
  - has
  - 0.0120
* - 10
  - 635
  - also
  - 0.0117
* - 11
  - 1625
  - came
  - 0.0091
* - 12
  - 1297
  - told
  - 0.0084
* - 13
  - 1422
  - didn
  - 0.0070
* - 14
  - 2993
  - knew
  - 0.0067
* - 15
  - 1816
  - went
  - 0.0061
* - 16
  - 561
  - would
  - 0.0061
* - 17
  - 3111
  - worked
  - 0.0055
* - 18
  - 750
  - did
  - 0.0054
* - 19
  - 2486
  - Obama
  - 0.0053
* - 20
  - 2492
  - wasn
  - 0.0050

```

Como era de esperar, el token "Jones" tiene una probabilidad notablemente elevada. Ahora, considera la entrada corrompida "Michelle Smith was a top-notch student. Michelle". Si le damos esta entrada a GPT2, esperamos que la probabilidad de "Jones" a como continuaci√≥n del texto sea mucho menor que antes y que la de "Smith" sea mucho mayor, lo que (puedes comprobarlo) efectivamente ocurre. Pero queremos ir m√°s all√° y saber qu√© embeddings son los que m√°s influyen en esta diferencia. Dado que ambas entradas tienen 11 tokens (m√°s adelante explicaremos c√≥mo averiguarlo) y que el transformer del modelo GPT2 peque√±o tiene 12 capas, si nos centramos en los embeddings que se obtienen a la salida de cada capa, podemos parchear 11√ó12 = 132 embeddings diferentes. Calcularemos, por tanto, 132 veces la diferencia entre el logit de "Smith" y el logit de "Jones" en la salida del √∫ltimo token de la entrada ("Michelle") en el modelo corrompido. Observa que tambi√©n podr√≠amos calcular las diferencias tras aplicar la funci√≥n softmax, pero en este caso no lo haremos.

Una representaci√≥n en forma de mapa de calor del resultado es la siguiente:

```{figure} images/mechanistic-michelle.png
---
height: 540px
name: fig-mech
---
```

Recuerda que en un gr√°fico como el anterior, debido a la m√°scara de atenci√≥n y a la disposici√≥n de las capas, la informaci√≥n fluye de izquierda a derecha y de arriba a abajo. Puedes ver c√≥mo intervenir en la primera columna no tiene efectos en la predicci√≥n del siguiente token, lo que tiene todo el sentido, ya que los embeddings que se parchean tienen exactamente los mismos valores en el modelo limpio y en el corrompido, ya que el contexto anterior es el mismo. Tampoco parece haber cambios al parchear los embeddings de la tercera a la antepen√∫ltima columna. Sin embargo, observa c√≥mo al intervenir los embeddings de muchas capas del segundo token, la predicci√≥n se decanta hacia "Jones" (el color se hace oscuro cuando la diferencia entre el logit de "Smith" y el de "Jones" se va haciendo negativa porque "Jones" tiene un logit mayor). Modificar los embeddings de las √∫ltimas capas del segundo token tiene efectos mucho menores, ya que el embedding apenas puede influir en el futuro de la secuencia. En la √∫ltima posici√≥n ("Michelle") se observa que los embeddings de las capas finales van anticip√°ndose al token que tienen que predecir.

Algunos textos corrompidos adicionales que puede ser interesante explorar son, por ejemplo, "Jessica Jones was a top-notch student. Michelle" o "Michelle Smith was a top-notch student. Jessica".

En esta pr√°ctica se trata de que programes el c√≥digo que te permite obtener gr√°ficas y probabilidades como las anteriores, propongas tus propios textos limpios y corrompidos (intenta tirar de creatividad y no estudiar textos o fen√≥menos muy similares), realices un an√°lisis parecido al anterior y escribas un informe dentro de un cuaderno de Python de unas 1500-2000 palabras en el que presentes y comentes el c√≥digo que has implementado, adem√°s de presentar tu enfoque, los resultados y las conclusiones pertinentes. Ser√°n bienvenidas las ideas originales y los experimentos adicionales que se te ocurran.

**<span style="font-size: 1.15em">Tokenization</span>**

El modelo GPT2 usa un tokenizador basado en BPE que trocea el texto de entrada en palabras o en unidades inferiores dependiendo de su frecuencia. El c√≥digo de minGPT permite descargar dicho tokenizador y usarlo para segmentar los textos. El siguiente c√≥digo muestra c√≥mo tokenizar un texto para obtener sus √≠ndices y viceversa.

```python
from mingpt.bpe import BPETokenizer

input = "Michelle Jones was a top-notch student. Michelle"
print("Input:", input)
bpe = BPETokenizer()
# bpe() gets a string and returns a 2D batch tensor 
# of indices with shape (1, input_length)
tokens = bpe(input)[0]
print("Tokenized input:", tokens)
input_length = tokens.shape[-1]
print("Number of input tokens:", input_length)
# bpe.decode gets a 1D tensor (list of indices) and returns a string
print("Detokenized input from indices:", bpe.decode(tokens))  
tokens_str = [bpe.decode(torch.tensor([token])) for token in tokens]
print("Detokenized input as strings: " + '/'.join(tokens_str))
```

**<span style="font-size: 1.15em">Detalles de implementaci√≥n</span>**

Lo siguiente son algunos detalles de implementaci√≥n que te pueden ser √∫tiles, pero que no es necesario que sigas. 

Para conseguir un c√≥digo que te permita realizar el parcheado de activaciones te tendr√°s que centrar en los ficheros `mingpt/model.py` y `generate.ipynb`. Si trabajas en local sin usar un *notebook* (recomendado) copia el c√≥digo de `generate.ipynb` en un fichero `generate.py` que puedas ejecutar desde la l√≠nea de √≥rdenes.

Puedes trabajar directamente en una sesi√≥n de Google Colab. Aqu√≠ tienes un [proyecto][proyectocolab] (accede con tu cuenta de `gcloud.ua.es`) con instrucciones sobre c√≥mo usarlo para desarrollar. Sin embargo, es mucho m√°s c√≥modo desarrollar en local (entre otras cosas, puedes trabajar con un mejor editor de texto que el de Colab y tambi√©n depurar). Incluso si no tienes una GPU, el c√≥digo funciona sin problemas sobre CPU y solo tarda unos segundos m√°s que sobre GPU al solo trabajar con un texto y con un modelo no excesivamente grande. Cuando tengas el c√≥digo final, puedes subirlo a un notebook para su entrega.

A√±ade a la funci√≥n `forward` del transformer, c√≥digo que permita salvar (seg√∫n el valor de cierto *flag* booleano recibido como par√°metro) en una variable de instancia las activaciones de cada capa y cada posici√≥n. Recuerda hacer una copia profunda de los embeddings y no guardar √∫nicamente una referencia que puede ser sobreescrita posteriormente; para ello, consulta la secuencia de llamadas `.detach().clone()` de PyTorch. A√±ade tambi√©n c√≥digo que permita (de nuevo en base a un par√°metro booleano) parchear el embedding de una capa y posici√≥n concretas. 

A√±ade tambi√©n a la funci√≥n `forward` c√≥digo que guarde los logits del √∫ltimo token, que contienen la informaci√≥n que nos interesa sobre la predicci√≥n del siguiente token. Puedes guardar esta informaci√≥n en un atributo que luego puedes acceder desde el exterior de la clase. Observa que solo te interesa el vector correspondiente al √∫ltimo token.

A√±ade c√≥digo al fichero `generate.py` que divida el texto limpio en tokens, lo pase por el modelo a trav√©s de la funci√≥n `generate` (pidi√©ndole al modelo que guarde los embeddings intermedios) y muestre las continuaciones m√°s probables a partir de los logits del √∫ltimo token. Ten en cuenta que si quieres saber la probabilidad de una continuaci√≥n como el token "Jones", por ejemplo, has de buscar el √≠ndice de dicho token en el vocabulario anteponi√©ndole un espacio en blanco (`index = bpe(' Jones')`). Esto es as√≠ porque el segmentador de BPE trata de forma diferente los tokens que aparecen al principio de la secuencia y los que aparecen en medio. Una vez tengas el √≠ndice del token, puedes acceder a la posici√≥n correspondiente del vector de logits y obtener la probabilidad no normalizada de que sea la continuaci√≥n.

Despu√©s, puedes trabajar con el texto corrupto. Incluye un doble bucle que itere sobre todas las capas y todas las posiciones y llame cada vez a `generate` pas√°ndole la capa y la posici√≥n en la que realizar la intervenci√≥n. En cada paso, eval√∫a la diferencia de logits oportuna y gu√°rdala en una matriz de diferencias.

Usa finalmente la funci√≥n `matshow` de `matplotlib` para visualizar la matriz de diferencias.

[proyectocolab]: https://colab.research.google.com/drive/1dq2EClvIbEtoEnHWoAXZQTArJDHivQly?usp=sharing

**<span style="font-size: 1.15em">Una explicaci√≥n m√°s informal</span>**

La siguiente explicaci√≥n informal puede que te ayude a entender mejor el objetivo de la pr√°ctica.

Considera para simplificar la frase "a b c" y la versi√≥n corrompida "d e f". En general, habr√° muchos m√°s tokens en com√∫n, pero as√≠ queda todo m√°s claro en la siguiente discusi√≥n. Considera que el modelo neuronal basado en el transformer tiene 5 capas de atenci√≥n. Considera que vamos a estudiar qu√© embeddings son importantes para la predicci√≥n de que tras estas frases vaya el token "X".

Se trata primero de que permitas que en la funci√≥n forward del transformer (clase `GPT`) se puedan guardar (por ejemplo en una lista de listas de tensores) los 3x5=15 embeddings que se generan a la salida de cada una de las capas cuando se procesa la frase "a b c". En el enunciado se dan algunos detalles porque no puedes guardar simplemente la referencia a los tensores, ya que se modificar√°n la pr√≥xima vez que llames a forward, sino que has de clonar los tensores (lo que se llama "copia defensiva"). Con esto tendr√°s almacenados los 15 tensores (embeddings) de la frase limpia.

Gu√°rdate tambi√©n los logits tras la √∫ltima capa. En particular, solo necesitar√°s los de la √∫ltima posici√≥n (es decir, los logits correspondientes al token "c"), que te dan una medida de la probabilidad del siguiente token, es decir, del token que ir√° tras "c". Recuerda que estos logits no son realmente probabilidades (son valores como -11.1, -0.5, 0.78, o 2.32323) porque no se les ha aplicado la funci√≥n softmax, pero trabajar con ellos es m√°s c√≥modo que trabajar con las probabilidades porque tenemos valores con un rango m√°s amplio. No obstante, el estudio podr√≠a hacerse igualmente con probabilidades estrictas. En realidad, ni siquiera necesitas guardarte todos los logits, sino solo el escalar que corresponde al token "X" porque es lo √∫nico que usar√°s despu√©s.

Ahora le das al modelo la versi√≥n corrompida "d e f", indic√°ndole que no sobreescriba la copia de los embeddings que obtuvimos con la frase limpia. La frase corrompida ha de tener el mismo n√∫mero de tokens que la limpia para que la siguiente discusi√≥n tenga sentido. La idea es modificar uno solo de los 15 embeddings que se producen mientras se procesa la frase sucia. Si, por ejemplo, nos centramos en el embedding del primer token ("d") tras la primera capa, se tratar√≠a de que el c√≥digo de la funci√≥n forward opere "casi" de la forma normal, pero cuando se obtenga la salida de la primera capa y antes de pasarla como entrada a la segunda capa, se ha de modificar el embedding correspondiente a la primera palabra (solo ese) y sustituirlo por el embedding correspondiente (de la misma capa y posici√≥n) que te guardaste para la frase limpia (es decir, en este caso, ser√≠a el embedding que te guardaste tras la primera capa para el token "a"). Con esto, la segunda capa recibir√° como entrada el embedding que se gener√≥ para "a" en lugar del de "d".

Tras intervenir en el embedding de la posici√≥n 1 tras la capa 1, el resto del modelo trabaja sin ning√∫n "contratiempo". De la misma manera que antes, ahora miramos los logits de la predicci√≥n del token que va tras el √∫ltimo token de la frase corrompida (es decir, "f"). Y nos centramos en el valor del logit de la predicci√≥n del token "X". La diferencia entre este valor y el que nos guardamos para la frase limpia nos da una idea de c√≥mo de relevante es el embedding de la capa 1 y posici√≥n 1 en la predicci√≥n del token "X". En el enunciado se muestra c√≥mo algunos embeddings son mucho m√°s relevantes que otros. Y t√∫ tienes que hacer un estudio similar con diferentes frases.

Si repites la operaci√≥n anterior con los otros 14 embeddings (llamando 14 veces m√°s a la funci√≥n forward), terminar√°s teniendo 15 diferencias de logits (15 valores escalares) que puedes representar en un mapa de calor de 3x5 como se ve m√°s arriba.

Finalmente, ten en cuenta que la discusi√≥n de este apartado tiene una peque√±a simplificaci√≥n respecto a lo que se pide en el enunciado de m√°s arriba. All√≠ se propon√≠a calcular la diferencia entre el logit de "Smith" y el logit de "Jones" en la salida del √∫ltimo token en el modelo corrompido, lo que da un poco m√°s de informaci√≥n que la diferencia que hemos explicado en este apartado, es decir, la diferencia entre la predicci√≥n de un solo token ("Jones") en la frase limpia y la corrompida, en lugar de dos tokens en la frase corrompida. En realidad, cualquiera de las dos opciones es v√°lida para llegar a las conclusiones que nos interesan: que en la frase corrompida, el logit de "Jones" se hace mucho menor excepto para ciertas intervenciones. Si quieres que tu mapa de calor coincida con el de este enunciado, sigue el enfoque basado en los dos tokens "Jones" y "Smith".

**<span style="font-size: 1.15em">Ampliar conocimientos</span>**

Lo anterior es solo uno de los m√∫ltiples an√°lisis que se han propuesto dentro de la interpretabilidad mecanicista. Para esta pr√°ctica no se espera que vayas m√°s all√° de esto, pero si te interesa conocer un par de an√°lisis m√°s puedes consultar [este tutorial][lines50]. Observa que aunque el tutorial usa una librer√≠a para parchear las activaciones, en esta pr√°ctica no puedes usar ninguna librer√≠a para ello y lo has de hacer directamente sobre el c√≥digo de minGPT. Una revisi√≥n mucho m√°s detallada sobre la interpretabilidad mecanicista se puede encontrar en [este trabajo][nanda] de Neel Nanda.

[lines50]: https://www.lesswrong.com/posts/hnzHrdqn3nrjveayv/how-to-transformer-mechanistic-interpretability-in-50-lines
[nanda]: https://www.neelnanda.io/mechanistic-interpretability/glossary
