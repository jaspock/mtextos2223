
Otras técnicas para la minería de textos
========================================

## Modelos multilingües

Para estudiar los modelos que explotan el entrenamiento y la transferencia multilingües seguiremos las diapositivas "[Multilingual][multilingual] training and cross-lingual transfer" preparadas por Xinyi Wang para el curso CMU [CS11-737][cs11737], "Multilingual Natural Language Processing", de la Carnegie Mellon University.

[multilingual]: http://demo.clab.cs.cmu.edu/11737fa20/slides/multiling-10-multilingual_training.pdf
[cs11737]: http://demo.clab.cs.cmu.edu/11737fa20/

## Visualización

- "Interfaces for [explaining][explaining] transformer language models" de Jay Alammar.
- La herramienta [LIT][lit] (Language Interpretability Tool) permite estudiar en línea las [predicciones de BERT][bert] para las palabras enmascaradas.

[explaining]: https://jalammar.github.io/explaining-transformers/?s=03
[lit]: https://pair-code.github.io/lit/demos/
[bert]: https://pair-code.github.io/lit/demos/lm.html

## Avances recientes

El investigador Sebastian Ruder suele escribir en su [página web][ruder] un resumen de los avances anuales más destacados en el área del procesamiento del lenguaje natural. 

- "ML and NLP research highlights of [2020][2020]"
- "10 ML & NLP research highlights of [2019][2019]"
- "10 exciting ideas of [2018][2018] in NLP"
- "Recent advances in language model [fine-tuning][fine]"

[ruder]: https://ruder.io/
[2020]: https://ruder.io/research-highlights-2020/
[2019]: https://ruder.io/research-highlights-2019/
[2018]: https://ruder.io/10-exciting-ideas-of-2018-in-nlp/
[fine]: https://ruder.io/recent-advances-lm-fine-tuning/

## Ética

Artículo "On the dangers of stochastic [parrots][parrots]: can language models be too big?" de Emily Bender et al.

[parrots]: http://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf

## El raspado web

Introducción al [raspado web][raspado] con Python por Robin Andrews.

[raspado]: https://www.codementor.io/@info658/introduction-to-web-scraping-with-python-1g1eb3pw9y

