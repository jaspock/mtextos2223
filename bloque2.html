
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>22. Técnicas para la minería de textos &#8212; Minería de Textos</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/estilos.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="23. Content in Jupyter Book" href="content.html" />
    <link rel="prev" title="21. Ev. Evaluación de prácticas del Bloque 2" href="bloque3_ev.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-master-ca.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Minería de Textos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Materiales de Minería de Textos
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 1
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1.html">
   1. Introducción a la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_1Introduccion.html">
   2. Minería de textos y procesamiento del lenguaje natural.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_2CategorialSintactico.html">
   3. Análisis categorial y sintáctico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica1.html">
   4. Práctica 1a: PLN con SpaCy.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_3AnalisisSemantico.html">
   5. Análisis semántico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_4AnalisisSemanticoVectorial.html">
   6. Análisis semántico vectorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica2.html">
   7. Práctica 1b :
   <em>
    Topic modeling
   </em>
   .
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 2
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3.html">
   8. Aplicaciones de la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t1_aplicaciones.html">
   9. T1. Aplicaciones generales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t2_subaplicaciones-benchmarks.html">
   10. T2. Aplicaciones específicas y Benchmacks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t2.1_analisis_sentimientos.html">
   11. T2.1. Aplicaciones específicas. Análisis de Sentimientos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t3.1_metricas.html">
   12. T3. Métricas de Evaluación
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t4_centralizacion.html">
   13. T4. Centralización de datasets y modelos: Huggingface, OpenAI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t5_automl.html">
   14. T5. Auto Machine Learning(AutoML)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t5.1_autogoal.html">
   15. T5.1. AutoGOAL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p1_SA-Pipeline-Reviews.html">
   16. P1.1. Pipeline simple
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p2_SA-Transformers-Basic.html">
   17. P1.2. APIs Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p3_SA-Transformers-Training-FineTuning.html">
   18. P2. Reajustar modelos Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p4_SA-Transformers-Training-Custom.html">
   19. P3. Composición de vectores de características
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p5-SA-Ensemble.html">
   20. P4. Ensemble de pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_ev.html">
   21. Ev. Evaluación de prácticas del Bloque 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 3
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   22. Técnicas para la minería de textos
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Extras
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="content.html">
   23. Content in Jupyter Book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   24. Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   25. Content with notebooks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/bloque2.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#practica-a-entregar-para-este-bloque">
   22.1. Práctica a entregar para este bloque
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#primera-sesion-29-de-marzo-de-2023">
   22.2. Primera sesión (29 de marzo de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#segunda-sesion-26-de-abril-de-2023">
   22.3. Segunda sesión (26 de abril de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tercera-sesion-10-de-mayo-de-2023">
   22.4. Tercera sesión (10 de mayo de 2023)
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Técnicas para la minería de textos</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#practica-a-entregar-para-este-bloque">
   22.1. Práctica a entregar para este bloque
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#primera-sesion-29-de-marzo-de-2023">
   22.2. Primera sesión (29 de marzo de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#segunda-sesion-26-de-abril-de-2023">
   22.3. Segunda sesión (26 de abril de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tercera-sesion-10-de-mayo-de-2023">
   22.4. Tercera sesión (10 de mayo de 2023)
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="tecnicas-para-la-mineria-de-textos">
<span id="label-tecnicas"></span><h1><span class="section-number">22. </span>Técnicas para la minería de textos<a class="headerlink" href="#tecnicas-para-la-mineria-de-textos" title="Permalink to this headline">#</a></h1>
<p>En este bloque se aborda el estudio de algunos modelos neuronales utilizados para procesar textos. El profesor de este bloque es Juan Antonio Pérez Ortiz. El bloque comienza con un repaso del funcionamiento del regresor logístico, que nos servirá para asentar los conocimientos necesarios para entender posteriores modelos. A continuación se estudia con cierto nivel de detalle <em>skip-grams</em>, uno de los algoritmos para la obtención de <em>embeddings</em> incontextuales de palabras. Después se repasa el funcionamiento de las arquitecturas neuronales <em>feedforward</em> y se estudia su aplicación a modelos de lengua. El objetivo último es abordar el estudio de la arquitectura más importante de los sistemas actuales de procesamiento de textos: el transformer. Una vez estudiadas estas arquitecturas, finalizaremos con un análisis del funcionamiento de los modelos preentrenados.</p>
<p>Los materiales de clase complementan la lectura de algunos capítulos de un libro de texto (“Speech and Language Processing” de Dan Jurafsky y James H. Martin, borrador de la tercera edición, disponible online) con anotaciones realizadas por el profesor.</p>
<section id="practica-a-entregar-para-este-bloque">
<h2><span class="section-number">22.1. </span>Práctica a entregar para este bloque<a class="headerlink" href="#practica-a-entregar-para-este-bloque" title="Permalink to this headline">#</a></h2>
<p>Durante las sesiones de este bloque, estudiaremos diferentes implementaciones en PyTorch de modelos neuronales para procesar textos. Para cada ejemplo de código, excepto el último, has de entregar un notebook con el código original y bloques de texto con tus comentarios explicando el código en base a lo que has aprendido sobre el tema y sobre PyTorch. Entrega todos los notebooks en forma de enlaces de Google Colab a través de una tutoría de UACloud. Crea los cuadernos de Google Colab con tu cuenta de <code class="docutils literal notranslate"><span class="pre">gcloud.ua.es</span></code> y compártelos con la cuenta del profesor que te indicará en clase. Para el último bloque de código (implementación del transformer), tendrás que complementar el cuaderno con código propio para realizar una tarea adicional que será convenientemente anunciada. El plazo de entrega acaba el 26 de mayo de 2023 a las 23.59 horas.</p>
</section>
<section id="primera-sesion-29-de-marzo-de-2023">
<h2><span class="section-number">22.2. </span>Primera sesión (29 de marzo de 2023)<a class="headerlink" href="#primera-sesion-29-de-marzo-de-2023" title="Permalink to this headline">#</a></h2>
<p><strong>Contenidos a preparar antes de la sesión del 29/03/2023</strong></p>
<p>Las actividades a realizar antes de esta clase son:</p>
<ul class="simple">
<li><p>Lectura y estudio de los contenidos de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/regresor">esta página</a> sobre regresión logística. Puedes saltar por ahora el apartado de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/regresor#regresores-implementados-en-pytorch">implementación en PyTorch</a>, ya que será el eje central de la clase presencial. Como verás, la página te indica qué contenidos has de leer del libro. Tras una primera lectura, lee las anotaciones del profesor, cuyo propósito es ayudarte a entender los conceptos clave del capítulo. Después, realiza una segunda lectura del capítulo del libro. En total, esta parte debería llevarte unas 3 horas 🕒️ de trabajo.</p></li>
<li><p>Visionado y estudio de los tutoriales en vídeo de esta <a class="reference external" href="https://www.youtube.com/playlist?list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN">playlist oficial de PyTorch</a>.  Estudia al menos los 4 primeros vídeos (“Introduction to PyTorch”, “Introduction to PyTorch Tensors”, “The Fundamentals of Autograd” y “Building Models with PyTorch”). En total, esta parte debería llevarte unas 2 horas 🕒️ de trabajo.</p></li>
<li><p>Tras acabar con las dos partes anteriores, realiza este <a class="reference external" href="https://forms.gle/E1xzZHw6hzMWJaNr7">test de evaluación</a> de estos contenidos. Son pocas preguntas y te llevará unos minutos.</p></li>
</ul>
<p><strong>Contenidos para la sesión presencial del 29/03/2023</strong></p>
<p>En la clase presencial, repasaremos los contenidos de la semana anterior y veremos cómo se implementa el regresor logístico en PyTorch siguiendo la implementación de un regresor logístico binario y de uno multinomial que se comentan en <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/regresor#regresores-implementados-en-pytorch">este apartado</a>.</p>
<p>La idea es que vayas creando una serie de notebooks en Google Colab en los que incluyas y comentes cada uno de los programas que vamos a ir viendo. En la última clase se presentará una práctica más avanzada que implicará modificar el código del transformer.</p>
</section>
<section id="segunda-sesion-26-de-abril-de-2023">
<h2><span class="section-number">22.3. </span>Segunda sesión (26 de abril de 2023)<a class="headerlink" href="#segunda-sesion-26-de-abril-de-2023" title="Permalink to this headline">#</a></h2>
<p>Entre la sesión anterior y la del 26 de abril transcurren varias semanas, por lo que la carga de trabajo es mayor que en la sesión anterior.</p>
<p><strong><span style="font-size: 1.1em">Contenidos a preparar antes de la sesión del 26/04/2023</span></strong></p>
<p>Las actividades a realizar antes de esta clase son:</p>
<ul class="simple">
<li><p>Lectura y estudio de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/embeddings">esta página</a> sobre la obtención de embeddings incontextuales. Puedes saltar de nuevo el apartado de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/embeddings#implementaci%C3%B3n-en-pytorch">implementación en PyTorch</a>, ya que se estudiará en la próxima clase presencial. Como verás, la página te indica qué contenidos has de leer del libro. Tras una primera lectura, lee las anotaciones del profesor, cuyo objetivo es ayudarte a entender los conceptos clave del capítulo. Después, realiza una segunda lectura del capítulo. En total, esta parte debería llevarte unas 4 horas 🕒️ de trabajo.</p></li>
<li><p>Lectura y estudio de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/ffw">esta página</a> sobre las redes neuronales hacia delante. Puedes saltar de nuevo el apartado de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/ffw#implementaci%C3%B3n-en-pytorch">implementación en PyTorch</a>, ya que se estudiará también en la próxima clase presencial. En total, esta parte debería llevarte unas 3 horas 🕒️ de trabajo.</p></li>
<li><p>Primeros pasos en el estudio del modelo transformer. Volveremos a dedicar más horas a esta arquitectura para la próxima sesión de forma que la abordaremos en dos fases. Por ahora, lee con detenimiento la introducción a mecanismos de atención de <a class="reference external" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">“Visualizing A Neural Machine Translation Model”</a>, así como la introducción visual a los transformers de <a class="reference external" href="http://jalammar.github.io/illustrated-transformer/">“The Illustrated Transformer”</a>. A continuación, lee el apartado 9.7 (solo este apartado) del capítulo <a class="reference external" href="https://web.archive.org/web/20221216193204/https://web.stanford.edu/~jurafsky/slp3/9.pdf">“Deep learning architectures for sequence processing”</a>; el objetivo es que entiendas conceptualmente el mecanismo de atención de los transformers, pero no es necesario que en este momento comprendas todos los detalles técnicos (especialmente las ecuaciones del modelo), ya que volverás a dedicarle tiempo a este capítulo más adelante. En total, esta parte debería llevarte ahora unas 4 horas 🕒️ de trabajo.</p></li>
<li><p>Realización del <a class="reference external" href="https://forms.gle/Eb3ZwwGxbQp88t4FA">test de evaluación</a> de estos contenidos. Son pocas preguntas y te llevará unos minutos.</p></li>
</ul>
<p><strong>Contenidos para la sesión presencial del 26/04/2023</strong></p>
<p>En la clase presencial, repasaremos los contenidos de la semana anterior y veremos sendas implementaciones en PyTorch del algoritmo <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/embeddings#implementaci%C3%B3n-en-pytorch">skip-grams</a> y de un modelo de lengua basado en <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/ffw#implementaci%C3%B3n-en-pytorch">redes feedforward</a>.</p>
</section>
<section id="tercera-sesion-10-de-mayo-de-2023">
<h2><span class="section-number">22.4. </span>Tercera sesión (10 de mayo de 2023)<a class="headerlink" href="#tercera-sesion-10-de-mayo-de-2023" title="Permalink to this headline">#</a></h2>
<p><strong>Contenidos a preparar antes de la sesión del 10/05/2023</strong></p>
<p><strong>Contenidos para la sesión del 10/05/2023</strong></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="bloque3_ev.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">21. </span>Ev. Evaluación de prácticas del Bloque 2</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="content.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">23. </span>Content in Jupyter Book</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Universitat d'Alacant<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>