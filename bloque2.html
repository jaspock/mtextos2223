
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>22. T√©cnicas para la miner√≠a de textos &#8212; Miner√≠a de Textos</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/estilos.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="23. Content in Jupyter Book" href="content.html" />
    <link rel="prev" title="21. Ev. Evaluaci√≥n de pr√°cticas del Bloque 2" href="bloque3_ev.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-master-ca.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Miner√≠a de Textos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Materiales de Miner√≠a de Textos
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 1
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1.html">
   1. Introducci√≥n a la miner√≠a de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_1Introduccion.html">
   2. Miner√≠a de textos y procesamiento del lenguaje natural.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_2CategorialSintactico.html">
   3. An√°lisis categorial y sint√°ctico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica1.html">
   4. Pr√°ctica 1a: PLN con SpaCy.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_3AnalisisSemantico.html">
   5. An√°lisis sem√°ntico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_4AnalisisSemanticoVectorial.html">
   6. An√°lisis sem√°ntico vectorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica2.html">
   7. Pr√°ctica 1b :
   <em>
    Topic modeling
   </em>
   .
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 2
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3.html">
   8. Aplicaciones de la miner√≠a de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t1_aplicaciones.html">
   9. T1. Aplicaciones generales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t2_subaplicaciones-benchmarks.html">
   10. T2. Aplicaciones espec√≠ficas y Benchmacks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t2.1_analisis_sentimientos.html">
   11. T2.1. Aplicaciones espec√≠ficas. An√°lisis de Sentimientos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t3.1_metricas.html">
   12. T3. M√©tricas de Evaluaci√≥n
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t4_centralizacion.html">
   13. T4. Centralizaci√≥n de datasets y modelos: Huggingface, OpenAI
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t5_automl.html">
   14. T5. Auto Machine Learning(AutoML)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t5.1_autogoal.html">
   15. T5.1. AutoGOAL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p1_SA-Pipeline-Reviews.html">
   16. P1.1. Pipeline simple
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p2_SA-Transformers-Basic.html">
   17. P1.2. APIs Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p3_SA-Transformers-Training-FineTuning.html">
   18. P2. Reajustar modelos Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p4_SA-Transformers-Training-Custom.html">
   19. P3. Composici√≥n de vectores de caracter√≠sticas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p5-SA-Ensemble.html">
   20. P4. Ensemble de pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_ev.html">
   21. Ev. Evaluaci√≥n de pr√°cticas del Bloque 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 3
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   22. T√©cnicas para la miner√≠a de textos
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Extras
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="content.html">
   23. Content in Jupyter Book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   24. Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   25. Content with notebooks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/bloque2.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#practicas-a-entregar-para-este-bloque">
   22.1. Pr√°cticas a entregar para este bloque
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#primera-sesion-29-de-marzo-de-2023">
   22.2. Primera sesi√≥n (29 de marzo de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#segunda-sesion-26-de-abril-de-2023">
   22.3. Segunda sesi√≥n (26 de abril de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tercera-sesion-10-de-mayo-de-2023">
   22.4. Tercera sesi√≥n (10 de mayo de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#practica-sobre-interpretabilidad-mecanicista-de-transformers">
   22.5. Pr√°ctica sobre interpretabilidad mecanicista de transformers
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>T√©cnicas para la miner√≠a de textos</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#practicas-a-entregar-para-este-bloque">
   22.1. Pr√°cticas a entregar para este bloque
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#primera-sesion-29-de-marzo-de-2023">
   22.2. Primera sesi√≥n (29 de marzo de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#segunda-sesion-26-de-abril-de-2023">
   22.3. Segunda sesi√≥n (26 de abril de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tercera-sesion-10-de-mayo-de-2023">
   22.4. Tercera sesi√≥n (10 de mayo de 2023)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#practica-sobre-interpretabilidad-mecanicista-de-transformers">
   22.5. Pr√°ctica sobre interpretabilidad mecanicista de transformers
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="tecnicas-para-la-mineria-de-textos">
<span id="label-tecnicas"></span><h1><span class="section-number">22. </span>T√©cnicas para la miner√≠a de textos<a class="headerlink" href="#tecnicas-para-la-mineria-de-textos" title="Permalink to this headline">#</a></h1>
<p>En este bloque se aborda el estudio de algunos modelos neuronales utilizados para procesar textos. El profesor de este bloque es Juan Antonio P√©rez Ortiz. El bloque comienza con un repaso del funcionamiento del regresor log√≠stico, que nos servir√° para asentar los conocimientos necesarios para entender posteriores modelos. A continuaci√≥n se estudia con cierto nivel de detalle <em>skip-grams</em>, uno de los algoritmos para la obtenci√≥n de <em>embeddings</em> incontextuales de palabras. Despu√©s se repasa el funcionamiento de las arquitecturas neuronales <em>feedforward</em> y se estudia su aplicaci√≥n a modelos de lengua. El objetivo √∫ltimo es abordar el estudio de la arquitectura m√°s importante de los sistemas actuales de procesamiento de textos: el transformer. Una vez estudiadas estas arquitecturas, finalizaremos con un an√°lisis del funcionamiento de los modelos preentrenados (modelos fundacionales), en general, y de los modelos de lengua, en particular.</p>
<p>Los materiales de clase complementan la lectura de algunos cap√≠tulos de un libro de texto (‚ÄúSpeech and Language Processing‚Äù de Dan Jurafsky y James H. Martin, borrador de la tercera edici√≥n, disponible online) con anotaciones realizadas por el profesor.</p>
<section id="practicas-a-entregar-para-este-bloque">
<h2><span class="section-number">22.1. </span>Pr√°cticas a entregar para este bloque<a class="headerlink" href="#practicas-a-entregar-para-este-bloque" title="Permalink to this headline">#</a></h2>
<p>Durante las sesiones de este bloque, estudiaremos diferentes implementaciones en PyTorch de modelos neuronales para procesar textos. Para cada ejemplo de c√≥digo, excepto el √∫ltimo, has de entregar un notebook con el c√≥digo original y peque√±os bloques de texto con tus comentarios explicando el c√≥digo en base a lo que has aprendido sobre el tema y sobre PyTorch. Entrega todos los notebooks en forma de enlaces de Google Colab a trav√©s de una tutor√≠a de UACloud. Crea los cuadernos de Google Colab con tu cuenta de <code class="docutils literal notranslate"><span class="pre">gcloud.ua.es</span></code> y comp√°rtelos con la cuenta del profesor que te indicar√° en clase. Para el √∫ltimo bloque de c√≥digo (implementaci√≥n del transformer), tendr√°s que complementar el cuaderno con c√≥digo propio para realizar una tarea adicional y ajuntar un informe detallado dentro del cuaderno. El <strong>plazo de entrega acaba el 31 de mayo de 2023</strong> a las 23.59 horas. Las pr√°cticas se pueden hacer en parejas. Recuerda que hay un examen final de la asignatura, por lo que es muy recomendable que ambos miembros del equipo se impliquen de igual manera.</p>
</section>
<section id="primera-sesion-29-de-marzo-de-2023">
<h2><span class="section-number">22.2. </span>Primera sesi√≥n (29 de marzo de 2023)<a class="headerlink" href="#primera-sesion-29-de-marzo-de-2023" title="Permalink to this headline">#</a></h2>
<p><strong><span style="font-size: 1.15em">Contenidos a preparar antes de la sesi√≥n del 29/03/2023</span></strong></p>
<p>Las actividades a realizar antes de esta clase son:</p>
<ul class="simple">
<li><p>Lectura y estudio de los contenidos de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/regresor">esta p√°gina</a> sobre regresi√≥n log√≠stica. Puedes saltar por ahora el apartado de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/regresor#regresores-implementados-en-pytorch">implementaci√≥n en PyTorch</a>, ya que ser√° el eje central de la clase presencial. Como ver√°s, la p√°gina te indica qu√© contenidos has de leer del libro. Tras una primera lectura, lee las anotaciones del profesor, cuyo prop√≥sito es ayudarte a entender los conceptos clave del cap√≠tulo. Despu√©s, realiza una segunda lectura del cap√≠tulo del libro. En total, esta parte deber√≠a llevarte unas 3 horas üïíÔ∏è de trabajo.</p></li>
<li><p>Visionado y estudio de los tutoriales en v√≠deo de esta <a class="reference external" href="https://www.youtube.com/playlist?list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN">playlist oficial de PyTorch</a>.  Estudia al menos los 4 primeros v√≠deos (‚ÄúIntroduction to PyTorch‚Äù, ‚ÄúIntroduction to PyTorch Tensors‚Äù, ‚ÄúThe Fundamentals of Autograd‚Äù y ‚ÄúBuilding Models with PyTorch‚Äù). En total, esta parte deber√≠a llevarte unas 2 horas üïíÔ∏è de trabajo.</p></li>
<li><p>Tras acabar con las dos partes anteriores, realiza este <a class="reference external" href="https://forms.gle/E1xzZHw6hzMWJaNr7">test de evaluaci√≥n</a> de estos contenidos. Son pocas preguntas y te llevar√° unos minutos.</p></li>
</ul>
<p><strong><span style="font-size: 1.15em">Contenidos para la sesi√≥n presencial del 29/03/2023</span></strong></p>
<p>En la clase presencial (3 horas üïíÔ∏è de duraci√≥n), repasaremos los contenidos de la semana anterior y veremos c√≥mo se implementa un regresor log√≠stico en PyTorch siguiendo la implementaci√≥n de un regresor log√≠stico binario y de uno multinomial que se comentan en <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/regresor#regresores-implementados-en-pytorch">este apartado</a>.</p>
<p>La idea es que vayas creando una serie de notebooks en Google Colab en los que incluyas y comentes cada uno de los programas que vamos a ir viendo. En la √∫ltima clase se presentar√° una pr√°ctica m√°s avanzada que implicar√° modificar el c√≥digo del transformer.</p>
<p><em>Nota:</em> por si te es de utilidad, tienes una copia del c√≥digo que veremos en este bloque en <a class="reference external" href="https://drive.google.com/drive/folders/1W47uSa0ddxalj9OWQIKk1mRYJ7xq6ftv?usp=sharing">esta carpeta de Google Drive</a> (accede con tu cuenta de <code class="docutils literal notranslate"><span class="pre">gcloud.ua.es</span></code>).</p>
</section>
<section id="segunda-sesion-26-de-abril-de-2023">
<h2><span class="section-number">22.3. </span>Segunda sesi√≥n (26 de abril de 2023)<a class="headerlink" href="#segunda-sesion-26-de-abril-de-2023" title="Permalink to this headline">#</a></h2>
<p>Entre la sesi√≥n anterior y la del 26 de abril transcurren varias semanas, por lo que la carga de trabajo es mayor que en la sesi√≥n anterior.</p>
<p><strong><span style="font-size: 1.15em">Contenidos a preparar antes de la sesi√≥n del 26/04/2023</span></strong></p>
<p>Las actividades a realizar antes de esta clase son:</p>
<ul class="simple">
<li><p>Lectura y estudio de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/embeddings">esta p√°gina</a> sobre la obtenci√≥n de embeddings incontextuales. Puedes saltar de nuevo el apartado de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/embeddings#implementaci%C3%B3n-en-pytorch">implementaci√≥n en PyTorch</a>, ya que se estudiar√° en la pr√≥xima clase presencial. Como ver√°s, la p√°gina te indica qu√© contenidos has de leer del libro. Tras una primera lectura, lee las anotaciones del profesor, cuyo objetivo es ayudarte a entender los conceptos clave del cap√≠tulo. Despu√©s, realiza una segunda lectura del cap√≠tulo. En total, esta parte deber√≠a llevarte unas 4 horas üïíÔ∏è de trabajo.</p></li>
<li><p>Lectura y estudio de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/ffw">esta p√°gina</a> sobre las redes neuronales hacia delante. Puedes saltar tambi√©n aqu√≠ el apartado de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/ffw#implementaci%C3%B3n-en-pytorch">implementaci√≥n en PyTorch</a>, ya que se estudiar√° tambi√©n en la pr√≥xima clase presencial. En total, esta parte deber√≠a llevarte unas 3 horas üïíÔ∏è de trabajo.</p></li>
<li><p>Primeros pasos en el estudio del modelo transformer. Volveremos a dedicar m√°s horas a esta arquitectura para la pr√≥xima sesi√≥n de forma que la abordaremos en dos fases. Por ahora, lee con detenimiento la introducci√≥n a mecanismos de atenci√≥n de <a class="reference external" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">‚ÄúVisualizing A Neural Machine Translation Model‚Äù</a>, as√≠ como la introducci√≥n visual a los transformers de <a class="reference external" href="http://jalammar.github.io/illustrated-transformer/">‚ÄúThe Illustrated Transformer‚Äù</a> y la m√°s elaborada de <a class="reference external" href="https://jalammar.github.io/illustrated-gpt2/">‚ÄúThe Illustrated GPT-2‚Äù</a>. A continuaci√≥n, lee el apartado 9.7 (solo este apartado) del cap√≠tulo <a class="reference external" href="https://web.archive.org/web/20221216193204/https://web.stanford.edu/~jurafsky/slp3/9.pdf">‚ÄúDeep learning architectures for sequence processing‚Äù</a>; el objetivo es que entiendas conceptualmente el mecanismo de atenci√≥n de los transformers, pero no es necesario que en este momento comprendas todos los detalles t√©cnicos (especialmente las ecuaciones del modelo), ya que volver√°s a dedicarle tiempo a este cap√≠tulo m√°s adelante. En total, esta parte deber√≠a llevarte ahora unas 4 horas üïíÔ∏è de trabajo.</p></li>
<li><p>Realizaci√≥n del <a class="reference external" href="https://forms.gle/Eb3ZwwGxbQp88t4FA">test de evaluaci√≥n</a> de estos contenidos. Son pocas preguntas y te llevar√° unos minutos.</p></li>
</ul>
<p><strong><span style="font-size: 1.15em">Contenidos para la sesi√≥n presencial del 26/04/2023</span></strong></p>
<p>En la clase presencial (3 horas üïíÔ∏è de duraci√≥n), repasaremos los contenidos de la semana anterior y veremos sendas implementaciones en PyTorch del algoritmo <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/embeddings#implementaci%C3%B3n-en-pytorch">skip-grams</a> y de un modelo de lengua basado en <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/ffw#implementaci%C3%B3n-en-pytorch">redes feedforward</a>.</p>
</section>
<section id="tercera-sesion-10-de-mayo-de-2023">
<h2><span class="section-number">22.4. </span>Tercera sesi√≥n (10 de mayo de 2023)<a class="headerlink" href="#tercera-sesion-10-de-mayo-de-2023" title="Permalink to this headline">#</a></h2>
<p><strong><span style="font-size: 1.15em">Contenidos a preparar antes de la sesi√≥n del 10/05/2023</span></strong></p>
<p>Las actividades a realizar antes de esta clase son:</p>
<ul class="simple">
<li><p>Afianzar el estudio de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/attention">esta p√°gina</a> sobre el modelo transformer y el cap√≠tulo correspondiente del libro. En realidad, ya estudiaste para la sesi√≥n anterior todos estos conceptos, pero se te pidi√≥ que no te detuvieras en exceso en los detalles t√©cnicos del libro. Ahora, es el momento de que vuelvas a leerlo con m√°s calma y consultes tambi√©n las anotaciones del profesor que hay en la p√°gina web. Puedes saltar de nuevo el apartado de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/attention#implementaci%C3%B3n-en-pytorch">implementaci√≥n en PyTorch</a>, ya que se estudiar√° en la pr√≥xima clase presencial. En total, esta parte deber√≠a llevarte unas 4 horas üïíÔ∏è de trabajo.</p></li>
<li><p>Visualizar el <a class="reference external" href="https://youtu.be/kCc8FmEb1nY">v√≠deo</a> que introduce las ideas principales de la implementaci√≥n del transformer que estudiaremos en la clase presencial. Pausa el v√≠deo y vuelve atr√°s cuando sea necesario para entender los conceptos clave. En total, esta parte deber√≠a llevarte unas 2 horas üïíÔ∏è de trabajo.</p></li>
</ul>
<p><strong><span style="font-size: 1.15em">Contenidos para la sesi√≥n del 10/05/2023</span></strong></p>
<p>En la clase presencial (3 horas üïíÔ∏è de duraci√≥n), repasaremos los contenidos de la semana anterior y veremos c√≥mo se <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/attention#implementaci%C3%B3n-en-pytorch">implementa el modelo transformer en PyTorch</a>. En esta clase, adem√°s, se presentar√° la parte final de la pr√°ctica a realizar en base al c√≥digo del transformer.</p>
<p>Del c√≥digo del transformer solo has de comentar en un cuaderno las clases <code class="docutils literal notranslate"><span class="pre">CausalSelfAttention</span></code> y <code class="docutils literal notranslate"><span class="pre">Block</span></code>, as√≠ como los m√©todos <code class="docutils literal notranslate"><span class="pre">forward</span></code>, <code class="docutils literal notranslate"><span class="pre">generate</span></code>, <code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">_init_weights</span></code> y <code class="docutils literal notranslate"><span class="pre">get_default_config</span></code> de la clase <code class="docutils literal notranslate"><span class="pre">GPT</span></code>. Puedes a√±adir un peque√±o c√≥digo que use las clases del modelo. Haz la pr√°ctica final que se menciona a continuaci√≥n en un cuaderno diferente.</p>
<p><strong><span style="font-size: 1.15em">Contenidos pr√°cticos a trabajar tras la sesi√≥n</span></strong></p>
<p>Tras la sesi√≥n, ya puedes ponerte a trabajar en la pr√°ctica de desarrollo a realizar para este bloque y de la cual saldr√° la mayor parte de la nota del bloque (un 90% aproximadamente). Se espera que dediques a ella unas 11 horas üïíÔ∏è de trabajo. La pr√°ctica se basa en modificar ligeramente el c√≥digo de <a class="reference external" href="https://jaspock.github.io/me/materials/transformers/attention#implementaci%C3%B3n-en-pytorch">minGPT</a> para poder realizar experimentos de interpretabilidad mecanicista. El enunciado completo est√° en el siguiente apartado.</p>
</section>
<section id="practica-sobre-interpretabilidad-mecanicista-de-transformers">
<h2><span class="section-number">22.5. </span>Pr√°ctica sobre interpretabilidad mecanicista de transformers<a class="headerlink" href="#practica-sobre-interpretabilidad-mecanicista-de-transformers" title="Permalink to this headline">#</a></h2>
<p>La <em>interpretabilidad mecanicista</em> en el contexto de la inteligencia artificial intenta dar una explicaci√≥n motivada del funcionamiento de los modelos de aprendizaje autom√°tico. Es una propuesta muy importante de cara a generar confianza en los sistemas e inducir ciertos comportamientos en ellos. Dentro del campo de la interpretabilidad mecanicista existen un buen n√∫mero de t√©cnicas que se pueden aplicar a los transformers. Aqu√≠ nos centraremos en el <a class="reference external" href="https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx">parcheado de activaciones</a>.</p>
<p>El parcheado de activaciones <em>interviene</em> en una activaci√≥n espec√≠fica de un modelo mediante la sustituci√≥n de una activaci√≥n <em>corrompida</em> con una activaci√≥n <em>limpia</em>. Se mide entonces c√≥mo afecta el cambio a la salida del modelo. Esto nos permite identificar qu√© activaciones son importantes para el resultado del modelo y localizar posibles causas de errores en la predicci√≥n.</p>
<p>En nuestro caso particular, vas a escribir c√≥digo que ejecute la versi√≥n m√°s peque√±a de GPT2 (usa la cadena <code class="docutils literal notranslate"><span class="pre">gpt2</span></code> en el c√≥digo) con dos entradas diferentes: dos textos que solo se diferencien en un √∫nico token. La idea es que al proporcionar al modelo la entrada corrompida, intervendremos en el embedding tras una cierta capa (uno solo cada vez) y lo parchearemos con el embedding correspondiente de la ejecuci√≥n limpia. Luego mediremos cu√°nto cambia la predicci√≥n del siguiente token respecto a la ejecuci√≥n limpia. Si el cambio es significativo, entonces podemos estar seguros de que la activaci√≥n que hemos alterado es importante para la predicci√≥n. Este proceso de parcheado lo realizaremos para cada capa del modelo y para cada token de la entrada. Con toda esta informaci√≥n, obtendremos una gr√°fica y sacaremos conclusiones. Por motivos que entender√°s en un momento, los dos textos han de tener el mismo n√∫mero de tokens.</p>
<p><strong><span style="font-size: 1.15em">Ejemplo de an√°lisis</span></strong></p>
<p>Daremos un ejemplo para que se entienda mejor. Considera el siguiente texto de entrada: ‚ÄúMichelle Jones was a top-notch student. Michelle‚Äù. Si se lo damos a GPT2 y estudiamos la probabilidad emitida por el modelo para el token que sigue a la segunda aparici√≥n de Michelle, obtendremos lo siguiente (solo se muestran los 20 tokens m√°s probables):</p>
<table class="table">
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Position</p></th>
<th class="head"><p>Token index</p></th>
<th class="head"><p>Token</p></th>
<th class="head"><p>Probability</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>373</p></td>
<td><p>was</p></td>
<td><p>0.1634</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>5437</p></td>
<td><p>Jones</p></td>
<td><p>0.1396</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>338</p></td>
<td><p>‚Äòs</p></td>
<td><p>0.0806</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>550</p></td>
<td><p>had</p></td>
<td><p>0.0491</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>318</p></td>
<td><p>is</p></td>
<td><p>0.0229</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>290</p></td>
<td><p>and</p></td>
<td><p>0.0227</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>11</p></td>
<td><p>,</p></td>
<td><p>0.0222</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>531</p></td>
<td><p>said</p></td>
<td><p>0.0134</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p>468</p></td>
<td><p>has</p></td>
<td><p>0.0120</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p>635</p></td>
<td><p>also</p></td>
<td><p>0.0117</p></td>
</tr>
<tr class="row-even"><td><p>11</p></td>
<td><p>1625</p></td>
<td><p>came</p></td>
<td><p>0.0091</p></td>
</tr>
<tr class="row-odd"><td><p>12</p></td>
<td><p>1297</p></td>
<td><p>told</p></td>
<td><p>0.0084</p></td>
</tr>
<tr class="row-even"><td><p>13</p></td>
<td><p>1422</p></td>
<td><p>didn</p></td>
<td><p>0.0070</p></td>
</tr>
<tr class="row-odd"><td><p>14</p></td>
<td><p>2993</p></td>
<td><p>knew</p></td>
<td><p>0.0067</p></td>
</tr>
<tr class="row-even"><td><p>15</p></td>
<td><p>1816</p></td>
<td><p>went</p></td>
<td><p>0.0061</p></td>
</tr>
<tr class="row-odd"><td><p>16</p></td>
<td><p>561</p></td>
<td><p>would</p></td>
<td><p>0.0061</p></td>
</tr>
<tr class="row-even"><td><p>17</p></td>
<td><p>3111</p></td>
<td><p>worked</p></td>
<td><p>0.0055</p></td>
</tr>
<tr class="row-odd"><td><p>18</p></td>
<td><p>750</p></td>
<td><p>did</p></td>
<td><p>0.0054</p></td>
</tr>
<tr class="row-even"><td><p>19</p></td>
<td><p>2486</p></td>
<td><p>Obama</p></td>
<td><p>0.0053</p></td>
</tr>
<tr class="row-odd"><td><p>20</p></td>
<td><p>2492</p></td>
<td><p>wasn</p></td>
<td><p>0.0050</p></td>
</tr>
</tbody>
</table>
<p>Como era de esperar, el token ‚ÄúJones‚Äù tiene una probabilidad notablemente elevada. Ahora, considera la entrada corrompida ‚ÄúMichelle Smith was a top-notch student. Michelle‚Äù. Si le damos esta entrada a GPT2, esperamos que la probabilidad de ‚ÄúJones‚Äù a como continuaci√≥n del texto sea mucho menor que antes y que la de ‚ÄúSmith‚Äù sea mucho mayor, lo que (puedes comprobarlo) efectivamente ocurre. Pero queremos ir m√°s all√° y saber qu√© embeddings son los que m√°s influyen en esta diferencia. Dado que ambas entradas tienen 11 tokens (m√°s adelante explicaremos c√≥mo averiguarlo) y que el transformer del modelo GPT2 peque√±o tiene 12 capas, si nos centramos en los embeddings que se obtienen a la salida de cada capa, podemos parchear 11√ó12 = 132 embeddings diferentes. Calcularemos, por tanto, 132 veces la diferencia entre el logit de ‚ÄúSmith‚Äù y el logit de ‚ÄúJones‚Äù en la salida del √∫ltimo token de la entrada (‚ÄúMichelle‚Äù) en el modelo corrompido. Observa que tambi√©n podr√≠amos calcular las diferencias tras aplicar la funci√≥n softmax, pero en este caso no lo haremos.</p>
<p>Una representaci√≥n en forma de mapa de calor del resultado es la siguiente:</p>
<figure class="align-default" id="fig-mech">
<a class="reference internal image-reference" href="_images/mechanistic-michelle.png"><img alt="_images/mechanistic-michelle.png" src="_images/mechanistic-michelle.png" style="height: 540px;" /></a>
</figure>
<p>Recuerda que en un gr√°fico como el anterior, debido a la m√°scara de atenci√≥n y a la disposici√≥n de las capas, la informaci√≥n fluye de izquierda a derecha y de arriba a abajo. Puedes ver c√≥mo intervenir en la primera columna no tiene efectos en la predicci√≥n del siguiente token, lo que tiene todo el sentido, ya que los embeddings que se parchean tienen exactamente los mismos valores en el modelo limpio y en el corrompido, ya que el contexto anterior es el mismo. Tampoco parece haber cambios al parchear los embeddings de la tercera a la antepen√∫ltima columna. Sin embargo, observa c√≥mo al intervenir los embeddings de muchas capas del segundo token, la predicci√≥n se decanta hacia ‚ÄúJones‚Äù (el color se hace oscuro cuando la diferencia entre el logit de ‚ÄúSmith‚Äù y el de ‚ÄúJones‚Äù se va haciendo negativa porque ‚ÄúJones‚Äù tiene un logit mayor). Modificar los embeddings de las √∫ltimas capas del segundo token tiene efectos mucho menores, ya que el embedding apenas puede influir en el futuro de la secuencia. En la √∫ltima posici√≥n (‚ÄúMichelle‚Äù) se observa que los embeddings de las capas finales van anticip√°ndose al token que tienen que predecir.</p>
<p>Algunos textos corrompidos adicionales que puede ser interesante explorar son, por ejemplo, ‚ÄúJessica Jones was a top-notch student. Michelle‚Äù o ‚ÄúMichelle Smith was a top-notch student. Jessica‚Äù.</p>
<p>En esta pr√°ctica se trata de que programes el c√≥digo que te permite obtener gr√°ficas y probabilidades como las anteriores, propongas tus propios textos limpios y corrompidos (intenta tirar de creatividad y no estudiar textos o fen√≥menos muy similares), realices un an√°lisis parecido al anterior y escribas un informe dentro de un cuaderno de Python de unas 1500-2000 palabras en el que presentes y comentes el c√≥digo que has implementado, adem√°s de presentar tu enfoque, los resultados y las conclusiones pertinentes. Ser√°n bienvenidas las ideas originales y los experimentos adicionales que se te ocurran.</p>
<p><strong><span style="font-size: 1.15em">Tokenization</span></strong></p>
<p>El modelo GPT2 usa un tokenizador basado en BPE que trocea el texto de entrada en palabras o en unidades inferiores dependiendo de su frecuencia. El c√≥digo de minGPT permite descargar dicho tokenizador y usarlo para segmentar los textos. El siguiente c√≥digo muestra c√≥mo tokenizar un texto para obtener sus √≠ndices y viceversa.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mingpt.bpe</span> <span class="kn">import</span> <span class="n">BPETokenizer</span>

<span class="nb">input</span> <span class="o">=</span> <span class="s2">&quot;Michelle Jones was a top-notch student. Michelle&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input:&quot;</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
<span class="n">bpe</span> <span class="o">=</span> <span class="n">BPETokenizer</span><span class="p">()</span>
<span class="c1"># bpe() gets a string and returns a 2D batch tensor </span>
<span class="c1"># of indices with shape (1, input_length)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">bpe</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tokenized input:&quot;</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
<span class="n">input_length</span> <span class="o">=</span> <span class="n">tokens</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of input tokens:&quot;</span><span class="p">,</span> <span class="n">input_length</span><span class="p">)</span>
<span class="c1"># bpe.decode gets a 1D tensor (list of indices) and returns a string</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Detokenized input from indices:&quot;</span><span class="p">,</span> <span class="n">bpe</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokens</span><span class="p">))</span>  
<span class="n">tokens_str</span> <span class="o">=</span> <span class="p">[</span><span class="n">bpe</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">token</span><span class="p">]))</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Detokenized input as strings: &quot;</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens_str</span><span class="p">))</span>
</pre></div>
</div>
<p><strong><span style="font-size: 1.15em">Detalles de implementaci√≥n</span></strong></p>
<p>Lo siguiente son algunos detalles de implementaci√≥n que te pueden ser √∫tiles, pero que no es necesario que sigas.</p>
<p>Para conseguir un c√≥digo que te permita realizar el parcheado de activaciones te tendr√°s que centrar en los ficheros <code class="docutils literal notranslate"><span class="pre">mingpt/model.py</span></code> y <code class="docutils literal notranslate"><span class="pre">generate.ipynb</span></code>. Si trabajas en local sin usar un <em>notebook</em> (recomendado) copia el c√≥digo de <code class="docutils literal notranslate"><span class="pre">generate.ipynb</span></code> en un fichero <code class="docutils literal notranslate"><span class="pre">generate.py</span></code> que puedas ejecutar desde la l√≠nea de √≥rdenes.</p>
<p>Puedes trabajar directamente en una sesi√≥n de Google Colab. Aqu√≠ tienes un <a class="reference external" href="https://colab.research.google.com/drive/1dq2EClvIbEtoEnHWoAXZQTArJDHivQly?usp=sharing">proyecto</a> (accede con tu cuenta de <code class="docutils literal notranslate"><span class="pre">gcloud.ua.es</span></code>) con instrucciones sobre c√≥mo usarlo para desarrollar. Sin embargo, es mucho m√°s c√≥modo desarrollar en local (entre otras cosas, puedes trabajar con un mejor editor de texto que el de Colab y tambi√©n depurar). Incluso si no tienes una GPU, el c√≥digo funciona sin problemas sobre CPU y solo tarda unos segundos m√°s que sobre GPU al solo trabajar con un texto y con un modelo no excesivamente grande. Cuando tengas el c√≥digo final, puedes subirlo a un notebook para su entrega.</p>
<p>A√±ade a la funci√≥n <code class="docutils literal notranslate"><span class="pre">forward</span></code> del transformer, c√≥digo que permita salvar (seg√∫n el valor de cierto <em>flag</em> booleano recibido como par√°metro) en una variable de instancia las activaciones de cada capa y cada posici√≥n. Recuerda hacer una copia profunda de los embeddings y no guardar √∫nicamente una referencia que puede ser sobreescrita posteriormente; para ello, consulta la secuencia de llamadas <code class="docutils literal notranslate"><span class="pre">.detach().clone()</span></code> de PyTorch. A√±ade tambi√©n c√≥digo que permita (de nuevo en base a un par√°metro booleano) parchear el embedding de una capa y posici√≥n concretas.</p>
<p>A√±ade tambi√©n a la funci√≥n <code class="docutils literal notranslate"><span class="pre">forward</span></code> c√≥digo que guarde los logits del √∫ltimo token, que contienen la informaci√≥n que nos interesa sobre la predicci√≥n del siguiente token. Puedes guardar esta informaci√≥n en un atributo que luego puedes acceder desde el exterior de la clase. Observa que solo te interesa el vector correspondiente al √∫ltimo token.</p>
<p>A√±ade c√≥digo al fichero <code class="docutils literal notranslate"><span class="pre">generate.py</span></code> que divida el texto limpio en tokens, lo pase por el modelo a trav√©s de la funci√≥n <code class="docutils literal notranslate"><span class="pre">generate</span></code> (pidi√©ndole al modelo que guarde los embeddings intermedios) y muestre las continuaciones m√°s probables a partir de los logits del √∫ltimo token. Ten en cuenta que si quieres saber la probabilidad de una continuaci√≥n como el token ‚ÄúJones‚Äù, por ejemplo, has de buscar el √≠ndice de dicho token en el vocabulario anteponi√©ndole un espacio en blanco (<code class="docutils literal notranslate"><span class="pre">index</span> <span class="pre">=</span> <span class="pre">bpe('</span> <span class="pre">Jones')</span></code>). Esto es as√≠ porque el segmentador de BPE trata de forma diferente los tokens que aparecen al principio de la secuencia y los que aparecen en medio. Una vez tengas el √≠ndice del token, puedes acceder a la posici√≥n correspondiente del vector de logits y obtener la probabilidad no normalizada de que sea la continuaci√≥n.</p>
<p>Despu√©s, puedes trabajar con el texto corrupto. Incluye un doble bucle que itere sobre todas las capas y todas las posiciones y llame cada vez a <code class="docutils literal notranslate"><span class="pre">generate</span></code> pas√°ndole la capa y la posici√≥n en la que realizar la intervenci√≥n. En cada paso, eval√∫a la diferencia de logits oportuna y gu√°rdala en una matriz de diferencias.</p>
<p>Usa finalmente la funci√≥n <code class="docutils literal notranslate"><span class="pre">matshow</span></code> de <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> para visualizar la matriz de diferencias.</p>
<p><strong><span style="font-size: 1.15em">Una explicaci√≥n m√°s informal</span></strong></p>
<p>La siguiente explicaci√≥n informal puede que te ayude a entender mejor el objetivo de la pr√°ctica.</p>
<p>Considera para simplificar la frase ‚Äúa b c‚Äù y la versi√≥n corrompida ‚Äúd e f‚Äù. En general, habr√° muchos m√°s tokens en com√∫n, pero as√≠ queda todo m√°s claro en la siguiente discusi√≥n. Considera que el modelo neuronal basado en el transformer tiene 5 capas de atenci√≥n. Considera que vamos a estudiar qu√© embeddings son importantes para la predicci√≥n de que tras estas frases vaya el token ‚ÄúX‚Äù.</p>
<p>Se trata primero de que permitas que en la funci√≥n forward del transformer (clase <code class="docutils literal notranslate"><span class="pre">GPT</span></code>) se puedan guardar (por ejemplo en una lista de listas de tensores) los 3x5=15 embeddings que se generan a la salida de cada una de las capas cuando se procesa la frase ‚Äúa b c‚Äù. En el enunciado se dan algunos detalles porque no puedes guardar simplemente la referencia a los tensores, ya que se modificar√°n la pr√≥xima vez que llames a forward, sino que has de clonar los tensores (aquello que en Programaci√≥n 3 llam√°bamos ‚Äúcopia defensiva‚Äù). Con esto tendr√°s almacenados los 15 tensores (embeddings) de la frase limpia.</p>
<p>Gu√°rdate tambi√©n los logits tras la √∫ltima capa. En particular, solo necesitar√°s los de la √∫ltima posici√≥n (es decir, los logits correspondientes al token ‚Äúc‚Äù), que te dan una medida de la probabilidad del siguiente token, es decir, del token que ir√° tras ‚Äúc‚Äù. Recuerda que estos logits no son realmente probabilidades (son valores como -11.1, -0.5, 0.78, o 2.32323) porque no se les ha aplicado la funci√≥n softmax, pero trabajar con ellos es m√°s c√≥modo que trabajar con las probabilidades porque tenemos valores con un rango m√°s amplio. No obstante, el estudio podr√≠a hacerse igualmente con probabilidades estrictas. En realidad, ni siquiera necesitas guardarte todos los logits, sino solo el escalar que corresponde al token ‚ÄúX‚Äù porque es lo √∫nico que usar√°s despu√©s</p>
<p>Ahora le das al modelo la versi√≥n corrompida ‚Äúd e f‚Äù, indic√°ndole que no sobreescriba la copia de los embeddings que obtuvimos con la frase limpia. La frase corrompida ha de tener el mismo n√∫mero de tokens que la limpia para que la siguiente discusi√≥n tenga sentido. La idea es modificar uno solo de los 15 embeddings que se producen mientras se procesa la frase sucia. Si, por ejemplo, nos centramos en el embedding del primer token (‚Äúd‚Äù) tras la primera capa, se tratar√≠a de que el c√≥digo de la funci√≥n forward opere ‚Äúcasi‚Äù de la forma normal, pero cuando se obtenga la salida de la primera capa y antes de pasarla como entrada a la segunda capa, se ha de modificar el embedding correspondiente a la primera palabra (solo ese) y sustituirlo por el embedding correspondiente (de la misma capa y posici√≥n) que te guardaste para la frase limpia (es decir, en este caso, ser√≠a el embedding que te guardaste tras la primera capa para el token ‚Äúa‚Äù). Con esto, la segunda capa recibir√° como entrada el embedding que se gener√≥ para ‚Äúa‚Äù en lugar del de ‚Äúd‚Äù.</p>
<p>Tras intervenir en el embedding de la posici√≥n 1 tras la capa 1, el resto del modelo trabaja sin ning√∫n ‚Äúcontratiempo‚Äù. De la misma manera que antes, ahora miramos los logits de la predicci√≥n del token que va tras el √∫ltimo token de la frase corrompida (es decir, ‚Äúf‚Äù). Y nos centramos en el valor del logit de la predicci√≥n del token ‚ÄúX‚Äù. La diferencia entre este valor y el que nos guardamos para la frase limpia nos da una idea de c√≥mo de relevante es el embedding de la capa 1 y posici√≥n 1 en la predicci√≥n del token ‚ÄúX‚Äù. En el enunciado se muestra c√≥mo algunos embeddings son mucho m√°s relevantes que otros. Y t√∫ tienes que hacer un estudio similar con diferentes frases.</p>
<p>Si repites la operaci√≥n anterior con los otros 14 embeddings (llamando 14 veces m√°s a la funci√≥n forward), terminar√°s teniendo 15 diferencias de logits (15 valores escalares) que puedes representar en un mapa de calor de 3x5 como se ve m√°s arriba.</p>
<p><strong><span style="font-size: 1.15em">Ampliar conocimientos</span></strong></p>
<p>Lo anterior es solo uno de los m√∫ltiples an√°lisis que se han propuesto dentro de la interpretabilidad mecanicista. Para esta pr√°ctica no se espera que vayas m√°s all√° de esto, pero si te interesa conocer un par de an√°lisis m√°s puedes consultar <a class="reference external" href="https://www.lesswrong.com/posts/hnzHrdqn3nrjveayv/how-to-transformer-mechanistic-interpretability-in-50-lines">este tutorial</a>. Observa que aunque el tutorial usa una librer√≠a para parchear las activaciones, en esta pr√°ctica no puedes usar ninguna librer√≠a para ello y lo has de hacer directamente sobre el c√≥digo de minGPT. Una revisi√≥n mucho m√°s detallada sobre la interpretabilidad mecanicista se puede encontrar en <a class="reference external" href="https://www.neelnanda.io/mechanistic-interpretability/glossary">este trabajo</a> de Neel Nanda.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="bloque3_ev.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">21. </span>Ev. Evaluaci√≥n de pr√°cticas del Bloque 2</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="content.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">23. </span>Content in Jupyter Book</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Universitat d'Alacant<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>