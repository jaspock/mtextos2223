
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3. Análisis categorial y sintáctico &#8212; Minería de Textos</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/estilos.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Análisis semántico" href="bloque1_3AnalisisSemantico.html" />
    <link rel="prev" title="2. Minería de textos y procesamiento del lenguaje natural." href="bloque1_1Introduccion.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-master-ca.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Minería de Textos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Materiales de Minería de Textos
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 1
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1.html">
   1. Introducción a la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_1Introduccion.html">
   2. Minería de textos y procesamiento del lenguaje natural.
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Análisis categorial y sintáctico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_3AnalisisSemantico.html">
   4. Análisis semántico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica1.html">
   5. Práctica 1.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_4AnalisisSemanticoVectorial.html">
   6. Análisis semántico vectorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica2.html">
   7. Práctica 1b :
   <em>
    Topic modeling
   </em>
   .
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 2
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3.html">
   8. Aplicaciones de la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t1_aplicaciones.html">
   9. T1. Aplicaciones generales
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t2_subaplicaciones-benchmarks.html">
   10. T2. Aplicaciones específicas y Benchmacks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t2.1_analisis_sentimientos.html">
   11. T2.1. Aplicaciones específicas. Análisis de Sentimientos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t3.1_metricas.html">
   12. T3. Métricas de Evaluación
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t4_huggingface.html">
   13. T4. Centralización de datasets y modelos: Huggingface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t5_automl.html">
   14. T5. Auto Machine Learning(AutoML)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_t5.1_autogoal.html">
   15. T5.1. AutoGOAL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p1_SA-Pipeline-Reviews.html">
   16. P1.1. Pipeline simple
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p2_SA-Transformers-Basic.html">
   17. P1.2. APIs Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p3_SA-Transformers-Training-FineTuning.html">
   18. P2. Reajustar modelos Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_p4_SA-Transformers-Training-Custom.html">
   19. P3. Composición de vectores de características
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque3_ev.html">
   20. Ev. Evaluación del bloque 2
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 3
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque2.html">
   21. Técnicas para la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque2_historia.html">
   22. Revisión histórica
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque2_embeddings.html">
   23. Representaciones de palabras y oraciones
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque2_practica.html">
   24. Práctica. Lectura y documentación del código de un extractor de entidades
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Extras
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="content.html">
   25. Content in Jupyter Book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   26. Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   27. Content with notebooks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/bloque1_2CategorialSintactico.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unidades-de-comunicacion-basica-la-palabra-type-token-y-lema">
   3.1. Unidades de comunicación básica. La palabra.
   <em>
    Type
   </em>
   ,
   <em>
    token
   </em>
   y lema.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenizacion">
     3.1.1. Tokenización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lematizacion-y-stemming">
     3.1.2. Lematización y
     <em>
      stemming
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analisis-morfologico-y-categorial">
   3.2. Análisis morfológico y categorial.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fundamentos-linguisticos-a-modo-de-recordatorio">
     3.2.1. Fundamentos lingüísticos (a modo de recordatorio).
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#importancia-en-mineria-de-textos">
     3.2.2. Importancia en Minería de textos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-de-la-informacion-morfologica-y-categorial">
     3.2.3. Representación de la información morfológica y categorial
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arquitectura-de-un-pos-tagger-algoritmos-clasicos-de-desambiguacion">
     3.2.4. Arquitectura de un
     <em>
      PoS_tagger
     </em>
     . Algoritmos clásicos de desambiguación.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algoritmos-de-desambiguacion-categorial-aproximacion-historica">
     3.2.5. Algoritmos de desambiguación categorial (aproximación histórica)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modelo-de-reglas-simples">
       3.2.5.1. Modelo de reglas simples.
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelo-estadistico-cadena-de-markov">
     3.2.6. Modelo estadístico: cadena de markov.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelo-oculto-de-markov">
     3.2.7. Modelo oculto de Markov
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gramaticas-de-restricciones-constraint-grammar">
     3.2.8. Gramáticas de restricciones (
     <em>
      Constraint grammar
     </em>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-basados-en-aprendizaje-automatico">
     3.2.9. Modelos basados en aprendizaje automático.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#situacion-actual">
     3.2.10. Situación actual
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recursos">
     3.2.11. Recursos.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analisis-sintactico">
   3.3. Análisis sintáctico.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arquitectura-estandar-de-un-parser">
     3.3.1. Arquitectura estándar de un
     <em>
      parser
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-de-representacion">
     3.3.2. Modelos de representación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principal-problema-computacional">
     3.3.3. Principal problema computacional
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gramaticas-formales">
     3.3.4. Gramáticas formales
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#context-free-grammars">
       3.3.4.1. Context free grammars
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#probabilistic-context-free-grammar-y-modelos-probabilisticos">
       3.3.4.2.
       <em>
        Probabilistic Context Free Grammar
       </em>
       y modelos probabilísticos
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chunkers">
     3.3.5.
     <em>
      Chunkers
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estrategias">
     3.3.6. Estrategias
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#formato-conll">
     3.3.7. Formato CONLL
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     3.3.8. Situación actual
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#herramientas">
     3.3.9. Herramientas
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   3.4. Bibliografía
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Análisis categorial y sintáctico</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unidades-de-comunicacion-basica-la-palabra-type-token-y-lema">
   3.1. Unidades de comunicación básica. La palabra.
   <em>
    Type
   </em>
   ,
   <em>
    token
   </em>
   y lema.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenizacion">
     3.1.1. Tokenización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lematizacion-y-stemming">
     3.1.2. Lematización y
     <em>
      stemming
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analisis-morfologico-y-categorial">
   3.2. Análisis morfológico y categorial.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fundamentos-linguisticos-a-modo-de-recordatorio">
     3.2.1. Fundamentos lingüísticos (a modo de recordatorio).
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#importancia-en-mineria-de-textos">
     3.2.2. Importancia en Minería de textos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-de-la-informacion-morfologica-y-categorial">
     3.2.3. Representación de la información morfológica y categorial
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arquitectura-de-un-pos-tagger-algoritmos-clasicos-de-desambiguacion">
     3.2.4. Arquitectura de un
     <em>
      PoS_tagger
     </em>
     . Algoritmos clásicos de desambiguación.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algoritmos-de-desambiguacion-categorial-aproximacion-historica">
     3.2.5. Algoritmos de desambiguación categorial (aproximación histórica)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modelo-de-reglas-simples">
       3.2.5.1. Modelo de reglas simples.
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelo-estadistico-cadena-de-markov">
     3.2.6. Modelo estadístico: cadena de markov.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelo-oculto-de-markov">
     3.2.7. Modelo oculto de Markov
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gramaticas-de-restricciones-constraint-grammar">
     3.2.8. Gramáticas de restricciones (
     <em>
      Constraint grammar
     </em>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-basados-en-aprendizaje-automatico">
     3.2.9. Modelos basados en aprendizaje automático.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#situacion-actual">
     3.2.10. Situación actual
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recursos">
     3.2.11. Recursos.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analisis-sintactico">
   3.3. Análisis sintáctico.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arquitectura-estandar-de-un-parser">
     3.3.1. Arquitectura estándar de un
     <em>
      parser
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-de-representacion">
     3.3.2. Modelos de representación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principal-problema-computacional">
     3.3.3. Principal problema computacional
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gramaticas-formales">
     3.3.4. Gramáticas formales
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#context-free-grammars">
       3.3.4.1. Context free grammars
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#probabilistic-context-free-grammar-y-modelos-probabilisticos">
       3.3.4.2.
       <em>
        Probabilistic Context Free Grammar
       </em>
       y modelos probabilísticos
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chunkers">
     3.3.5.
     <em>
      Chunkers
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estrategias">
     3.3.6. Estrategias
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#formato-conll">
     3.3.7. Formato CONLL
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     3.3.8. Situación actual
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#herramientas">
     3.3.9. Herramientas
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   3.4. Bibliografía
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="analisis-categorial-y-sintactico">
<span id="label-pos"></span><h1><span class="section-number">3. </span>Análisis categorial y sintáctico<a class="headerlink" href="#analisis-categorial-y-sintactico" title="Permalink to this headline">#</a></h1>
<div class="note admonition">
<p class="admonition-title">Nota</p>
<p>Para preparar este tema, consulta los capítulos 12, 13 y 14 de Juravsky y Martin (2022) <em>Speech and Language Processing</em>. <a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</a>.</p>
</div>
<section id="unidades-de-comunicacion-basica-la-palabra-type-token-y-lema">
<h2><span class="section-number">3.1. </span>Unidades de comunicación básica. La palabra. <em>Type</em>, <em>token</em> y lema.<a class="headerlink" href="#unidades-de-comunicacion-basica-la-palabra-type-token-y-lema" title="Permalink to this headline">#</a></h2>
<p>Si bien el concepto de “palabra” se suele utilizar como unidad mínima y básica de comunicación, realmente desde la palabra no tiene en lingüística una definición clara: es un concepto vago muy difícil de delimitar.</p>
<p>En lingüística de corpus, lingüística computacional y procesamiento del lenguaje natural, más que con el concepto de “palabra”, se trabaja con los conceptos de <em>type</em> (“tipo”) y <em>token</em> (“caso”) (<a class="reference external" href="https://es.wikipedia.org/wiki/Caso_y_tipo">introducidos por el filósofo Charles S. Peirce</a> a principio de siglo XX):</p>
<ul class="simple">
<li><p><em>Type</em> es la palabra entendida como clase o tipo. Una secuencia de caracteres diferente de cualquier otra secuencia.</p></li>
<li><p><em>Token</em> es cada una de las instancias o casos concretos de esas clase <em>type</em> que se pueda hallar en un texto <a class="footnote-reference brackets" href="#id4" id="id1">1</a>.</p></li>
</ul>
<p>Se suele ejemplificar la diferencia entre ambos conceptos con el verso de G. Stein:</p>
<blockquote>
<div><p>“Rose is a rose is a rose is a rose”;</p>
</div></blockquote>
<p>pero para españolizarlo un poco vamos a coger como ejemplo el siguiente verso de <a class="reference external" href="https://www.youtube.com/watch?v=dv958EeZXHc">esta canción</a> de <em>Mecano</em>, que es una versión simplificada del verso de Stein:</p>
<blockquote>
<div><p>“Una rosa es una rosa es” <a class="footnote-reference brackets" href="#id5" id="id2">2</a></p>
</div></blockquote>
<p>En este verso encontramos tres <em>types</em>:</p>
<ul class="simple">
<li><p>“una”</p></li>
<li><p>“rosa”</p></li>
<li><p>“es”;</p></li>
</ul>
<p>pero seis <em>tokens</em>: 2 <em>tokens</em> del <em>type</em> “una”, 2 del <em>type</em> “rosa” y 2 del <em>type</em> “es”. Son por tanto <span class="math notranslate nohighlight">\(2+2+2 = 6\)</span> <em>tokens</em>. Este texto está formado por seis <em>tokens</em> y tres <em>types</em>.</p>
<p>Como se puede comprobar, esta diferencia es la base conceptual del cálculo de frecuencias textuales. El cálculo más simple es contar, como se ha hecho antes, la cantidad de <em>tokens</em> de cada <em>type</em> en un texto:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><em>type</em></p></th>
<th class="head"><p><em>tokens</em></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>una</p></td>
<td><p><span class="math notranslate nohighlight">\(2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>rosa</p></td>
<td><p><span class="math notranslate nohighlight">\(2\)</span></p></td>
</tr>
<tr class="row-even"><td><p>es</p></td>
<td><p><span class="math notranslate nohighlight">\(2\)</span></p></td>
</tr>
</tbody>
</table>
<p>En esta línea, <strong>el tamaño de un corpus siempre se mide en cantidad de <em>tokens</em>.</strong></p>
<section id="tokenizacion">
<h3><span class="section-number">3.1.1. </span>Tokenización<a class="headerlink" href="#tokenizacion" title="Permalink to this headline">#</a></h3>
<p>El primer paso a la hora de procesar un texto es, por tanto, hallar los <em>tokens</em> y, con ello, los <em>types</em> que forman el texto. A este proceso se le denomina <strong>tokenización</strong>.</p>
<p>El método de tokenización más simple es separar cada token por espacio en blaco. <em>Token</em> quedaría así definido como la secunencia de caracteres separada por un espacio en blanco. Desde un punto de vista lingüístico, esta aproximación presenta algunas limitaciones:</p>
<ul class="simple">
<li><p>signos de puntuación,</p></li>
<li><p>unidades multipalabra (como formas complejas del verbo Ej. “he comido”) o</p></li>
<li><p>contracciones (“del”, “al”) y en general formas aglutinantes (“dáselo”).</p></li>
</ul>
<p>Necesidad de modelos más sofisticados. <!-- Hoy día es un problema resuelto --></p>
<!-- Por otro lado, no siempre es necesario detectar la secuencia entre blancos. ver Stemmer, tokenización en word embeddings, incluso tokenización por carácter. -->
</section>
<section id="lematizacion-y-stemming">
<h3><span class="section-number">3.1.2. </span>Lematización y <em>stemming</em><a class="headerlink" href="#lematizacion-y-stemming" title="Permalink to this headline">#</a></h3>
<p><em>Type</em> y <em>token</em> se refieren siempre a formas flexionadas, es decir, a formas con variaciones morfológicas. Así, “catamos” y “cantaré” son <em>tokens</em> distintos; al igual que “casa” y “casas”.</p>
<p>Para agrupar todos los <em>tokens</em> relacionados con la misma palabra (es decir, la forma sin flexionar o la unidad léxica que podemos encontrar, por ejemplo, en los diccionarios) se realiza un proceso de <em>lematización</em>. La lematización es asignar a cada palabra su forma no marcada: infinitivo para verbos, forma masculino singular para nombres y verbos (es decir, la forma que aparece en el diccionario). El lema es una manera de nombrar la palabra en toda su diversidad flexiva.</p>
<p>La lematización es un fenómenos complejo porque es necesario analizar morfológicamente la palabra para determinar su lema. Ej. El lema del <em>token</em> “traje” puede ser “traer” (si es verbo) o “traje” (si es nombre).</p>
<p>Un proceso similar pero más sencillo es el <em>stemming</em>: reducir cada <em>token</em> a su raíz o lexema (la parte invarible que, en principio, asume el significado general de la palabra).</p>
<blockquote>
<div><p><em>Reflexión:</em> para minería de textos, ¿qué es mejor, dejar el corpus con los <em>tokens</em>, lematizarlo o trabajar solo con las raíces léxicas (<em>stemm</em>)?</p>
</div></blockquote>
</section>
</section>
<section id="analisis-morfologico-y-categorial">
<h2><span class="section-number">3.2. </span>Análisis morfológico y categorial.<a class="headerlink" href="#analisis-morfologico-y-categorial" title="Permalink to this headline">#</a></h2>
<p>El objetivo general de la anotación categorial (<em>PoS Tagger</em>): asignar a cada palabra de un texto su categoría gramatical correspondiente. En concreto, a cada <em>token</em> del texto (incluidos signos de puntuación, etc) se le asigna:</p>
<ul class="simple">
<li><p>lema,</p></li>
<li><p>categoría gramatical,</p></li>
<li><p>rasgos morfológicos.</p></li>
</ul>
<p>El mayor problema viene en la selección de la categoría gramatical por los problemas de <em>ambigüedad categorial</em> que vimos en la sesión anterior.</p>
<section id="fundamentos-linguisticos-a-modo-de-recordatorio">
<h3><span class="section-number">3.2.1. </span>Fundamentos lingüísticos (a modo de recordatorio).<a class="headerlink" href="#fundamentos-linguisticos-a-modo-de-recordatorio" title="Permalink to this headline">#</a></h3>
<p>Categorías gramaticales: agrupaciones de palabras (“paradigmas”) según sus rasgos distributivos, morfológicos y (en menor medida) semánticos.</p>
<p>ESP: determinantes (artículo, demostrativos, etc.), sustantivos, adjetivos, pronombres, verbos, adverbios, preposiciones, conjunciones e interjecciones.</p>
<p>Por su función en el texto: categorías con significado léxico vs. “significado” gramatical (solo aportan información gramatical).</p>
<p>Por su flexión: variables e invariables.</p>
<p>Categorías abiertas vs cerradas.</p>
</section>
<section id="importancia-en-mineria-de-textos">
<h3><span class="section-number">3.2.2. </span>Importancia en Minería de textos<a class="headerlink" href="#importancia-en-mineria-de-textos" title="Permalink to this headline">#</a></h3>
<p>Base para análisis sintáctico y semántico.</p>
<p>Un pre-proceso muy común en Minería de Textos es eliminar las “stop-words”, es decir, las palabras de categorías gramaticales sin significado semántico (artículos, preposiciones, conjunciones, etc.). En ocasiones además las palabras se lematizan. En ambos casos es necesario un análisis categorial (aunque sea un simple filtro de “stop-words”). Algunas aplicaciones dependen de las categorías gramaticales, como:</p>
<ul class="simple">
<li><p>extracción de entidades –&gt; nombres propios;</p></li>
<li><p>extracción de eventos –&gt; verbos y nombres;</p></li>
<li><p>extracción de sentimientos –&gt; adjetivos;</p></li>
<li><p>detección de autoría –&gt; categorías cerradas;</p></li>
<li><p>etc.</p></li>
</ul>
</section>
<section id="representacion-de-la-informacion-morfologica-y-categorial">
<h3><span class="section-number">3.2.3. </span>Representación de la información morfológica y categorial<a class="headerlink" href="#representacion-de-la-informacion-morfologica-y-categorial" title="Permalink to this headline">#</a></h3>
<p>La información categorial y morfológica se representa explícitamente mediante etiquetas.</p>
<p>Actualmente hay diversas propuestas. Es necesario saber con qué juego de etiquetas representa la información el sistema de PoS que estemos utilizando par poder interpretar la información correctamente.</p>
<p>Algunas propuestas:</p>
<ul class="simple">
<li><p>Penn Treebank tag set:</p></li>
</ul>
<p><a class="reference external" href="https://www.cs.upc.edu/~nlp/SVMTool/PennTreebank.html">https://www.cs.upc.edu/~nlp/SVMTool/PennTreebank.html</a></p>
<ul class="simple">
<li><p>EAGLES tag set:</p></li>
</ul>
<p><a class="reference external" href="http://www.ilc.cnr.it/EAGLES96/annotate/annotate.html">http://www.ilc.cnr.it/EAGLES96/annotate/annotate.html</a></p>
<p><a class="reference external" href="http://blade10.cs.upc.edu/freeling-old/doc/tagsets/tagset-es.html">http://blade10.cs.upc.edu/freeling-old/doc/tagsets/tagset-es.html</a></p>
<p><a class="reference external" href="https://freeling-user-manual.readthedocs.io/en/latest/tagsets/">https://freeling-user-manual.readthedocs.io/en/latest/tagsets/</a></p>
<ul class="simple">
<li><p>Universal tagset (<em>Universal dependencies project</em>):</p></li>
</ul>
<p><a class="reference external" href="https://universaldependencies.org/u/pos/">https://universaldependencies.org/u/pos/</a></p>
</section>
<section id="arquitectura-de-un-pos-tagger-algoritmos-clasicos-de-desambiguacion">
<h3><span class="section-number">3.2.4. </span>Arquitectura de un <em>PoS_tagger</em>. Algoritmos clásicos de desambiguación.<a class="headerlink" href="#arquitectura-de-un-pos-tagger-algoritmos-clasicos-de-desambiguacion" title="Permalink to this headline">#</a></h3>
<p><img alt="ArquitecturaPoStagger" src="_images/arquitecturaPoStagger.png" /></p>
<p>Ejemplo: Freeling.</p>
</section>
<section id="algoritmos-de-desambiguacion-categorial-aproximacion-historica">
<h3><span class="section-number">3.2.5. </span>Algoritmos de desambiguación categorial (aproximación histórica)<a class="headerlink" href="#algoritmos-de-desambiguacion-categorial-aproximacion-historica" title="Permalink to this headline">#</a></h3>
<section id="modelo-de-reglas-simples">
<h4><span class="section-number">3.2.5.1. </span>Modelo de reglas simples.<a class="headerlink" href="#modelo-de-reglas-simples" title="Permalink to this headline">#</a></h4>
<p>Sistema TAGGIT (1950).
71 etiquetas + 3300 reglas. 77% de precisión.</p>
<p>Reglas: expresiones regulares tipo</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>\b.*ing\b = Verbo Infinitivo
\b.*mente\b = adverbio
las\s[a-z]*as → Nombre femenino plural
etc.
</pre></div>
</div>
</section>
</section>
<section id="modelo-estadistico-cadena-de-markov">
<h3><span class="section-number">3.2.6. </span>Modelo estadístico: cadena de markov.<a class="headerlink" href="#modelo-estadistico-cadena-de-markov" title="Permalink to this headline">#</a></h3>
<p>Tiene en cuenta el contexto de aparición de las palabras.
Basados en bigramas.</p>
<p>Calculan dos tipos de probabilidades:
Léxica: p(W|T)
Contextual: p(W|T|Ctx)</p>
<p>ctx = palabra anterior –&gt; bigrama.</p>
</section>
<section id="modelo-oculto-de-markov">
<h3><span class="section-number">3.2.7. </span>Modelo oculto de Markov<a class="headerlink" href="#modelo-oculto-de-markov" title="Permalink to this headline">#</a></h3>
<p>Basado en la probabilidad de cadenas de etiquetas (cadena oculta).</p>
<p>Dos tipos de probabilidades:</p>
<ul class="simple">
<li><p>Probabilidad de emisión = p(W|T)</p></li>
<li><p>Probabilidad de transmisión = p(T|T-1). Esta es la parte oculta.</p></li>
</ul>
<p>Así, la probabilidad final queda como:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>p(W|T) = p(W|T) * p(T|T-1)
</pre></div>
</div>
<p>Proceso iterativo: primero analiza lo no ambiguo, luego hace una segunda vuelta calculando probabilidades de transición y re-anotando, hasta llegar a situación estable (fin).</p>
</section>
<section id="gramaticas-de-restricciones-constraint-grammar">
<h3><span class="section-number">3.2.8. </span>Gramáticas de restricciones (<em>Constraint grammar</em>)<a class="headerlink" href="#gramaticas-de-restricciones-constraint-grammar" title="Permalink to this headline">#</a></h3>
<p>Modelo teórico: este tipo de gramáticas no dice cómo es un idioma, sino cómo NO es.</p>
<p>Las reglas, por tanto, son reglas negativas. Dada una ambigüedad, las reglas indican cuál de las opciones seguro que no es. Combinando restricciones se llega al final a la solución correcta.</p>
<p>Las reglas son condicionales al contexto (si la palabra anterior es X, la siguiente NO es Y).</p>
<p>Ejemplo:
“Un verbo no va precedido de artículo”.</p>
<p>Sistema ENGCG de 1990 (Karlsson et al 1995)</p>
</section>
<section id="modelos-basados-en-aprendizaje-automatico">
<h3><span class="section-number">3.2.9. </span>Modelos basados en aprendizaje automático.<a class="headerlink" href="#modelos-basados-en-aprendizaje-automatico" title="Permalink to this headline">#</a></h3>
<p>Sistemas supervisados. Aprendizaje a partir de un corpsu anotado a mano y validado por lingüistas.</p>
<p>Diferentes algoritmos: árboles de decisión, vectores de soporte (SVM), etc.</p>
<p>Ejemplo “Transformation-based Tagger” (Brill 1995). Proceso iterativo donde va aprendiendo reglas, cada vez más específicas. Analiza aplicando primero las específicas y luego las generales. Refinamiento: revisón manual de cada iteración.</p>
</section>
<section id="situacion-actual">
<h3><span class="section-number">3.2.10. </span>Situación actual<a class="headerlink" href="#situacion-actual" title="Permalink to this headline">#</a></h3>
<p>Aproximaciones multilingües basadas en <em>embeddings</em> y redes neuronales:</p>
<p><a class="reference external" href="http://nlpprogress.com/english/part-of-speech_tagging.html">http://nlpprogress.com/english/part-of-speech_tagging.html</a></p>
</section>
<section id="recursos">
<h3><span class="section-number">3.2.11. </span>Recursos.<a class="headerlink" href="#recursos" title="Permalink to this headline">#</a></h3>
<p>Cualquier sistema de PLN parte de un PoS tagger. Es el análisis básico.</p>
<ul class="simple">
<li><p>Freeling <a class="reference external" href="http://nlp.lsi.upc.edu/freeling/index.php/">http://nlp.lsi.upc.edu/freeling/index.php/</a></p></li>
<li><p>SpaCy: <a class="reference external" href="https://spacy.io/">https://spacy.io/</a></p></li>
<li><p>NLTK: <a class="reference external" href="http://www.nltk.org/">http://www.nltk.org/</a></p></li>
<li><p>Standford CORE NLP: <a class="reference external" href="https://stanfordnlp.github.io/CoreNLP/">https://stanfordnlp.github.io/CoreNLP/</a></p></li>
<li><p>Google CLOUD: <a class="reference external" href="https://cloud.google.com/natural-language/">https://cloud.google.com/natural-language/</a></p></li>
</ul>
<p>y muchos más</p>
</section>
</section>
<section id="analisis-sintactico">
<h2><span class="section-number">3.3. </span>Análisis sintáctico.<a class="headerlink" href="#analisis-sintactico" title="Permalink to this headline">#</a></h2>
<p>Sintaxis: agrupación y relaciones de las palabras dentro de una oración.</p>
<p>Análisis automático: <em>parser</em></p>
<section id="arquitectura-estandar-de-un-parser">
<h3><span class="section-number">3.3.1. </span>Arquitectura estándar de un <em>parser</em><a class="headerlink" href="#arquitectura-estandar-de-un-parser" title="Permalink to this headline">#</a></h3>
<p><img alt="ArquitecturaParser" src="_images/parser.png" /></p>
</section>
<section id="modelos-de-representacion">
<h3><span class="section-number">3.3.2. </span>Modelos de representación<a class="headerlink" href="#modelos-de-representacion" title="Permalink to this headline">#</a></h3>
<p>Análisis basado en <em>constituyentes</em></p>
<p><img alt="Constituyentes" src="_images/constituyentes.png" /></p>
<p>Análisis basado en <em>dependencias</em></p>
<p><img alt="Dependecias_Freeling" src="_images/dependency_parsing_FreeLing.jpg" /></p>
<p>(Créditos de la imagen <a class="reference external" href="http://liceu.uab.cat/~joaquim/language_technology/NLP/PLN_analisis.html#An%C3%A1lisis_de_dependencias">aquí</a>)</p>
</section>
<section id="principal-problema-computacional">
<h3><span class="section-number">3.3.3. </span>Principal problema computacional<a class="headerlink" href="#principal-problema-computacional" title="Permalink to this headline">#</a></h3>
<p>Ambigüedad estructural:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;Ayer vi a tu hermano con los prismáticos&quot;
</pre></div>
</div>
<p>Ambigüedad coordinación:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;Sirve los platos y los cubiertos limpios&quot;
</pre></div>
</div>
</section>
<section id="gramaticas-formales">
<h3><span class="section-number">3.3.4. </span>Gramáticas formales<a class="headerlink" href="#gramaticas-formales" title="Permalink to this headline">#</a></h3>
<p>Conjunto de reglas formales de análisis sintático.</p>
<section id="context-free-grammars">
<h4><span class="section-number">3.3.4.1. </span>Context free grammars<a class="headerlink" href="#context-free-grammars" title="Permalink to this headline">#</a></h4>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>G = (NT, T, S, P)
NT: {no terminales},
T: {terminales},
S: Símbolo inicial
P: Reglas de producción A -&gt; w: 
    A   NT
    W   (NT U T)*
</pre></div>
</div>
<p>Tal que</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>NT ={S,NP,VP,nprop,n,v,det}, 
T ={Pepe,manzana, come,una},
P:
    S -&gt; NP VP
    NP -&gt; nprop
    NP -&gt; det  n
    VP -&gt; v
    VP -&gt; v NP
</pre></div>
</div>
<p><img alt="AnalisisConstituyentes" src="_images/constituyentes_2.png" /></p>
<p>Estas gramáticas eran muy limitadas y fueron ampliadas con estructuras de rasgos y técnicas de unificación.</p>
<p><img alt="Unificación" src="_images/unificacion.png" /></p>
<p>En lingüística se han desarrollado diferentes modelos basados en estas técnicas las <em>Head-driven phrase structure grammar</em> o las <em>Lexical-Functional Grammar</em> (que sigue siendo un modelo válido: <a class="reference external" href="https://ling.sprachwiss.uni-konstanz.de/pages/home/lfg/">https://ling.sprachwiss.uni-konstanz.de/pages/home/lfg/</a> )</p>
</section>
<section id="probabilistic-context-free-grammar-y-modelos-probabilisticos">
<h4><span class="section-number">3.3.4.2. </span><em>Probabilistic Context Free Grammar</em> y modelos probabilísticos<a class="headerlink" href="#probabilistic-context-free-grammar-y-modelos-probabilisticos" title="Permalink to this headline">#</a></h4>
<p>Añaden peso estadístico a cada regla.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>SV → V SP SP (0.5)
SV → V SP (0.3)
SV → V (0.2)
</pre></div>
</div>
<p>Modelos de aprendizaje automático.</p>
<p>Corpus de aprendizaje y evaluación: <em>treebanks</em></p>
<ul class="simple">
<li><p>Penn Treebank:</p>
<ul>
<li><p><a class="reference external" href="https://catalog.ldc.upenn.edu/LDC99T42">https://catalog.ldc.upenn.edu/LDC99T42</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/nltkdata/penn-tree-bank">https://www.kaggle.com/nltkdata/penn-tree-bank</a></p></li>
</ul>
</li>
<li><p>Ancora (español, catalán):</p>
<ul>
<li><p><a class="reference external" href="http://clic.ub.edu/corpus/en/ancora-descarregues">http://clic.ub.edu/corpus/en/ancora-descarregues</a></p></li>
</ul>
</li>
</ul>
<p>Y muchos otros</p>
</section>
</section>
<section id="chunkers">
<h3><span class="section-number">3.3.5. </span><em>Chunkers</em><a class="headerlink" href="#chunkers" title="Permalink to this headline">#</a></h3>
<p>En ocasiones el análisis sintáctico completo (<em>full parsing</em>) es complejo, consume mucho recurso y no suele obtener buenos resultados.</p>
<p>Lo normal es realizar <em>análisis sintáctico parcial</em> o <em>chunkers</em>: extraer agrupaciones sintáticas (<em>chunks</em>) sin llegar a derivar el árbol sintáctico completo (Abney 1991).</p>
</section>
<section id="estrategias">
<h3><span class="section-number">3.3.6. </span>Estrategias<a class="headerlink" href="#estrategias" title="Permalink to this headline">#</a></h3>
<p>Descendente:
Recursive Descendent:</p>
<p>(El siguiente código es Python y requiere tener instalado <a class="reference external" href="https://www.nltk.org/">NLTK</a>)</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import nltk
nltk.app.rdparser()
</pre></div>
</div>
<p>Ascendente
Shift Reduce:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import nltk
nltk.app.srparser()
</pre></div>
</div>
</section>
<section id="formato-conll">
<h3><span class="section-number">3.3.7. </span>Formato CONLL<a class="headerlink" href="#formato-conll" title="Permalink to this headline">#</a></h3>
<p>Formato de salida estándar en análisis de dependencias. Además de la información morfológica, por cada palabra indica de quién depende y el tipo de dependencia.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    Salida CoNLL-U
    # sent_id = 1
    # text = Los hombres que fuman puro tienen cara de canguro .
    1   Los el  DET DET Definite=Def|Gender=Masc|Number=Plur|PronType=Art   2   det _   _
    2   hombres hombre  NOUN    NOUN    Gender=Masc|Number=Plur 6   nsubj   _   _
    3   que que PRON    PRON    PronType=Int,Rel    4   nsubj   _   _
    4   fuman   fumar   VERB    VERB    Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin   2   acl _   _
    5   puro    puro    ADJ ADJ Gender=Masc|Number=Sing 4   obj _   _
    6   tienen  tener   VERB    VERB    Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin   0   root    _   _
    7   cara    cara    NOUN    NOUN    Gender=Fem|Number=Sing  6   obj _   _
    8   de  de  ADP ADP _   9   case    _   _
    9   canguro canguro NOUN    NOUN    Gender=Masc|Number=Sing 7   nmod    _   _
    10  .   .   PUNCT   PUNCT   PunctType=Peri  6   punct   _   _
</pre></div>
</div>
</section>
<section id="id3">
<h3><span class="section-number">3.3.8. </span>Situación actual<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h3>
<p><em>Transition-based dependency parsing</em> (Nivre 2014). Algoritmo shift-reduce.</p>
<p><em>Neural Network Dependency Parser</em>: <a class="reference external" href="https://nlp.stanford.edu/software/nndep.shtml">https://nlp.stanford.edu/software/nndep.shtml</a></p>
<p>Modelo de dependencias universal: <a class="reference external" href="https://universaldependencies.org/"><em>Universal Dependencies</em></a>:</p>
<blockquote>
<div><p>The Universal Dependencies project (Nivre et al., 2016) provides an inventory of dependency relations that arelinguistically motivated, computationally useful, and cross-linguistically applicable. (Juravsky y Martin 2020, cap. 14)</p>
</div></blockquote>
<p>Representación vectorial (<em>embeddings</em>).</p>
<p><a class="reference external" href="http://nlpprogress.com/english/constituency_parsing.html">http://nlpprogress.com/english/constituency_parsing.html</a></p>
<p><a class="reference external" href="http://nlpprogress.com/english/constituency_parsing.html">http://nlpprogress.com/english/dependency_parsing.html</a></p>
</section>
<section id="herramientas">
<h3><span class="section-number">3.3.9. </span>Herramientas<a class="headerlink" href="#herramientas" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>SpaCy: <a class="reference external" href="https://spacy.io/">https://spacy.io/</a></p></li>
<li><p>STANZA: <a class="reference external" href="https://stanfordnlp.github.io/stanza/">https://stanfordnlp.github.io/stanza/</a></p></li>
<li><p>Freeling: <a class="reference external" href="https://nlp.lsi.upc.edu/freeling/node/1">https://nlp.lsi.upc.edu/freeling/node/1</a></p></li>
<li><p>UD-Pipe: <a class="reference external" href="https://ufal.mff.cuni.cz/udpipe">https://ufal.mff.cuni.cz/udpipe</a></p></li>
</ul>
</section>
</section>
<section id="bibliografia">
<h2><span class="section-number">3.4. </span>Bibliografía<a class="headerlink" href="#bibliografia" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Abney S.P. (1991) “Parsing By Chunks”. In: Berwick R.C., Abney S.P., Tenny C. (eds) Principle-Based Parsing. Studies in Linguistics and Philosophy, vol 44. Springer, Dordrecht. <a class="reference external" href="https://doi.org/10.1007/978-94-011-3474-3_10">https://doi.org/10.1007/978-94-011-3474-3_10</a></p></li>
<li><p>Juravsky y Martin (2020) <em>Speech and Language Processing</em>. <a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</a></p></li>
<li><p>Karlsson, F., A. Voutilainen, J. Heikkilä, and A. Anttila (eds.). 1995. <em>Constraint Grammar. A language-independent system for parsing unrestricted text</em>. Berlin and New-York: Mouton de Gruyter</p></li>
</ul>
<hr class="docutils" />
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>“Token” se asimila en este caso a “occurrence”. Cfr. <a class="reference external" href="https://plato.stanford.edu/entries/types-tokens/#Occ">https://plato.stanford.edu/entries/types-tokens/#Occ</a></p>
</dd>
<dt class="label" id="id5"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Este verso es una adaptación del verso de Gertrude Stein “A rose is a rose is a rose”. Ver <a class="reference external" href="https://es.wikipedia.org/wiki/Rosa_es_una_rosa_es_una_rosa_es_una_rosa">https://es.wikipedia.org/wiki/Rosa_es_una_rosa_es_una_rosa_es_una_rosa</a>.</p>
</dd>
</dl>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="bloque1_1Introduccion.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">2. </span>Minería de textos y procesamiento del lenguaje natural.</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="bloque1_3AnalisisSemantico.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Análisis semántico</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Universitat d'Alacant<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>