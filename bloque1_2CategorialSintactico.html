
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3. Análisis categorial y sintáctico &#8212; Minería de Textos</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/estilos.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Práctica 1." href="bloque1_Practica1.html" />
    <link rel="prev" title="2. Minería de textos y procesamiento del lenguaje natural." href="bloque1_1Introduccion.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-master-ca.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Minería de Textos</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Materiales de Minería de Textos
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Bloque 1
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1.html">
   1. Introducción a la minería de textos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_1Introduccion.html">
   2. Minería de textos y procesamiento del lenguaje natural.
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3. Análisis categorial y sintáctico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica1.html">
   4. Práctica 1.
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_3AnalisisSemantico.html">
   5. Análisis semántico
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_4AnalisisSemanticoVectorial.html">
   6. Análisis semántico vectorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bloque1_Practica2.html">
   7. Práctica 1b :
   <em>
    Topic modeling
   </em>
   .
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Extras
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="content.html">
   8. Content in Jupyter Book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markdown.html">
   9. Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="notebooks.html">
   10. Content with notebooks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/bloque1_2CategorialSintactico.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unidades-de-comunicacion-basica-la-palabra-type-token-y-lema">
   3.1. Unidades de comunicación básica. La palabra.
   <em>
    Type
   </em>
   ,
   <em>
    token
   </em>
   y lema.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenizacion">
     3.1.1. Tokenización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lematizacion-y-stemming">
     3.1.2. Lematización y
     <em>
      stemming
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analisis-morfologico-y-categorial">
   3.2. Análisis morfológico y categorial.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algunos-conceptos-linguisticos">
     3.2.1. Algunos conceptos lingüísticos.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relevancia-del-analisis-categorial-en-mineria-de-textos">
     3.2.2. Relevancia del análisis categorial en minería de textos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-formal-de-la-informacion-morfologica-y-categorial">
     3.2.3. Representación formal de la información morfológica y categorial
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arquitectura-de-un-pos-tagger">
     3.2.4. Arquitectura de un
     <em>
      PoS_tagger
     </em>
     .
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algoritmos-de-desambiguacion-categorial">
     3.2.5. Algoritmos de desambiguación categorial.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modelo-basado-en-reglas-simbolicos">
       3.2.5.1. Modelo basado en reglas (simbólicos).
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#gramaticas-de-restricciones-constraint-grammar">
         3.2.5.1.1. Gramáticas de restricciones (
         <em>
          Constraint grammar
         </em>
         )
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modelos-estadisticos">
       3.2.5.2. Modelos estadísticos
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#cadena-de-markov">
         3.2.5.2.1. Cadena de Markov
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#modelo-oculto-de-markov">
         3.2.5.2.2. Modelo oculto de Markov
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#conditional-random-fields-y-otros">
         3.2.5.2.3.
         <em>
          Conditional Random Fields
         </em>
         y otros.
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#situacion-actual">
     3.2.6. Situación actual
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recursos">
     3.2.7. Recursos.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analisis-sintactico">
   3.3. Análisis sintáctico.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arquitectura-estandar-de-un-parser">
     3.3.1. Arquitectura estándar de un
     <em>
      parser
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principal-problema-computacional">
     3.3.2. Principal problema computacional
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-de-representacion">
     3.3.3. Modelos de representación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gramaticas-formales">
     3.3.4. Gramáticas formales
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#context-free-grammars">
       3.3.4.1. Context free grammars
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modelos-probabilisticos">
       3.3.4.2. Modelos probabilísticos
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chunkers">
     3.3.5.
     <em>
      Chunkers
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estrategias">
     3.3.6. Estrategias
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-dependencias">
     3.3.7. Análisis de dependencias
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#formato-de-representacion-conll">
       3.3.7.1. Formato de representación: CONLL
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dependencias-universales">
       3.3.7.2. Dependencias universales
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#analisis">
       3.3.7.3. Análisis
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     3.3.8. Situación actual
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#herramientas">
     3.3.9. Herramientas
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   3.4. Bibliografía
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cuestionario-de-aprendizaje">
   3.5. Cuestionario de aprendizaje
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Análisis categorial y sintáctico</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#unidades-de-comunicacion-basica-la-palabra-type-token-y-lema">
   3.1. Unidades de comunicación básica. La palabra.
   <em>
    Type
   </em>
   ,
   <em>
    token
   </em>
   y lema.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#tokenizacion">
     3.1.1. Tokenización
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lematizacion-y-stemming">
     3.1.2. Lematización y
     <em>
      stemming
     </em>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analisis-morfologico-y-categorial">
   3.2. Análisis morfológico y categorial.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algunos-conceptos-linguisticos">
     3.2.1. Algunos conceptos lingüísticos.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#relevancia-del-analisis-categorial-en-mineria-de-textos">
     3.2.2. Relevancia del análisis categorial en minería de textos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#representacion-formal-de-la-informacion-morfologica-y-categorial">
     3.2.3. Representación formal de la información morfológica y categorial
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arquitectura-de-un-pos-tagger">
     3.2.4. Arquitectura de un
     <em>
      PoS_tagger
     </em>
     .
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algoritmos-de-desambiguacion-categorial">
     3.2.5. Algoritmos de desambiguación categorial.
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modelo-basado-en-reglas-simbolicos">
       3.2.5.1. Modelo basado en reglas (simbólicos).
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#gramaticas-de-restricciones-constraint-grammar">
         3.2.5.1.1. Gramáticas de restricciones (
         <em>
          Constraint grammar
         </em>
         )
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modelos-estadisticos">
       3.2.5.2. Modelos estadísticos
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#cadena-de-markov">
         3.2.5.2.1. Cadena de Markov
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#modelo-oculto-de-markov">
         3.2.5.2.2. Modelo oculto de Markov
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#conditional-random-fields-y-otros">
         3.2.5.2.3.
         <em>
          Conditional Random Fields
         </em>
         y otros.
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#situacion-actual">
     3.2.6. Situación actual
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recursos">
     3.2.7. Recursos.
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analisis-sintactico">
   3.3. Análisis sintáctico.
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arquitectura-estandar-de-un-parser">
     3.3.1. Arquitectura estándar de un
     <em>
      parser
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#principal-problema-computacional">
     3.3.2. Principal problema computacional
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-de-representacion">
     3.3.3. Modelos de representación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gramaticas-formales">
     3.3.4. Gramáticas formales
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#context-free-grammars">
       3.3.4.1. Context free grammars
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#modelos-probabilisticos">
       3.3.4.2. Modelos probabilísticos
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#chunkers">
     3.3.5.
     <em>
      Chunkers
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estrategias">
     3.3.6. Estrategias
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-dependencias">
     3.3.7. Análisis de dependencias
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#formato-de-representacion-conll">
       3.3.7.1. Formato de representación: CONLL
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dependencias-universales">
       3.3.7.2. Dependencias universales
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#analisis">
       3.3.7.3. Análisis
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     3.3.8. Situación actual
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#herramientas">
     3.3.9. Herramientas
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   3.4. Bibliografía
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cuestionario-de-aprendizaje">
   3.5. Cuestionario de aprendizaje
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="analisis-categorial-y-sintactico">
<span id="label-pos"></span><h1><span class="section-number">3. </span>Análisis categorial y sintáctico<a class="headerlink" href="#analisis-categorial-y-sintactico" title="Permalink to this headline">#</a></h1>
<div class="note admonition">
<p class="admonition-title">Nota</p>
<p>Para preparar este tema, tras leer este documento, debes leer los capítulos 8 y 18 de Juravsky y Martin (2022) <em>Speech and Language Processing</em>. <a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</a>. Durante la explicación a continuación se indica qué secciones son las más relevantes.
Al final de esta página tienes el enlace para realizar el cuestionario de aprendizaje. Debéis realizarlo <strong>ANTES de la próxima clase</strong>.</p>
</div>
<section id="unidades-de-comunicacion-basica-la-palabra-type-token-y-lema">
<h2><span class="section-number">3.1. </span>Unidades de comunicación básica. La palabra. <em>Type</em>, <em>token</em> y lema.<a class="headerlink" href="#unidades-de-comunicacion-basica-la-palabra-type-token-y-lema" title="Permalink to this headline">#</a></h2>
<p>Si bien el concepto de “palabra” se suele utilizar como unidad mínima y básica de comunicación, realmente la palabra “palabra” no tiene en lingüística una definición clara: es un concepto vago muy difícil de delimitar.</p>
<p>En lingüística de corpus, lingüística computacional y procesamiento del lenguaje natural, más que con el concepto de “palabra”, se trabaja con los conceptos de <em>type</em> (“tipo”) y <em>token</em> (“caso”) (<a class="reference external" href="https://es.wikipedia.org/wiki/Caso_y_tipo">introducidos por el filósofo Charles S. Peirce</a> a principio de siglo XX):</p>
<ul class="simple">
<li><p><em>Type</em> es la palabra entendida como clase o tipo. Una secuencia de caracteres diferente de cualquier otra secuencia.</p></li>
<li><p><em>Token</em> es cada una de las instancias o casos concretos de esas clase <em>type</em> que se pueda hallar en un texto <a class="footnote-reference brackets" href="#id8" id="id1">1</a>.</p></li>
</ul>
<p>Se suele ejemplificar la diferencia entre ambos conceptos con el verso de G. Stein:</p>
<blockquote>
<div><p>“Rose is a rose is a rose is a rose”;</p>
</div></blockquote>
<p>pero para españolizarlo un poco vamos a coger como ejemplo el siguiente verso de <a class="reference external" href="https://www.youtube.com/watch?v=dv958EeZXHc">esta canción</a> de <em>Mecano</em>, que es una versión simplificada del verso de Stein:</p>
<blockquote>
<div><p>“Una rosa es una rosa es”.</p>
</div></blockquote>
<p>En este verso encontramos tres <em>types</em>:</p>
<ul class="simple">
<li><p>“una”</p></li>
<li><p>“rosa”</p></li>
<li><p>“es”;</p></li>
</ul>
<p>pero seis <em>tokens</em>: 2 <em>tokens</em> del <em>type</em> “una”, 2 del <em>type</em> “rosa” y 2 del <em>type</em> “es”. Son por tanto <span class="math notranslate nohighlight">\(2+2+2 = 6\)</span> <em>tokens</em>. Este texto está formado por seis <em>tokens</em> y tres <em>types</em>.</p>
<p>Como se puede comprobar, esta diferencia es la base conceptual del cálculo de frecuencias textuales. El cálculo más simple es contar, como se ha hecho antes, la cantidad de <em>tokens</em> de cada <em>type</em> en un texto:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><em>type</em></p></th>
<th class="head"><p><em>tokens</em></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>una</p></td>
<td><p><span class="math notranslate nohighlight">\(2\)</span></p></td>
</tr>
<tr class="row-odd"><td><p>rosa</p></td>
<td><p><span class="math notranslate nohighlight">\(2\)</span></p></td>
</tr>
<tr class="row-even"><td><p>es</p></td>
<td><p><span class="math notranslate nohighlight">\(2\)</span></p></td>
</tr>
</tbody>
</table>
<p>En esta línea, <strong>el tamaño de un corpus siempre se mide en cantidad de <em>tokens</em>.</strong></p>
<section id="tokenizacion">
<h3><span class="section-number">3.1.1. </span>Tokenización<a class="headerlink" href="#tokenizacion" title="Permalink to this headline">#</a></h3>
<p>El primer paso a la hora de procesar un texto es, por tanto, hallar los <em>tokens</em> y, con ello, los <em>types</em> que forman el texto. A este proceso se le denomina <strong>tokenización</strong>.</p>
<p>El método de tokenización más simple es separar cada token por espacio en blaco. <em>Token</em> quedaría así definido como la secunencia de caracteres separada por un espacio en blanco. Desde un punto de vista lingüístico, esta aproximación presenta algunas limitaciones:</p>
<ol class="simple">
<li><p>Los signos de puntuación son un <em>type</em> diferente, pero aparecen pegados a la palabra anterior o posterio. Es necesario algún tipo de regla más allá del espacio en blanco que separe los signos de puntuación.</p></li>
<li><p>Hay unidades lingüísticas que están formadas por más de un <em>type</em>. Me refiero a las llamadas “unidades multipalabra”, como por ejemplo las formas complejas de los verbos: “he comido”, “había creídos”, “fue resuelto”, etc.</p></li>
<li><p>La situación contraria se produce con las contracciones como “del” o “al” y en general formas aglutinantes (“dáselo”). En este caso se podría considerar <em>types</em> diferentes porque responde a diferentes palabras y habría que separarlas.</p></li>
</ol>
<p>Un <em>tokenizador</em> estándar resuelve el primer problema de los signos de puntuación, pero no los otros dos. Esto se deja para el lematizador, que se comentará después.</p>
<p>Por otro lado, no siempre la tokenización depende del espacio en blanco. Como se comentó antes, un <em>token</em> es la instancia de un <em>type</em>. Este puede ser cualquier secuencia de caracteres que se repitan en el texto, incluso se podría tokenizar por caracteres individuales. Los sistemas neuronales, por ejemplo, explotan diversas formas de tokenización para mejorar los análisis. En capítulos siguiente se verá cómo. Los sistemas de PLN estándar suelen trabajar con la tokenización por espacio en blanco. La herramienta NLTK (<em>Natural Language Toolkit</em>) dispone de diferentes <a class="reference external" href="https://www.nltk.org/api/nltk.tokenize.html">tokenizadores</a>.<a class="footnote-reference brackets" href="#id9" id="id2">2</a></p>
</section>
<section id="lematizacion-y-stemming">
<h3><span class="section-number">3.1.2. </span>Lematización y <em>stemming</em><a class="headerlink" href="#lematizacion-y-stemming" title="Permalink to this headline">#</a></h3>
<p><em>Type</em> y <em>token</em> se refieren siempre a formas flexionadas, es decir, a formas con variaciones morfológicas. Así, “catamos” y “cantaré” son <em>types</em> distintos; al igual que “casa” y “casas”.</p>
<p>Para agrupar todos los <em>tokens</em> relacionados con la misma palabra (es decir, la forma sin flexionar) se realiza un proceso de <em>lematización</em>. La lematización consiste en asignar a cada palabra lo que en lingüística se denomina su “forma no marcada” o lema: el infinitivo para verbos, o la forma masculino singular para nombres y adjetivos. La forma no marcada es la que aparece en el diccionario. El lema es una manera de nombrar la palabra en toda su diversidad flexiva.</p>
<p>La lematización es un fenómenos complejo porque para saber el lema de un <em>token</em> es necesario analizar morfológicamente la palabra. Hay muchos casos de ambigüedad. Por ejemplo, el lema del <em>token</em> “traje” puede ser tanto “traer” (si es verbo) como “traje” (si es nombre), como en el siguiente texto:</p>
<blockquote>
<div><ul class="simple">
<li><p>¿Usted no nada nada?</p></li>
<li><p>Es que no traje traje.</p></li>
</ul>
</div></blockquote>
<p>Por ello en algunas aplicaciones como en recuperación de información, en vez de una lematización completa, se utiliza un proceso similar pero más rápido y sencillo denominado <em><strong>stemming</strong></em>. Este consiste en reducir cada <em>token</em> a su raíz o lexema, es decir, la parte invarible del <em>token</em> (siempre y cuando responda a una flexió morfológica regular) que, en principio, asume el significado general de la palabra. Así, por ejemplo, de las diferentes formas del verbo “amar” (“amaría, amaré, amado, ame,” etc.), un <em>stemmer</em> reduciría cada <em>token</em> a su raíz “am-”, mientras que un lematizador lo relacionaría con el lema “amar”.</p>
<!-- *Reflexión:* para minería de textos, ¿qué es mejor, dejar el corpus con los *tokens*, lematizarlo o trabajar solo con las raíces léxicas (*stemm*)? -->
</section>
</section>
<section id="analisis-morfologico-y-categorial">
<h2><span class="section-number">3.2. </span>Análisis morfológico y categorial.<a class="headerlink" href="#analisis-morfologico-y-categorial" title="Permalink to this headline">#</a></h2>
<p>La herramienta de PLN que realiza el análisis morfológico y categorial es el <em>Part of Speech tagger</em> (<em>pos_tagger</em> o analizador categorial).</p>
<p>El objetivo principal de una analizador categorial es asignar a cada <em>token</em> de un texto su categoría gramatical correspondiente, incluidos signos de puntuación. En concreto, los datos que analiza un <em>pos_tagger</em> estándar suelen ser, por cada <em>token</em>:</p>
<ul class="simple">
<li><p>el lema,</p></li>
<li><p>la categoría gramatical (“nombre, verbo, adjetivo, …”),</p></li>
<li><p>rasgos morfológicos (género, número, voz, tiempo, etc.).</p></li>
</ul>
<p>El mayor problema que resuelve un analizador categorial es la <em>ambigüedad categorial</em> que vimos anteriormente: aquellos <em>tokens</em> que pueden pertencer a dos o más categorías gramaticales.</p>
<section id="algunos-conceptos-linguisticos">
<h3><span class="section-number">3.2.1. </span>Algunos conceptos lingüísticos.<a class="headerlink" href="#algunos-conceptos-linguisticos" title="Permalink to this headline">#</a></h3>
<p>A modo de recordatorio, en esta sección se repasan algunos conceptos lingüísticos que se deben tener claros para trabajar con <em>PoS_taggers</em>.<a class="footnote-reference brackets" href="#id10" id="id3">3</a></p>
<p>Las palabras de un idioma se clasifican en categorías gramaticales o “clases de palabras”. Cada categoría agrupas palabras que tienen un corportamiento lingüístico similar: palabras con rasgos distributivos y morfológicos similares, y en algunos casos también rasgos semánticos parecidos.</p>
<p>Si bien no hay una lista fija de categorías gramaticales (las diferentes teorías suelen presentar pequeñas variantes), en español las categorías gramaticales suelen ser: determinantes (incluyendo aquí artículos, demostrativos, posesivos, numerales e indefinidos), sustantivos, adjetivos, pronombres, verbos, adverbios, preposiciones, conjunciones e interjecciones.</p>
<p>Estas clases se agrupan en dos grandes grupos: las categorías abiertas y cerradas. Las abiertas son aquellas en las que constantemente está apareciendo palabras nuevas (neologismos) y desapareciendo otras (arcaísmos): nombres, verbos y adjetivos sobre todo. Las clases cerradas son las clases más estables porque apenas cambian en el tiempo (preposiciones, determinantes, conjunciones, interjecciones principalmente).</p>
<p>Este diferencia es relevante desde el punto de vista computacional por dos hechos:</p>
<ol class="simple">
<li><p>Todo sistema de PLN debe estar preparado para analizar palabras nuevas. En una clase abierta el sistema de PLN se puede encontrar con palabras que no ha visto nunca antes (bien porque no está en el diccionario, bien porque no está en los corpus de aprendizaje, o bien simplemente porque es un neologismo) y debe ser capaz de analizarla. Este problema se da sobre todo con los nombres. Los sistemas neuronales actuales han mostrado ser muy eficaces para tratar este problema.</p></li>
<li><p>Las clases cerradas suelene estar formadas por pocas palabras. Esto provoca que la frecuencia de uso de las palabras de clases cerradas (preposiciones, conjunciones, pronombres, etc.) sea muy alta. Así, al extraer las frecuencias de cualquier texto encontramos pocas palabras con frecuencias muy altas (las palabras de categorías cerradas) y muchas palabras con frecuencias muy bajas (el llamado <a class="reference external" href="https://es.wikipedia.org/wiki/H%C3%A1pax"><em>hápax legómena</em></a>, que se produce por la gran cantidad de palabras de categorías abiertas que aparecen solo una vez). Esto complica los análisis de frecuencia. Para evitar esta situación, las palabras de categoras cerradas se suelen filtrar antes de extraer frecuencias: son las llamadas <em>stop words</em>.</p></li>
</ol>
<p>Por su flexión, hay categorías cuyas palabras son variables o “flexivas” y categorías de palabras invariables. Son categorías variables los nombres (con flexión de género y número), verbos (con flexión en tiempo, modo, voz, aspectos, número y persona), adjetivos (género, número y grado), pronombres y algunos adverbios y determinantes. La flexión tiene implicaciones semánticas, por lo que su análisis es más complejo. Esta es la razón de ser del análisis morfológico completo, donde de cada <em>token</em> se especifica automáticamente no solo su categoría gramatical, sino también sus rasgos flexivos.</p>
<p>Finalmente, por su función en el texto, se diferencia entre clases de palabras con significado léxico (nombres, verbos, adjetivos, adverbios) y clases de palabras con “significado” gramatical (determinantes, preposiciones, pronombres, etc.). Este significado gramatical no es significado pleno. Se refiere a que esas palabras pueden modificar o determinar el significado de las palabras con significado léxico con las que aparecen, pero en sí mismas y por sí solas no podemos decir que tengan un significado completo. Una preposición como “ante”, por ejemplo, podemos intuir rasgos semánticos (“frente a algo o delate de algo”), pero su función es completar ese “algo” con indicación de posición (“se paró <em>ante</em> de la puerta”).</p>
</section>
<section id="relevancia-del-analisis-categorial-en-mineria-de-textos">
<h3><span class="section-number">3.2.2. </span>Relevancia del análisis categorial en minería de textos<a class="headerlink" href="#relevancia-del-analisis-categorial-en-mineria-de-textos" title="Permalink to this headline">#</a></h3>
<p>Así como un proceso de tokenización es un paso inleduble para realizar minería de textos, el análisis categorial no siempre es necesario. Éste es un proceso que requiere recursos computacionales y, si el corpus es muy amplio, también mucho tiempo de procesamiento. Por ello se debe tener claro qué se necesita para valorar si es necesario utilizar un <em>pos tagger</em> o no.</p>
<p>Un análisis categorial es en muchas ocasiones la base del sistema de PLN, porque los análisis sintáticos y muchos de los análisis semánticos y pragmáticos dependen de las clases de palabras: necesitan saber el lema de cada <em>token</em>, la clase de palabra a la que pertenecen y/o sus rasgos morfológicos.</p>
<p>Un proceso muy común en minería de texto y de poco coste computacional es realizar un filtro de “stop words”: elimiar todas aquellas palabras que pertenecen a categorías cerradas y que no tienen significado léxico (preposiones, conjunciones, artículos, etc.). Este filtrado NO necesita realizar el análisis categorial completo: como son categorías cerradas (es, por tanto, un conjunto finito de palabras), se pueden listar en un fichero y filtrar con un simple <em>pattern matching</em>. También un proceso de <em>stemming</em> requiere poco tiempo de proceso (no es necesario realizar todo el ánalisis categorial) y permitiría tratar <em>token</em> de categorías flexivas como un solo <em>type</em>.</p>
<p>Otras aplicaciones de minería de textos sí dependen de las categorías gramaticales y por tanto requieren realizar el análisis categorial y morfológico. Entre otras:</p>
<ul class="simple">
<li><p>la <em>extracción de entidades</em> necesita saber qué palabras son nombres y en especial los nombres propios;</p></li>
<li><p>la <em>extracción de eventos</em> necesita saber qué palabras son verbos y qué palabras son nombres;</p></li>
<li><p>el <em>análisis de sentimientos y opiniones</em> depende mucho de los adjetivos;</p></li>
<li><p>la <em>detección de autoría</em> determina automáticamente quién es el autor de un texto sobre todo por cómo se utilizan las palabras de categorías cerradas (preposiciones, conjunciones, etc). Se ha demostrado que sus frecuencias de uso depende mucho del estilo personal de escritura de cada persona. La frecuencia de uso de otras clases de palabras como nombres o verbos depende más del tema del texto y no suelen ser buenos indicadores para detectar automáticamente la autoría de un texto.</p></li>
<li><p>etc.</p></li>
</ul>
</section>
<section id="representacion-formal-de-la-informacion-morfologica-y-categorial">
<h3><span class="section-number">3.2.3. </span>Representación formal de la información morfológica y categorial<a class="headerlink" href="#representacion-formal-de-la-informacion-morfologica-y-categorial" title="Permalink to this headline">#</a></h3>
<p>Antes de exponer los métodos de análisis categorial, vamos a ver cómo se representa formalmente esta información lingüística.</p>
<p>La información categorial y morfológica se representa explícitamente mediante etiquetas o tags. Actualmente hay diversas propuestas, cada una con un juego de etiquetas diferente. Antes de usar un <em>PoS_tagger</em>, es muy importante saber con qué juego de etiquetas representa la información para poder luego interpretar la información correctamente. Las listas de etiquetas (o <em>tag sets</em>) comunes hoy día en PLN son los siguientes:</p>
<ul>
<li><p><em>Penn Treebank tag set</em> (solo para inglés):</p>
<ul>
<li><p><a class="reference external" href="https://www.cs.upc.edu/~nlp/SVMTool/PennTreebank.html">https://www.cs.upc.edu/~nlp/SVMTool/PennTreebank.html</a></p></li>
<li><p>Ejemplos:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>JJ = adjetivo
NN = nombre común
VB = verbo
...
</pre></div>
</div>
</li>
</ul>
</li>
<li><p><em>Universal tagset</em> (<em>Universal dependencies project</em>):</p>
<ul>
<li><p><a class="reference external" href="https://universaldependencies.org/u/pos/">https://universaldependencies.org/u/pos/</a></p></li>
<li><p>Ejemplos:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ADJ   = adjetivo
NOUN  = nombre
VERB  = verbo
...
</pre></div>
</div>
</li>
<li><p>Este modelo, el más utilizado hoy día, está adaptado a más de 50 idiomas (y sigue creciendo). Es el más apropiado para minería de textos multilingüe. Ver <a class="reference external" href="https://universaldependencies.org/">https://universaldependencies.org/</a></p></li>
</ul>
</li>
<li><p><em>EAGLES tag set</em> (para varios idiomas):</p>
<ul>
<li><p><a class="reference external" href="http://blade10.cs.upc.edu/freeling-old/doc/tagsets/tagset-es.html">http://blade10.cs.upc.edu/freeling-old/doc/tagsets/tagset-es.html</a></p></li>
<li><p><a class="reference external" href="https://freeling-user-manual.readthedocs.io/en/latest/tagsets/">https://freeling-user-manual.readthedocs.io/en/latest/tagsets/</a></p></li>
<li><p><a class="reference external" href="http://www.ilc.cnr.it/EAGLES96/annotate/annotate.html">http://www.ilc.cnr.it/EAGLES96/annotate/annotate.html</a></p></li>
<li><p>Ejemplo:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>AQ0CP0  = adjetivo calificativo común plural
NCFP000 = nombre común femenino plural
VMIP1S0 = verbo principal indicativo presente primera persona singular
...
</pre></div>
</div>
</li>
<li><p>Este tipo de etiqueta es más complejo pero contiene bastante información. Cada posición es un rasgo morfológico. El primero (A, N, V, etc.) indica la categoría gramatical. El resto de posiciones, dependiendo de la categoría, aporta una información morfológica u otra. Así, para nombre, las posicones indican:</p>
<ul class="simple">
<li><p>1 categoría</p></li>
<li><p>2: tipo: común o propio</p></li>
<li><p>3: género</p></li>
<li><p>4 número</p></li>
<li><p>5-6 rasgos semántico</p></li>
<li><p>7 grado</p></li>
</ul>
</li>
<li><p>Ver <a class="reference external" href="http://blade10.cs.upc.edu/freeling-old/doc/tagsets/tagset-es.html">las tablas</a> para saber qué información contiene cada posición del resto de categorías.</p></li>
<li><p>Este modelo se planteó como un modelo multilingüe. Así, no todas las palabras de todos los idiomas tienen esa información morfológica. Si una palabra no tiene un rasgo morfológico determinado, en la etiqueta aparece <span class="math notranslate nohighlight">\(0\)</span>.</p></li>
<li><p>Por ejemplo, en la etiqueta “NCFP000” no es relevante ni el rasgo semántico (codificado como 00) ni el grado (codificado como 0). Sí es relevante la categoría (N: nombre), el tipo (C: común), el género (F: femenino) y el número (P: plural). Esta etiqueta se asociaría por ejemplo a la palabra “camisas”.</p></li>
</ul>
</li>
</ul>
<p>Como se puede observar, los <em>tag sets</em> utilizados en PLN suelen tener más categorías que las utilizadas en lingüística teórica. Por ejemplo, presentan etiquetas específicas para los signos de puntuación o para números y fechas, entre otros casos.</p>
</section>
<section id="arquitectura-de-un-pos-tagger">
<h3><span class="section-number">3.2.4. </span>Arquitectura de un <em>PoS_tagger</em>.<a class="headerlink" href="#arquitectura-de-un-pos-tagger" title="Permalink to this headline">#</a></h3>
<p>La siguiente imagen muestra una sencilla arquitectura para un <em>pos_tagger</em>:</p>
<p><img alt="ArquitecturaPoStagger" src="_images/arquitecturaPoStagger.png" /></p>
<p>La entrada es un texto que ha sido previamente tokenizado. Los signos de puntuación, por ejemplo, estarán separados de las palabras anterior o posterior (según proceda). La salida será cada <em>token</em> de entrada junto a su información categorial y morfológica. Normalmente, la salida de un <em>pos tagger</em> es:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>token lema etiqueta_PoS
</pre></div>
</div>
<p>Para poder determinar el lema y la categoría de cada <em>token</em>, así como la información morfológica, el <em>pos_tagger</em> necesita algún tipo de recurso. Básicamente dos: un diccionario que contenga la información morfológica de cada palabra; y un conjunto de reglas (gramática) que deriven la información morfológica según los rasgos de la palabra y de las palabas del contexto. Este puede haber sido creado a mano (reglas manuales) o  mediante aprendizaje automático. Esto es una analizador en dos fases (consulta diccionario y desambiguación), que es la arquitectura básica de un <em>PoS_tagger</em>.</p>
<p>Un ejemplo de <em>PoS_tagger</em> para español es <em>Freeling</em>. Antes de seguir, prueba su demo:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://nlp.lsi.upc.edu/freeling/demo/demo.php">https://nlp.lsi.upc.edu/freeling/demo/demo.php</a></p></li>
</ul>
</section>
<section id="algoritmos-de-desambiguacion-categorial">
<h3><span class="section-number">3.2.5. </span>Algoritmos de desambiguación categorial.<a class="headerlink" href="#algoritmos-de-desambiguacion-categorial" title="Permalink to this headline">#</a></h3>
<p>Si un <em>token</em> solo puede pertenecer a una categoría gramatical, su análisis morfológico es sencillo: basta con consultar el diccionario para saber su categoría. El problema viene cuando un <em>token</em> puede pertenecer a dos o más categorías gramaticales (ambigüedad categorial). Este es el caso más común, pues más del 60% de las palabras de un texto en español suelen presentar ambigüedad categorial. En esta sección se presentan los principales algoritmos para resolver la ambigüedad categorial.</p>
<section id="modelo-basado-en-reglas-simbolicos">
<h4><span class="section-number">3.2.5.1. </span>Modelo basado en reglas (simbólicos).<a class="headerlink" href="#modelo-basado-en-reglas-simbolicos" title="Permalink to this headline">#</a></h4>
<p>Los primeros sistemas utilizaban reglas morfológica simples creadas a mano por lingüistas. Se seguía el modelo de dos fases: una primera que asigna las categorías gramaticales a cada <em>token</em> según el diccionario, y una segunda que aplica reglas de desambiguación en el caso de que el <em>token</em> tenga asignadas dos o más etiquetas.</p>
<p>Las reglas de desambiguación era básicamente expresiones regulares tipo:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>\b.*ing\b = Verbo Infinitivo en inglés.
\b.*mente\b = adverbio en español.
las\s[a-z]*as → Nombre femenino plural en español.
etc.
</pre></div>
</div>
<p>Ejemplo de esta aproximación es el sistema TAGGIT, de 1971. Constaba de 71 etiquetas y 3300 reglas de desambiguación. Con esto alcanzó un nivel de precisión del 77%.<a class="footnote-reference brackets" href="#id11" id="id4">4</a></p>
<p>La herramienta NLTK tiene implementado un <em>PoS_tagger</em> basado en expresiones regulares que se puede adaptar. Ver <a class="reference external" href="https://www.nltk.org/book/ch05.html">https://www.nltk.org/book/ch05.html</a>.</p>
<section id="gramaticas-de-restricciones-constraint-grammar">
<h5><span class="section-number">3.2.5.1.1. </span>Gramáticas de restricciones (<em>Constraint grammar</em>)<a class="headerlink" href="#gramaticas-de-restricciones-constraint-grammar" title="Permalink to this headline">#</a></h5>
<p>En los años 90 hubo un modelo teórico que tuvo buenos resultados en su aplicación al análisis categorial: las gramáticas de restricciones. Este modelo se basa en la idea de que las reglas de la gramática no tienen por qué ser positivas (reglas que digan cómo es el idioma), sino que pueden ser negativas (reglas que digan como NO es el idioma). Estas reglas negativas son las <strong>restricciones</strong>.</p>
<p>Así, aplicado al análisis categorial, una restricción indicaría no qué categoría sería la apropiada para una palabra dado un contexto, sino que categoría seguro que NO es la apropiada a una palabra dado un contexto. Por ejemplo, esta regla</p>
<blockquote>
<div><p>“Un verbo no va precedido nunca de artículo”.</p>
</div></blockquote>
<p>permitiría analizar correctamente el sintagma:</p>
<blockquote>
<div><p>El cura de la iglesia</p>
</div></blockquote>
<p>“Cura” no puede ser verbo (de “curar”) porque va precedido de un artículo. Por tanto, es un nombre.</p>
<p>El sistema principal basado en restricciones es el sistema ENGCG (Karlsson et al 1995).<a class="footnote-reference brackets" href="#id12" id="id5">5</a></p>
</section>
</section>
<section id="modelos-estadisticos">
<h4><span class="section-number">3.2.5.2. </span>Modelos estadísticos<a class="headerlink" href="#modelos-estadisticos" title="Permalink to this headline">#</a></h4>
<section id="cadena-de-markov">
<h5><span class="section-number">3.2.5.2.1. </span>Cadena de Markov<a class="headerlink" href="#cadena-de-markov" title="Permalink to this headline">#</a></h5>
<p>La aplicación de modelos de Markov supuso un gran avance en la desambiguación categorial. La categoría gramatical de un <em>token</em> depende en gran medida del contexto lingüístico donde aparece. Las reglas directas no son capaces de modelar ese contexto, pero los modelos de Markov sí.</p>
<p>Dada una secuencia de estados, la propiedad de Markov asume que es posible predecir el siguiente estado tendiendo en cuenta únicamente el estado presente. Así, dada una secuencia de palabras (cadena), la propiedad de Markov postula que podemos saber la siguiente palabra a partir de la palabra actual. Así, un modelo de Markov predice un token <span class="math notranslate nohighlight">\(w_i\)</span>  según la probabilidad de la palabra anterior <span class="math notranslate nohighlight">\(w_{i-1}\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(w_i|w_{i-1})\]</div>
<p>Este es un modelo de bigramas porque solo tiene en cuenta la palabra anterior y no todas las palabras anteriores <span class="math notranslate nohighlight">\(w_{i-2} \dots w_{i-n}\)</span>, que es la asunción principal de la propiedad de Markov.</p>
</section>
<section id="modelo-oculto-de-markov">
<h5><span class="section-number">3.2.5.2.2. </span>Modelo oculto de Markov<a class="headerlink" href="#modelo-oculto-de-markov" title="Permalink to this headline">#</a></h5>
<p>Aplicado a cadena de <em>tokens</em> tendríamos un simple predictor de palabras como el que tenemos en el móvil. Lo característico de su aplicación para análisis categorial es que se aplica no a la secuencia de palabras (la cadena visible de <em>tokens</em>), sino a la secuencia de categorías gramaticales: la cadena <strong>oculta</strong> de <em>tags</em>. Se condiera una cadena oculta porque las categorías gramaticales no están explícitamente en el texto, sino que son inferidas. De ahí el nombre de <strong>Modelo Oculto de Markov</strong> o <em><strong>Hidden Markov Model</strong></em> (HMM).</p>
<p>El modelo oculto de Markov necesita, así, en dos probabilidades: una probabilidad de transición de un estado a otro de la cadena (la probabilidad del modelo de Markov simple) y además una probabilidad de emisión del estado oculto al estado visible.</p>
<p>Aplicado al análisis categorial, la probabilidad de transición es la probabilidad de una etiqueta categorial <span class="math notranslate nohighlight">\(t_i\)</span> dada la etiqueta categorial de la palabra anterior <span class="math notranslate nohighlight">\(t_{i-1}\)</span>.</p>
<div class="math notranslate nohighlight">
\[P(t_i|t_{i-1})\]</div>
<p>La probabildad de emisión es la probabilidad de que una palabra dada <span class="math notranslate nohighlight">\(w_i\)</span> esté asociada a una etiqueta categorial <span class="math notranslate nohighlight">\(t_i\)</span>:</p>
<div class="math notranslate nohighlight">
\[P(w_i|t_i)\]</div>
<p>Combinando ambos valores obtenemos la predicción final:</p>
<div class="math notranslate nohighlight">
\[P(t_i) = P(w_i|t_i) * P(t_i|t_{i-1})\]</div>
<p>Por ejemplo, dado el siguiente sintagma ya comentado:</p>
<blockquote>
<div><p>El cura de la iglesia.</p>
</div></blockquote>
<p>Un modelo oculto de Markov predice perfectamente que ese “cura” es nombre y no es verbo (de “curar”) porque la probabilidad de que un artículo (la categoría del <em>token</em> “El”) esté seguido por un verbo es prácticamente 0. Por lo que la probabilidad más alta es que “cura” sea nombre.</p>
<p>Un modelo oculto de Markov puede ser entrenado a partir de un corpus anotado, pero también se puede entrenar de manera iterativa con corpus sin anotar, tomando las palabras no ambiguas como inicio del entrenamiento.</p>
<div class="note admonition">
<p class="admonition-title">Lectura obligatoria</p>
<p>Lee con atención el apartado <a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/8.pdf">“8.4 HMM Part-of-Speech Tagging”</a> del capítulo 8 del libro de Juravsky y Martin (2022) <em>Speech and Language Processing</em>, donde aprenderás los detalles matemáticos y  computacionales del análisis categorial basado en modelos ocultos de Markov.</p>
</div>
</section>
<section id="conditional-random-fields-y-otros">
<h5><span class="section-number">3.2.5.2.3. </span><em>Conditional Random Fields</em> y otros.<a class="headerlink" href="#conditional-random-fields-y-otros" title="Permalink to this headline">#</a></h5>
<p>Si bien con modelos ocultos de Markov un <em>PoS_tagger</em> puede tener una precisión superior al 90%, aún hay aspectos en los que no funciona bien, como por ejemplo cómo analizar palabras que no ha visto antes (y por tanto no tiene probabilidad de emisión). Estos problemas se superaron con un modelo matemático también secuencial pero con más relevancia en cuanto al modelado del contexto: <em><strong>conditional random field</strong></em> (CRF o <a class="reference external" href="https://es.wikipedia.org/wiki/Campo_aleatorio_condicional">“campo aleatorio condicional”</a>). Este permite un tratamiento más rico del contexto. Lee el apartado [“8.5 Conditional Random Fields (CRFs)”] (<a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/8.pdf">https://web.stanford.edu/~jurafsky/slp3/8.pdf</a>) del capítulo 8 del libro de Juravsky y Martin (2022) <em>Speech and Language Processing</em> para más detalles.</p>
<p>Modelos ocultos de Markov y <em>Conditional Random Fields</em> son las dos principales aproximaciones al análisis categorial, pero no las únicas. Se han aplicado otro modelos de aprendizaje, tanto supervisados como no supervisados, como árboles de decisión o máquinas de vectores soporte (<em>support vector machine</em> SVM), etc. Un ejemplo que tuvo impacto en su momento fue el “Transformation-based Tagger” de Brill (1995), que aplicaba un modelo iterativo de aprendizaje de reglas con refinado manual.</p>
</section>
</section>
</section>
<section id="situacion-actual">
<h3><span class="section-number">3.2.6. </span>Situación actual<a class="headerlink" href="#situacion-actual" title="Permalink to this headline">#</a></h3>
<p>El análisis categorial de las lenguas más habladas se considera una tarea prácticamente resuelta. Las dos líneas de investigación principales son:</p>
<ul class="simple">
<li><p>desarrollar analizadores multilingües (en la línea, por ejemplo, de las Dependencias Universales que se verá luego); y</p></li>
<li><p>aplicar redes neuronales, que es hoy día el modelo estándar. En próximos temas se verán las redes neuronales.</p></li>
</ul>
<p>La siguiente página recoge los últimos artículos sobre <em>Part of Speech tagging</em>:</p>
<p><a class="reference external" href="http://nlpprogress.com/english/part-of-speech_tagging.html">http://nlpprogress.com/english/part-of-speech_tagging.html</a></p>
</section>
<section id="recursos">
<h3><span class="section-number">3.2.7. </span>Recursos.<a class="headerlink" href="#recursos" title="Permalink to this headline">#</a></h3>
<p>Cualquier sistema de PLN parte de un PoS tagger. Es el análisis básico. Hay muchos disponibles por la web:</p>
<ul class="simple">
<li><p>Freeling <a class="reference external" href="http://nlp.lsi.upc.edu/freeling/index.php/">http://nlp.lsi.upc.edu/freeling/index.php/</a></p></li>
<li><p>SpaCy: <a class="reference external" href="https://spacy.io/">https://spacy.io/</a></p></li>
<li><p>NLTK: <a class="reference external" href="http://www.nltk.org/">http://www.nltk.org/</a></p></li>
<li><p>Standford CORE NLP: <a class="reference external" href="https://stanfordnlp.github.io/CoreNLP/">https://stanfordnlp.github.io/CoreNLP/</a></p></li>
<li><p>Google CLOUD: <a class="reference external" href="https://cloud.google.com/natural-language/">https://cloud.google.com/natural-language/</a></p></li>
<li><p>En CLARIN hay también varios PoS_taggers: <a class="reference external" href="https://www.clarin.eu/resource-families/tools-part-speech-tagging-and-lemmatisation">https://www.clarin.eu/resource-families/tools-part-speech-tagging-and-lemmatisation</a></p></li>
<li><p>En OpenNLP (Java): <a class="reference external" href="https://opennlp.apache.org/docs/">https://opennlp.apache.org/docs/</a></p></li>
</ul>
<p>y muchos más…</p>
</section>
</section>
<section id="analisis-sintactico">
<h2><span class="section-number">3.3. </span>Análisis sintáctico.<a class="headerlink" href="#analisis-sintactico" title="Permalink to this headline">#</a></h2>
<p>La sintaxis es el área de la lingüística que estudia cómo se relacionan las palabras dentro de una oración: cómo se agrupan y qué tipo de relación establecen entre ellas.</p>
<p>En Procesamiento del Lenguaje Natural, a la herramienta encargada de realizar el análisis sintático se le da el nombre genérico de <em>parser</em> y a la tarea <em>parsing</em> (como en los compiladores de lenguajes de programación).</p>
<p>En el proceso de interpretación automática de un texto, es necesario conocer las relaciones sintáticas porque de ellas dependen diversos aspectos semánticos. Si te fijas en el siguiente ejemplo, verás dos oraciones con las mismas palabras (“subir”, “tender” y “a”) y la misma categoría gramatica (verbo infinitivo, verbo infinitivo y preposción), pero con sentido totalmente diferente. Son las relaciones sitnáticas las que nos indican la interpretación correcta de cada una:</p>
<blockquote>
<div><p>No es lo mismo “subir a tender” que “tender a subir”.</p>
</div></blockquote>
<p>En minería de textos, sin embargo, no es realmente una tarea de PLN que se utilice mucho: requiere tiempo de procesamiento (que aumenta cuanto más grande es el corpus) y no aporta la suficiente información como para que valga la pena ese gasto computacional. La sintaxis es necesaria, sobre todo, para cuando se necesita análisis de precisión.</p>
<p>En esta sección se exponen los fundamento del análisis sintáctico computacional, el análisis de dependencias y  se muestran algunas herramientas disponibles para aplicar en minería de textos.</p>
<section id="arquitectura-estandar-de-un-parser">
<h3><span class="section-number">3.3.1. </span>Arquitectura estándar de un <em>parser</em><a class="headerlink" href="#arquitectura-estandar-de-un-parser" title="Permalink to this headline">#</a></h3>
<p>La siguiente imagen muestra la arquiectura básica de un <em>parser</em>:</p>
<p><img alt="ArquitecturaParser" src="_images/parser.png" /></p>
<p>Como se puede observar, la entrada del <em>parser</em> es la salida del analizador categorial. De hecho el <em>parser</em> necesita saber (en principio) la categoría gramatical de las palabras para poder establecer las relaciones sintáticas entre ellas. La salida suele ser en forma de árbol, donde las palabras están relacionadas entre sí mediante arcos. En la siguiente sección se mostrarán los principales tipos de árboles sintácticos.</p>
<p>El <em>parser</em> necesita un recursos para realizar el análisis que se suele denominar “gramática”. Esta contiene las reglas para establecer las relaciones. En los inicios del PLN, estas gramáticas se realizaban a mano: eran gramática pequeñas con muy poca cobertura. Hoy día, al igual que en el análisis categorial, las gramáticas se realizan con modelos de aprendizaje automático, y se aplican reglas manuales solo para ganar precisión en casos concretos. Las últimas propuestas están basadas en modelos neuronales, que se ha demostrado son capaces de inferir relaciones sintácticas sin necesidad de una gramática previa.<a class="footnote-reference brackets" href="#id13" id="id6">6</a></p>
</section>
<section id="principal-problema-computacional">
<h3><span class="section-number">3.3.2. </span>Principal problema computacional<a class="headerlink" href="#principal-problema-computacional" title="Permalink to this headline">#</a></h3>
<p>Asignar relaciones a palabras a partir de categorías gramaticales es una tarea hasta cierto punto viable. El gran problema que debe resolver un <em>parser</em> es la ambigüedad estructural: cuando es posible derivar dos o más árboles sintáticos de la misma oración. La resolución de esta ambigüedad requiere en muchas ocasiones información semántica y conocimiento del mundo (para realizar una interpretación coherente), aspectos estos que salen fuera del análisis sintático propiamente dicho.</p>
<p>A continuación se muestran dos casos de ambigüedad estructural. En este primer ejemplo (ya visto en el tema anterior), la ambigüedad viene producida por el sintgma preposicional “con los prismáticos”, que puede ser tanto complemento de “hermano” como del sujeto “yo”:</p>
<blockquote>
<div><p>“Ayer vi a tu hermano con los prismáticos.”</p>
</div></blockquote>
<p>En el siguiente ejemplo es la coordinación la que está generando la ambigüedad. El adjetivo “limpios” puede ser complemento solo de “cubiertos” o de la coordinación completa “los platos y los cubiertos”. En uno u otro caso, el árbol sintático cambia:</p>
<blockquote>
<div><p>“Sirve los platos y los cubiertos limpios.”</p>
</div></blockquote>
<p>El <em>parser</em> debe incluir, por tanto, algoritmos de desambiguación que decidan, en casos como estos, qué árbol sintático sería el más apropiado.</p>
</section>
<section id="modelos-de-representacion">
<h3><span class="section-number">3.3.3. </span>Modelos de representación<a class="headerlink" href="#modelos-de-representacion" title="Permalink to this headline">#</a></h3>
<p>En PLN hay dos modelos de representación sintáctica: los modelos basados en <strong>constituyentes</strong> y los modelos basados en <strong>dependencias</strong>. Cada uno representa algún aspectos concreto de la sintaxis y está motivado por diferentes teorías lingüísticas. Antes de utilizar un <em>parser</em> para hacer minería de textos, es necesario saber en qué modelo está basado para saber qué información nos va a dar.</p>
<p>Lo que viene a continuación igual te recuerda las clases de bachillerato.</p>
<p>El modelo basado en constituyentes realiza dos tareas: primero agrupa las palabras en unidades complejas llamados “sintagmas” (<em>phrases</em> en inglés). Un sintagma puede contener tanto palabras como otros sintagmas. Así, de abajo arriba, las palabras con relación sintática estrecha se agrupan en sintagmas, estos a su vez se agrupan en sintagmas complejos hasta llegar a la agrupación final que es toda la oración. Cada una de estas agrupaciones recibe el nombre de <em>constituyente oracional</em>.</p>
<p>La segunda tarea es determinar el tipo de sintagma: nominal, verbal, preposicional, adjetivo, etc. El tipo de sintagma depende siempre de la palabra que actúa como núcleo sintagmático (un nombre, una preposición, un adjetivo…). El sintagma que los agrupa a todos es la oración y su núcleo, normalmente, un verbo.</p>
<p>La siguiente imagen es un ejemplo de árbol de análisis basado en constituyentes:</p>
<p><img alt="Constituyentes" src="_images/constituyentes.png" /></p>
<p>En este caso tenemos dos sintagmas nominales (SN), un sintagam verbal (SV) y la oración. En la herramientas de PLN lo normal es que te encuentres esos sintagmas con las siglas en inglés: “NP” para <em>nominal phrase</em>, “PP” para <em>prepositional phrase</em>, “VP” para <em>verbal phrase</em>, etc.</p>
<p>El modelo basado en dependencias es diferente. No le interesa tanto mostrar cómo se agrupan las palabras según su relación sintática, como mostrar qué relación o dependencia tienen unas palabras con otras. La dependencia se produce siempre entre dos palabras: una actúa de núcleo (<em>head</em>) y otro que actúa de “dependiente” (<em>dependent</em>) o complemento. El análisis de dependencias también supone dos tareas: primer detectar de quién depende cada palabra de la oración, y segundo determinar el tipo de dependencia: sujeto, objeto, complemento, especificador… Los árboles de depencias suelen tener forma de grafo con nodos/hojas (las palabras) y arcos dirigidos (el tipo de dependencia entre dos nodos), como muestra la siguiente imagen:</p>
<p><img alt="Dependecias" src="_images/arbol_dependencias.png" /></p>
<!-- ![Dependecias_Freeling](images/dependency_parsing_FreeLing.jpg)
(Créditos de la imagen [aquí](http://liceu.uab.cat/~joaquim/language_technology/NLP/PLN_analisis.html#An%C3%A1lisis_de_dependencias)) -->
<p>En este ejemplo podemos ver que el núcleo oracional (<em>root</em>) es el verbo “buscó”. De este dependen tres palabras: “Inés” con una dependencia de <em>nsubj</em> (sujeto nominal), “llaves” con una dependencia de <em>obj</em> (lo que en la gramática escolar se denomina “complemento directo” u “objeto directo”) y “cajón”
con una dependencia de <a class="reference external" href="https://universaldependencies.org/u/dep/obl.html"><em>obl</em></a> (de <em>oblique</em> o <em>adjunct</em>, que vendría a ser un complemento circustancial). A su vez, “llaves” y “cajón” son núcleo de otras palabras, etc.</p>
<p>Hoy día el modelo más común es el de dependencias, sobre todo porque hace una representación de la relación sintática más explícita. Pero antes de profundizar en él, y para entender bien cómo funciona un <em>parser</em>, vamos a ver los modelos de constituyentes.</p>
</section>
<section id="gramaticas-formales">
<h3><span class="section-number">3.3.4. </span>Gramáticas formales<a class="headerlink" href="#gramaticas-formales" title="Permalink to this headline">#</a></h3>
<p>La parte principal del un <em>parser</em> es la gramática: el conjunto de reglas que, dado una secuencia de <em>tokens</em> (y en su caso también categorías gramaticales) derivan un árbol sintático. Estas deben ser reglas formales que la máquina puede entender y procesar.</p>
<section id="context-free-grammars">
<h4><span class="section-number">3.3.4.1. </span>Context free grammars<a class="headerlink" href="#context-free-grammars" title="Permalink to this headline">#</a></h4>
<p>Las gramáticas independients del contexto (CFG: <em>Context free grammars</em>) es el formalismo base de toda una familia de gramáticas formales que se desarrollaron después. La definición formal es la siguiente:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>G = (NT, T, S, P)
NT: {no terminales},
T: {terminales},
S: Símbolo inicial
P: Reglas de producción A -&gt; w: 
    A   NT
    W   (NT U T)*
</pre></div>
</div>
<p>Una CFG es una tupla de cuatro elementos: un conjunto de símbolos no terminales, un conjunto de símbolos terminales, un símbolo inicial, y una serie de reglas de producción con la forma <span class="math notranslate nohighlight">\(A \to w\)</span>, en la que los símbolos de la izquierda (<span class="math notranslate nohighlight">\(A\)</span>) tienen que ser siempre no terminales, y los de la derecha <span class="math notranslate nohighlight">\(w\)</span> pueden ser tanto terminales como no terminales.</p>
<p>Ejemplo:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>NT={S,NP,VP,nprop,n,v,det}, 
T={Pepe,manzana, come,una},
S=S,
P:
    S -&gt; NP VP
    NP -&gt; nprop
    NP -&gt; det  n
    VP -&gt; v
    VP -&gt; v NP
</pre></div>
</div>
<p>En este caso los símbolos no terminales son las etiquetas sintáticas y categoriales (S, NP, VP, nprop, n, v, det), los símbolos terminales son los <em>tokens</em> (“Pepe,manzana, come,una”), el símbolo incial es <span class="math notranslate nohighlight">\(S\)</span> y las reglas de producción indica cómo cada símbolo no terminal se puede transformar en otros símbolos. De esta gramática se podría derivar el siguiente árbol:</p>
<p><img alt="AnalisisConstituyentes" src="_images/constituyentes_2.png" /></p>
<p>Estas gramáticas son, por supuesto, muy limitadas. Sólo sirven para conjuntos predefinidos de oraciones. En los años 80 fueron ampliadas con estructuras de rasgos y técnicas de unificación. Las estructuras de ragos son estructuras asociadas a cada símbolo (tanto terminal como no terminal) que permiten enriquecerlo con datos (pares atributo-valor). En el ejemplo siguiente se puede ver una estructura de rasgos con información morfológica. La unificación es una operación que permite comparar y, si son compatibles, unir dos estructuras de rasgos. La siguiente imagen muestra un caso de unificación porque las dos estructuras de rasgos son compatibles:</p>
<p><img alt="Unificación" src="_images/unificacion.png" /></p>
<p>Si en vez de “La casa”, la oración de entrada fuera “El casa”, la regla <span class="math notranslate nohighlight">\(SN \to DET N\)</span> no se aplicaría porque la estructura de rasgos sería incompatible. El género de “el” sería masculino y el de “casa” femenino. Este simple caso de concordancia se puede modelar bien con estructuras de rasgos.</p>
<p>A partir de estos formalismos, en lingüística se han desarrollado diferentes modelos completos com las <em>Head-driven phrase structure grammar</em> o las <em>Lexical-Functional Grammar</em> (que sigue siendo un modelo válido y objeto de investigación lingüística: <a class="reference external" href="https://ling.sprachwiss.uni-konstanz.de/pages/home/lfg/">https://ling.sprachwiss.uni-konstanz.de/pages/home/lfg/</a>).</p>
</section>
<section id="modelos-probabilisticos">
<h4><span class="section-number">3.3.4.2. </span>Modelos probabilísticos<a class="headerlink" href="#modelos-probabilisticos" title="Permalink to this headline">#</a></h4>
<p>Si bien estos formalismo son hoy válidos para el estudio lingüístico por permitir una forma elegante de tratar los rasgos, no son útiles para Procesamiento del Lenguaje Natural. Entre otras cosas, no son capaces de dar solución a la ambigüedad estructural que se comentó antes.</p>
<p>Una solución a este problema fueron las gramáticas probabilísticas, como la <em>Probabilistic Context Free Grammar</em>. Este modelo simplemente incluye un valor probabilístico de aplicación de la regla (que ha aprendido a partir de corpus anotados mediante aprendizaje supervisado). Este peso estadístico permite decidir qué regla aplicar en según qué casos:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>SV → V SP SP (0.5)
SV → V SP (0.3)
SV → V (0.2)
</pre></div>
</div>
<p>Con la aplicación del aprendizaje supervisado al análisis sintáctico se desarrollaron los <em>treebanks</em>: corpus de texto anotados a mano con árboles sintácticos. Estos se utilizan tanto como corpus de aprendizaje como corpus de evaluación para todo tipo de sistemas. Dos de los <em>treebanks</em> más conocidos, uno para para inglés y otro para español, son:</p>
<ul class="simple">
<li><p>Penn Treebank:</p>
<ul>
<li><p><a class="reference external" href="https://catalog.ldc.upenn.edu/LDC99T42">https://catalog.ldc.upenn.edu/LDC99T42</a></p></li>
<li><p><a class="reference external" href="https://www.kaggle.com/nltkdata/penn-tree-bank">https://www.kaggle.com/nltkdata/penn-tree-bank</a></p></li>
</ul>
</li>
<li><p>Ancora (español, catalán):</p>
<ul>
<li><p><a class="reference external" href="http://clic.ub.edu/corpus/en/ancora-descarregues">http://clic.ub.edu/corpus/en/ancora-descarregues</a></p></li>
</ul>
</li>
</ul>
<p>Hay muchos más para diferentes idiomas.</p>
</section>
</section>
<section id="chunkers">
<h3><span class="section-number">3.3.5. </span><em>Chunkers</em><a class="headerlink" href="#chunkers" title="Permalink to this headline">#</a></h3>
<p>Hasta ahora el análisis sintático se ha planteado como un análisis completo (<em>full parsing</em>): derivar el árbol entero en toda su profundidad. Dada la coplejidad que una oración real puede tener, este tipo de análisis resulta en muchas ocasiones muy complejo o incluso imposible, además de consumir mucho tiempo y recursos para obtener resultados no del todo buenos.</p>
<p>En los años 90 se propuso una solución a este problema: el <em>chunkers</em> o análisis sintáctico parcial (Abney 1991). Un análisis sintáctico parcial no deriva el árbol sintáctico completo de una oración, sino solo deriva el árbol de algunos sub-árboles. De un oración se pueden derivar, por ejemplo, solo los sintagmas nominales y verbales, sin llegar a construir un único árbol completo. Cada uno de estos sub-árboles es un <em>chunk</em>.</p>
<p>En análisis de constituyentes lo normal es realizar análisis parcial. Con ello se gana en velocidad y recursos.</p>
</section>
<section id="estrategias">
<h3><span class="section-number">3.3.6. </span>Estrategias<a class="headerlink" href="#estrategias" title="Permalink to this headline">#</a></h3>
<p>Hay dos tipos de estrategias de análisis: la descendente y la ascendente.</p>
<p>La descendente comienza el análisis con el símbolo inicial <span class="math notranslate nohighlight">\(S\)</span> y va derivando el árbol mediante la aplicación de las reglas en orden hasta llegar a analizar todos los símbolos terminales.</p>
<p>Con la herramienta <a class="reference external" href="https://www.nltk.org/">NLTK</a> instalada, puedes ver de manera gráfica cómo funciona un analizador descendente recursivo con el siguiente código:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import nltk
nltk.app.rdparser()
</pre></div>
</div>
<p>El ascendente parte de los símbolos terminales y, mediante las reglas, trata de llegar hasta el símbolo inicial. El modelo <em>shift-reduce</em>, por ejemplo, va seleccionando <em>token</em> a <em>token</em> (<em>shift</em>) y, cuando estos responden a un símbolo no terminal, los agrupa (<em>reduce</em>). Luego repite ambos procesos con los símbolos no terminales hasta alcanzar el símbolo inicial. Por ejemplo, la regla <span class="math notranslate nohighlight">\(SN \to DET N\)</span> agruparía un determinante con un nombre. Puedes ver una muestra grafica de este algoritmo con el siguiente código de NLTK:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import nltk
nltk.app.srparser()
</pre></div>
</div>
</section>
<section id="analisis-de-dependencias">
<h3><span class="section-number">3.3.7. </span>Análisis de dependencias<a class="headerlink" href="#analisis-de-dependencias" title="Permalink to this headline">#</a></h3>
<section id="formato-de-representacion-conll">
<h4><span class="section-number">3.3.7.1. </span>Formato de representación: CONLL<a class="headerlink" href="#formato-de-representacion-conll" title="Permalink to this headline">#</a></h4>
<p>Si bien hay difernetes formatos para representar el análisis de dependencias, el más común hoy día es el formato CONLL. Aquí puede ver un ejemplo:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>    Salida CoNLL-U
    # sent_id = 1
    # text = Los hombres que fuman puro tienen cara de canguro .
    1   Los el  DET DET Definite=Def|Gender=Masc|Number=Plur|PronType=Art   2   det _   _
    2   hombres hombre  NOUN    NOUN    Gender=Masc|Number=Plur 6   nsubj   _   _
    3   que que PRON    PRON    PronType=Int,Rel    4   nsubj   _   _
    4   fuman   fumar   VERB    VERB    Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin   2   acl _   _
    5   puro    puro    ADJ ADJ Gender=Masc|Number=Sing 4   obj _   _
    6   tienen  tener   VERB    VERB    Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin   0   root    _   _
    7   cara    cara    NOUN    NOUN    Gender=Fem|Number=Sing  6   obj _   _
    8   de  de  ADP ADP _   9   case    _   _
    9   canguro canguro NOUN    NOUN    Gender=Masc|Number=Sing 7   nmod    _   _
    10  .   .   PUNCT   PUNCT   PunctType=Peri  6   punct   _   _
</pre></div>
</div>
<p>Cada línes es un <em>token</em>. La primera columna es un índice, y las siguientes corresponden a: <em>token</em>, lema, categoría gramatical, información morfológica (opcional). Las dos última columnas indican el número de identificación de la palabra de quien es núcleo y la relación de dependencia con éste. Así se determina la dependencia y con ello el árbol. El inicio del árbol lo marca simpre la etiqueta <em>root</em> (en la palabra 6 en este caso).</p>
</section>
<section id="dependencias-universales">
<h4><span class="section-number">3.3.7.2. </span>Dependencias universales<a class="headerlink" href="#dependencias-universales" title="Permalink to this headline">#</a></h4>
<p>Esas etiquetas sintácticas responden al <em>tag set</em> de las dependencias universales o <a class="reference external" href="https://universaldependencies.org/"><em>Universal Dependencies</em></a> (Nivre et al., 2016). Este modelo es hoy el más utilizado por diversas razones. Entre otras cosas, está bien motivado desde un punto de vista lingüístico, pero al mismo tiempo es útil desde el punto de vista computacional y es “multilingüe, lo que permite tratar corpus con textos en diferentes idiomas con una representación sintática común.</p>
<p>Sin entrar en detalles, las principales etiquetas sintáticas que pueden a aparecer en un análisis de dependencias con las dependencias universales son:</p>
<ul class="simple">
<li><p>nsubj (sujeto nominal): <a class="reference external" href="https://universaldependencies.org/u/dep/nsubj.html">https://universaldependencies.org/u/dep/nsubj.html</a></p></li>
<li><p>obj (objecto directo): <a class="reference external" href="https://universaldependencies.org/u/dep/obj.html">https://universaldependencies.org/u/dep/obj.html</a></p></li>
<li><p>iobj (objeto indirecto): <a class="reference external" href="https://universaldependencies.org/u/dep/iobj.html">https://universaldependencies.org/u/dep/iobj.html</a></p></li>
<li><p>obl (<em>oblique nominal</em>), otros complementos del verbo: <a class="reference external" href="https://universaldependencies.org/u/dep/obl.html">https://universaldependencies.org/u/dep/obl.html</a></p></li>
<li><p>nmod (<em>nominal modifier</em> o complemento del nombre): <a class="reference external" href="https://universaldependencies.org/u/dep/nmod.html">https://universaldependencies.org/u/dep/nmod.html</a></p></li>
<li><p>etc.</p></li>
</ul>
<p>Puedes consultar todas las relaciones aquí: <a class="reference external" href="https://universaldependencies.org/u/dep/index.html">https://universaldependencies.org/u/dep/index.html</a></p>
</section>
<section id="analisis">
<h4><span class="section-number">3.3.7.3. </span>Análisis<a class="headerlink" href="#analisis" title="Permalink to this headline">#</a></h4>
<p>El análisis de dependecia estándar es el análisis basado en transiciones: <em>transition-based dependency parsing</em> (Nivre 2014), que es un tipo de análisis <em>shift-reduce</em>.</p>
<div class="note admonition">
<p class="admonition-title">Lectura obligatoria</p>
<p>Para completar este tema, lee con atención los apartados 18.1 y 18.2 (exceptuando 18.2.4.) del capítulo <a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/18.pdf">“18 Dependency Parsing”</a> del libro de Juravsky y Martin (2022) <em>Speech and Language Processing</em>. El resto del capítulo es lectura opcional.</p>
</div>
</section>
</section>
<section id="id7">
<h3><span class="section-number">3.3.8. </span>Situación actual<a class="headerlink" href="#id7" title="Permalink to this headline">#</a></h3>
<p>La situación actual del análisis sintático se caracteriza por:</p>
<ul class="simple">
<li><p>la aplicación de modelos neuronales como el <em>Neural Network Dependency Parser</em> (<a class="reference external" href="https://nlp.stanford.edu/software/nndep.shtml">https://nlp.stanford.edu/software/nndep.shtml</a>),</p></li>
<li><p>con ello, la representación de información sintática en <em>embeddings</em> com vectores (de lo que se hablará en los siguientes temas), y</p></li>
<li><p>las dependencias universales.</p></li>
</ul>
<p>Ver:</p>
<p><a class="reference external" href="http://nlpprogress.com/english/constituency_parsing.html">http://nlpprogress.com/english/constituency_parsing.html</a></p>
<p><a class="reference external" href="http://nlpprogress.com/english/constituency_parsing.html">http://nlpprogress.com/english/dependency_parsing.html</a></p>
</section>
<section id="herramientas">
<h3><span class="section-number">3.3.9. </span>Herramientas<a class="headerlink" href="#herramientas" title="Permalink to this headline">#</a></h3>
<p>Hay multitud de herramientas para realizar análisis sintático. Aquí cuatro de las más conocidas:</p>
<ul class="simple">
<li><p>SpaCy: <a class="reference external" href="https://spacy.io/">https://spacy.io/</a></p></li>
<li><p>STANZA: <a class="reference external" href="https://stanfordnlp.github.io/stanza/">https://stanfordnlp.github.io/stanza/</a></p></li>
<li><p>Freeling: <a class="reference external" href="https://nlp.lsi.upc.edu/freeling/node/1">https://nlp.lsi.upc.edu/freeling/node/1</a></p></li>
<li><p>UD-Pipe: <a class="reference external" href="https://ufal.mff.cuni.cz/udpipe">https://ufal.mff.cuni.cz/udpipe</a></p></li>
</ul>
<p>En la práctica se utilizará SpaCy.</p>
</section>
</section>
<section id="bibliografia">
<h2><span class="section-number">3.4. </span>Bibliografía<a class="headerlink" href="#bibliografia" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Abney S.P. (1991) “Parsing By Chunks”. In: Berwick R.C., Abney S.P., Tenny C. (eds) Principle-Based Parsing. Studies in Linguistics and Philosophy, vol 44. Springer, Dordrecht. <a class="reference external" href="https://doi.org/10.1007/978-94-011-3474-3_10">https://doi.org/10.1007/978-94-011-3474-3_10</a></p></li>
<li><p>Emily M. Bender (2013) <em>Linguistic Fundamentals for Natural Language Processing. 100 Essentials from Morphology and Syntax</em>, Synthesis Lectures on Human Language Technologies DOI: <a class="reference external" href="https://doi.org/10.1007/978-3-031-02150-3">https://doi.org/10.1007/978-3-031-02150-3</a></p></li>
<li><p>Steven Bird, Ewan Klein, and Edward Loper (2009) <em>Natural Language Processing with Python</em> <a class="reference external" href="https://www.nltk.org/book/">https://www.nltk.org/book/</a></p></li>
<li><p>Juravsky y Martin (2020) <em>Speech and Language Processing</em>. <a class="reference external" href="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</a></p></li>
<li><p>Karlsson, F., A. Voutilainen, J. Heikkilä, and A. Anttila (eds.). 1995. <em>Constraint Grammar. A language-independent system for parsing unrestricted text</em>. Berlin and New-York: Mouton de Gruyter</p></li>
</ul>
</section>
<section id="cuestionario-de-aprendizaje">
<h2><span class="section-number">3.5. </span>Cuestionario de aprendizaje<a class="headerlink" href="#cuestionario-de-aprendizaje" title="Permalink to this headline">#</a></h2>
<p>Una vez realizadas las lecturas, contesta el siguiente cuestionario:</p>
<p><a class="reference external" href="https://forms.gle/ncbWkFGCjSqXSTiX9">https://forms.gle/ncbWkFGCjSqXSTiX9</a></p>
<hr class="docutils" />
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="id8"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>“Token” se asimila en este caso a “occurrence”. Cfr. <a class="reference external" href="https://plato.stanford.edu/entries/types-tokens/#Occ">https://plato.stanford.edu/entries/types-tokens/#Occ</a></p>
</dd>
<dt class="label" id="id9"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Ver <a class="reference external" href="https://www.nltk.org/book/ch03.html">capítulo 3</a> del libro <a class="reference external" href="https://www.nltk.org/book/ch03.html"><em>Natural Language Processing with Python</em></a> para una explicación sencilla.</p>
</dd>
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Bender (2013) presenta una buena introducción a conceptos lingüísticos de uso común en Procesamiento del Lenguaje Natural.</p>
</dd>
<dt class="label" id="id11"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p>Greene, B. B. and G. M. R.ubin (1971). “Automatic grammatical tagging of English. Technical report”, Department of Linguistics, Brown University,
Providence, Rhode Island.</p>
</dd>
<dt class="label" id="id12"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p>Karlsson, Voutilainen, Heikkilä and Antilla (eds) 1995. <em>Constraint Grammar: A Language-Independent System for Parsing Unrestricted Text.</em> Mouton de Gruyter, Berlin and New York.</p>
</dd>
<dt class="label" id="id13"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p>Ver, entre otros, Ethan A. Chi, John Hewitt, and Christopher D. Manning (2020) “Finding Universal Grammatical Relations in Multilingual BERT” In <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 5564–5577. Association for Computational Linguistics. <a class="reference external" href="https://aclanthology.org/2020.acl-main.493/">https://aclanthology.org/2020.acl-main.493/</a></p>
</dd>
</dl>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="bloque1_1Introduccion.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">2. </span>Minería de textos y procesamiento del lenguaje natural.</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="bloque1_Practica1.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">4. </span>Práctica 1.</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Universitat d'Alacant<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>